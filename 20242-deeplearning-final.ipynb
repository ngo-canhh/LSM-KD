{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61910eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T01:33:40.118990Z",
     "iopub.status.busy": "2025-05-18T01:33:40.118789Z",
     "iopub.status.idle": "2025-05-18T01:33:40.125093Z",
     "shell.execute_reply": "2025-05-18T01:33:40.124517Z"
    },
    "papermill": {
     "duration": 0.011589,
     "end_time": "2025-05-18T01:33:40.126145",
     "exception": false,
     "start_time": "2025-05-18T01:33:40.114556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "working_dir = os.getcwd()w\n",
    "print(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ee9072",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-18T01:33:40.133208Z",
     "iopub.status.busy": "2025-05-18T01:33:40.132648Z",
     "iopub.status.idle": "2025-05-18T01:34:03.527493Z",
     "shell.execute_reply": "2025-05-18T01:34:03.526481Z"
    },
    "papermill": {
     "duration": 23.399682,
     "end_time": "2025-05-18T01:34:03.529122",
     "exception": false,
     "start_time": "2025-05-18T01:33:40.129440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/20242-deeplearning/* $working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a49cf9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T01:34:03.536308Z",
     "iopub.status.busy": "2025-05-18T01:34:03.536082Z",
     "iopub.status.idle": "2025-05-18T01:35:27.811383Z",
     "shell.execute_reply": "2025-05-18T01:35:27.810685Z"
    },
    "papermill": {
     "duration": 84.28046,
     "end_time": "2025-05-18T01:35:27.812811",
     "exception": false,
     "start_time": "2025-05-18T01:34:03.532351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hProcessing ./LSM-YOLO\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (3.7.2)\r\n",
      "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (1.26.4)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (4.11.0.86)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (11.1.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (1.15.2)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (4.67.1)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (2.2.3)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (0.12.2)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (7.0.0)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (9.0.0)\r\n",
      "Collecting thop>=0.1.1 (from lsmyolo==8.0.202)\r\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Collecting albumentations==1.3.1 (from lsmyolo==8.0.202)\r\n",
      "  Downloading albumentations-1.3.1-py3-none-any.whl.metadata (34 kB)\r\n",
      "Requirement already satisfied: pycocotools>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (2.0.8)\r\n",
      "Collecting timm==0.9.8 (from lsmyolo==8.0.202)\r\n",
      "  Downloading timm-0.9.8-py3-none-any.whl.metadata (59 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting efficientnet_pytorch==0.7.1 (from lsmyolo==8.0.202)\r\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from lsmyolo==8.0.202) (0.8.1)\r\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.3.1->lsmyolo==8.0.202) (0.25.2)\r\n",
      "Collecting qudida>=0.0.4 (from albumentations==1.3.1->lsmyolo==8.0.202)\r\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.3.1->lsmyolo==8.0.202) (4.11.0.86)\r\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from timm==0.9.8->lsmyolo==8.0.202) (0.31.1)\r\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm==0.9.8->lsmyolo==8.0.202) (0.5.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->lsmyolo==8.0.202) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->lsmyolo==8.0.202) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->lsmyolo==8.0.202) (4.57.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->lsmyolo==8.0.202) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->lsmyolo==8.0.202) (25.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->lsmyolo==8.0.202) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->lsmyolo==8.0.202) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.2->lsmyolo==8.0.202) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.2->lsmyolo==8.0.202) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.2->lsmyolo==8.0.202) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.2->lsmyolo==8.0.202) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.2->lsmyolo==8.0.202) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.2->lsmyolo==8.0.202) (2.4.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->lsmyolo==8.0.202) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->lsmyolo==8.0.202) (2025.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lsmyolo==8.0.202) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lsmyolo==8.0.202) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lsmyolo==8.0.202) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lsmyolo==8.0.202) (2025.4.26)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (4.13.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->lsmyolo==8.0.202) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->lsmyolo==8.0.202) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->lsmyolo==8.0.202) (1.17.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from qudida>=0.0.4->albumentations==1.3.1->lsmyolo==8.0.202) (1.2.2)\r\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->lsmyolo==8.0.202) (2.37.0)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->lsmyolo==8.0.202) (2025.3.30)\r\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->lsmyolo==8.0.202) (0.4)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.9.8->lsmyolo==8.0.202) (1.1.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->lsmyolo==8.0.202) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.2->lsmyolo==8.0.202) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.2->lsmyolo==8.0.202) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.2->lsmyolo==8.0.202) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.2->lsmyolo==8.0.202) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.2->lsmyolo==8.0.202) (2024.2.0)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1->lsmyolo==8.0.202) (1.5.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1->lsmyolo==8.0.202) (3.6.0)\r\n",
      "Downloading albumentations-1.3.1-py3-none-any.whl (125 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading timm-0.9.8-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\r\n",
      "Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\r\n",
      "Building wheels for collected packages: lsmyolo, efficientnet_pytorch\r\n",
      "  Building wheel for lsmyolo (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for lsmyolo: filename=lsmyolo-8.0.202-py3-none-any.whl size=327902 sha256=628607f0b1e17703f26987b1709861b6fafc3956f1ba145a19b7731f9e7b4843\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/a6/d9/fe/267ab4269a32d70fb66881f1b9c91a169146b328984e1f4423\r\n",
      "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16426 sha256=e841999d180fb732e0a9bc6a4fc012a052e27aefafc4ef59846038f2f65ed638\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/6f/9b/231a832f811ab6ebb1b32455b177ffc6b8b1cd8de19de70c09\r\n",
      "Successfully built lsmyolo efficientnet_pytorch\r\n",
      "Installing collected packages: thop, efficientnet_pytorch, qudida, timm, albumentations, lsmyolo\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 1.0.15\r\n",
      "    Uninstalling timm-1.0.15:\r\n",
      "      Successfully uninstalled timm-1.0.15\r\n",
      "  Attempting uninstall: albumentations\r\n",
      "    Found existing installation: albumentations 2.0.5\r\n",
      "    Uninstalling albumentations-2.0.5:\r\n",
      "      Successfully uninstalled albumentations-2.0.5\r\n",
      "Successfully installed albumentations-1.3.1 efficientnet_pytorch-0.7.1 lsmyolo-8.0.202 qudida-0.0.4 thop-0.1.1.post2209072238 timm-0.9.8\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q ultralytics\n",
    "!pip install $working_dir/LSM-YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b67acb12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T01:35:27.859367Z",
     "iopub.status.busy": "2025-05-18T01:35:27.859135Z",
     "iopub.status.idle": "2025-05-18T01:35:35.424087Z",
     "shell.execute_reply": "2025-05-18T01:35:35.423489Z"
    },
    "papermill": {
     "duration": 7.590061,
     "end_time": "2025-05-18T01:35:35.425457",
     "exception": false,
     "start_time": "2025-05-18T01:35:27.835396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Type hints and docstrings were generated by AI and reviewed by the author ngocanhh.---\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as tfs\n",
    "from PIL import Image\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Optional, Callable\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class for loading images and their corresponding annotations.\n",
    "\n",
    "    The dataset expects a directory structure where 'data_path' contains\n",
    "    two subdirectories: 'images' and 'labels'.\n",
    "    - 'images': Contains image files (e.g., .jpg, .png, .webp).\n",
    "    - 'labels': Contains annotation files (e.g., .txt) with the same base name\n",
    "                as their corresponding images. Each line in a label file\n",
    "                represents an object annotation in the format:\n",
    "                <class_id> <x_center_norm> <y_center_norm> <width_norm> <height_norm>\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path: str, transforms: Optional[Callable] = None):\n",
    "        \"\"\"\n",
    "        Initializes the CustomDataset.\n",
    "\n",
    "        Args:\n",
    "            data_path (str): The root path to the dataset directory.\n",
    "                             This directory should contain 'images' and 'labels' subfolders.\n",
    "            transforms (Optional[Callable]): A callable (e.g., torchvision.transforms.Compose)\n",
    "                                             to apply to the images. Defaults to None.\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If `data_path` does not exist.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(data_path):\n",
    "            raise FileNotFoundError(f'Path not found {data_path}')\n",
    "        self.data_path: str = data_path\n",
    "        self.image_dir: str = os.path.join(self.data_path, 'images')\n",
    "        self.label_dir: str = os.path.join(self.data_path, 'labels')\n",
    "        self.transforms: Optional[Callable] = transforms\n",
    "\n",
    "        # Prepare imgs, labels\n",
    "        self.images: List[str] = []\n",
    "        for f in os.listdir(self.image_dir):\n",
    "            if f.endswith(('.jpg', '.png', '.webp')):\n",
    "                self.images.append(f)\n",
    "        self.images.sort()\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the total number of images in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of images.\n",
    "        \"\"\"\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Retrieves an image and its annotations at the given index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor]:\n",
    "                - img (torch.Tensor): The transformed image tensor.\n",
    "                - annotations (torch.Tensor): A tensor of annotations.\n",
    "                  Each row is [class_id, x_center, y_center, width, height].\n",
    "                  If no annotations are found, an empty tensor of shape (0, 5)\n",
    "                  or similar (depending on `torch.tensor(annotations)`) is returned.\n",
    "                  If annotations exist, its shape is (num_annotations, 5).\n",
    "        \"\"\"\n",
    "        # Get image tensor\n",
    "        img_path: str = os.path.join(self.image_dir, self.images[idx])\n",
    "        img: Image.Image = Image.open(img_path).convert('RGB')\n",
    "        if self.transforms:\n",
    "            img_tensor: torch.Tensor = self.transforms(img)\n",
    "        else:\n",
    "            # If no transforms, convert to tensor manually (basic example)\n",
    "            img_tensor: torch.Tensor = tfs.ToTensor()(img)\n",
    "\n",
    "\n",
    "        # Get labels tensor\n",
    "        label_file_name: str = self.images[idx].split('.')[0] + '.txt'\n",
    "        label_path: str = os.path.join(self.label_dir, label_file_name)\n",
    "        annotations_list: List[List[float]] = []\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines: List[str] = f.readlines()\n",
    "            for line in lines:\n",
    "                anno: List[float] = list(map(float, line.split()))\n",
    "                if len(anno) == 5: # class_id, x_center, y_center, width, height\n",
    "                    annotations_list.append(anno)\n",
    "\n",
    "        # Ensure annotations tensor has 2 dimensions, even if empty.\n",
    "        # If annotations_list is empty, torch.tensor([]) creates a 1D tensor of size 0.\n",
    "        # We want (0, 5) for consistency if there are no annotations.\n",
    "        if not annotations_list:\n",
    "            annotations_tensor: torch.Tensor = torch.empty((0, 5), dtype=torch.float32)\n",
    "        else:\n",
    "            annotations_tensor: torch.Tensor = torch.tensor(annotations_list, dtype=torch.float32)\n",
    "\n",
    "        return img_tensor, annotations_tensor\n",
    "\n",
    "def custom_collate_fn(data_list: List[Tuple[torch.Tensor, torch.Tensor]]) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Custom collate function to process a batch of data from CustomDataset.\n",
    "\n",
    "    It combines images into a single tensor and organizes annotations into a\n",
    "    dictionary, mapping annotation components (batch_idx, cls, bboxes) to tensors.\n",
    "\n",
    "    Args:\n",
    "        data_list (List[Tuple[torch.Tensor, torch.Tensor]]):\n",
    "            A list of tuples, where each tuple contains:\n",
    "            - img (torch.Tensor): An image tensor.\n",
    "            - annotations (torch.Tensor): An annotation tensor of shape (N, 5)\n",
    "              where N is the number of objects in the image. Each row is\n",
    "              [class_id, x_center, y_center, width, height].\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "            - batch (Dict[str, torch.Tensor]): A dictionary containing:\n",
    "                - 'img' (torch.Tensor): A tensor of stacked images (B, C, H, W).\n",
    "                - 'batch_idx' (torch.Tensor): Tensor indicating the image index in the batch\n",
    "                                              for each bounding box. Shape (total_bboxes,).\n",
    "                - 'cls' (torch.Tensor): Tensor of class IDs for each bounding box.\n",
    "                                        Shape (total_bboxes,).\n",
    "                - 'bboxes' (torch.Tensor): Tensor of bounding boxes (x_center, y_center, width, height)\n",
    "                                           for all images in the batch. Shape (total_bboxes, 4).\n",
    "                                           If no bboxes in batch, shape is (0,4).\n",
    "    \"\"\"\n",
    "    imgs: List[torch.Tensor] = []\n",
    "    batch_index_list: List[int] = []\n",
    "    cls_list: List[float] = [] # Storing as float initially due to anno[0].item()\n",
    "    bboxes_list: List[torch.Tensor] = []\n",
    "\n",
    "    for i, (img, annotations) in enumerate(data_list):\n",
    "        imgs.append(img)\n",
    "        # annotations is expected to be (N, 5)\n",
    "        if annotations.numel() > 0: # Check if annotations tensor is not empty\n",
    "            for anno in annotations: # anno is a 1D tensor of shape (5,)\n",
    "                batch_index_list.append(i)\n",
    "                cls_list.append(anno[0].item()) # class_id\n",
    "                bboxes_list.append(anno[1:])    # bbox coordinates\n",
    "\n",
    "    batch: Dict[str, torch.Tensor] = {\n",
    "        'img': torch.stack(imgs, dim=0),\n",
    "        'batch_idx': torch.tensor(batch_index_list, dtype=torch.int64),\n",
    "        'cls': torch.tensor(cls_list, dtype=torch.int64), # Convert class IDs to int64\n",
    "        'bboxes': torch.empty((0, 4), dtype=torch.float32) if not bboxes_list else torch.stack(bboxes_list, dim=0)\n",
    "    }\n",
    "\n",
    "    return batch\n",
    "\n",
    "def get_dataloader(data_path: str,\n",
    "                   batch_size: int = 4,\n",
    "                   num_workers: int = 4,\n",
    "                   shuffle: bool = True) -> DataLoader:\n",
    "    \"\"\"\n",
    "    Creates and returns a DataLoader for the CustomDataset.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the dataset.\n",
    "        batch_size (int): Number of samples per batch. Defaults to 4.\n",
    "        num_workers (int): Number of subprocesses to use for data loading.\n",
    "                           Defaults to 4.\n",
    "        pin_memory (bool): If True, the data loader will copy Tensors\n",
    "                           into CUDA pinned memory before returning them.\n",
    "                           Defaults to True.\n",
    "        shuffle (bool): Whether to shuffle the data at every epoch. Defaults to True.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: A PyTorch DataLoader instance.\n",
    "    \"\"\"\n",
    "    transforms: tfs.Compose = tfs.Compose([\n",
    "        tfs.Resize((640, 640)),\n",
    "        tfs.ToTensor()\n",
    "    ])\n",
    "    dataset: CustomDataset = CustomDataset(data_path, transforms)\n",
    "\n",
    "    return DataLoader(dataset,\n",
    "                      batch_size=batch_size,\n",
    "                      num_workers=num_workers,\n",
    "                      pin_memory=False,\n",
    "                      shuffle=shuffle,\n",
    "                      collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b39007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebf27bac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T01:35:35.470904Z",
     "iopub.status.busy": "2025-05-18T01:35:35.470590Z",
     "iopub.status.idle": "2025-05-18T01:35:39.654442Z",
     "shell.execute_reply": "2025-05-18T01:35:39.653876Z"
    },
    "papermill": {
     "duration": 4.208116,
     "end_time": "2025-05-18T01:35:39.655831",
     "exception": false,
     "start_time": "2025-05-18T01:35:35.447715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ultralytics import YOLO as YOLO_ultra\n",
    "from lsmyolo import YOLO as YOLO_lsm\n",
    "import math\n",
    "import copy\n",
    "\n",
    "class KDModelConfig:\n",
    "    def __init__(self):\n",
    "        self.layers_name = ['head_p3', 'head_p4', 'head_p5', 'backbone_p3', 'backbone_p4', 'backbone_p5']\n",
    "        self.student_layers_idx = {\n",
    "            'head_p3': 21,\n",
    "            'head_p4': 24,\n",
    "            'head_p5': 27,\n",
    "            'backbone_p3': 4,\n",
    "            'backbone_p4': 6,\n",
    "            'backbone_p5': 9\n",
    "        }\n",
    "        self.teacher_layers_idx = {\n",
    "            'head_p3': 15,\n",
    "            'head_p4': 18,\n",
    "            'head_p5': 21,\n",
    "            'backbone_p3': 4,\n",
    "            'backbone_p4': 6,\n",
    "            'backbone_p5': 9\n",
    "        }\n",
    "        self.student_layers_output_channel = {\n",
    "            'head_p3': 64,\n",
    "            'head_p4': 128,\n",
    "            'head_p5': 256,\n",
    "            'backbone_p3': 64,\n",
    "            'backbone_p4': 128,\n",
    "            'backbone_p5': 256\n",
    "        }\n",
    "        self.teacher_layers_output_channel = {\n",
    "            'head_p3': 256,\n",
    "            'head_p4': 512,\n",
    "            'head_p5': 512,\n",
    "            'backbone_p3': 512,\n",
    "            'backbone_p4': 512,\n",
    "            'backbone_p5': 512\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, config_dict):\n",
    "        \"\"\"\n",
    "        Create a KDModelConfig instance from a dictionary\n",
    "\n",
    "        Args:\n",
    "            config_dict (dict): Dictionary containing configuration parameters\n",
    "\n",
    "        Returns:\n",
    "            KDModelConfig: A new instance with parameters from the dictionary\n",
    "        \"\"\"\n",
    "        config = cls()\n",
    "\n",
    "        # Update config with values from dictionary\n",
    "        if 'layers_name' in config_dict:\n",
    "            config.layers_name = config_dict['layers_name']\n",
    "\n",
    "        if 'student_layers_idx' in config_dict:\n",
    "            config.student_layers_idx = config_dict['student_layers_idx']\n",
    "\n",
    "        if 'teacher_layers_idx' in config_dict:\n",
    "            config.teacher_layers_idx = config_dict['teacher_layers_idx']\n",
    "\n",
    "        if 'student_layers_output_channel' in config_dict:\n",
    "            config.student_layers_output_channel = config_dict['student_layers_output_channel']\n",
    "\n",
    "        if 'teacher_layers_output_channel' in config_dict:\n",
    "            config.teacher_layers_output_channel = config_dict['teacher_layers_output_channel']\n",
    "\n",
    "        return config\n",
    "\n",
    "class FeatureExtractor():\n",
    "    def __init__(self):\n",
    "        self.features = {}\n",
    "\n",
    "    def get_hook(self, name):\n",
    "\n",
    "        def hook(module, input, output):\n",
    "            self.features[name] = output\n",
    "            # print(module.__class__.__name__)\n",
    "            # print(output.shape)\n",
    "\n",
    "        return hook\n",
    "\n",
    "    def clear(self):\n",
    "        self.features.clear()\n",
    "\n",
    "class HyperParams:\n",
    "    def __init__(self, hyp_dict):\n",
    "        # Set default values\n",
    "        self.box = 7.5  # Default YOLOv8 values\n",
    "        self.cls = 0.5\n",
    "        self.dfl = 1.5\n",
    "\n",
    "        # Update with any values from the dict\n",
    "        for key, value in hyp_dict.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "        # Ensure the hyp attribute exists\n",
    "        if not hasattr(self, 'hyp'):\n",
    "            self.hyp = self\n",
    "\n",
    "class Teacher(nn.Module):\n",
    "    def __init__(self, model, config):\n",
    "        super(Teacher, self).__init__()\n",
    "\n",
    "        # Get base model\n",
    "        yolo = YOLO_ultra(model)\n",
    "        self.model = yolo.model\n",
    "        self.config = config\n",
    "\n",
    "        # Feature extractor and register hooks\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        for layer_name in self.config.layers_name:\n",
    "            layer = self.model.model[self.config.teacher_layers_idx[layer_name]]\n",
    "            layer.register_forward_hook(self.feature_extractor.get_hook(layer_name))\n",
    "\n",
    "        # Get hyperparams\n",
    "        self.model.args = HyperParams(self.model.args)\n",
    "\n",
    "        # Get number of classes\n",
    "        self.nc = self.model.model[-1].nc\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.feature_extractor.clear()\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x, self.feature_extractor.features\n",
    "\n",
    "class Student(nn.Module):\n",
    "    def __init__(self, model, config):\n",
    "        super(Student, self).__init__()\n",
    "\n",
    "        # Get base model\n",
    "        self.yolo = YOLO_lsm(model)\n",
    "        self.model = self.yolo.model\n",
    "        self.config = config\n",
    "\n",
    "        # Feature extractor and register hooks\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        for layer_name in self.config.layers_name:\n",
    "            layer = self.model.model[self.config.student_layers_idx[layer_name]]\n",
    "            layer.register_forward_hook(self.feature_extractor.get_hook(layer_name))\n",
    "\n",
    "        # Get hyperparams\n",
    "        self.model.args = HyperParams(self.model.args)\n",
    "\n",
    "        # Get number of classes\n",
    "        self.nc = self.model.model[-1].nc\n",
    "\n",
    "    def eval(self):\n",
    "        self.training = False\n",
    "        self.model.eval()\n",
    "\n",
    "    def train(self):\n",
    "        self.training = True\n",
    "        self.model.train()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.feature_extractor.clear()\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x, self.feature_extractor.features\n",
    "\n",
    "class KD_Model(nn.Module):\n",
    "    def __init__(self, teacher_model, student_model, config=None):\n",
    "        super(KD_Model, self).__init__()\n",
    "        self.config = config if config is not None else KDModelConfig()\n",
    "        self.teacher = Teacher(teacher_model, self.config)\n",
    "        self.student = Student(student_model, self.config)\n",
    "\n",
    "        # Get number of classes\n",
    "        self.nc = self.student.nc\n",
    "        self.adapters = nn.ModuleDict()\n",
    "\n",
    "        for layer_name in self.config.layers_name:\n",
    "            adapter = nn.Conv2d(\n",
    "                self.config.student_layers_output_channel[layer_name],\n",
    "                self.config.teacher_layers_output_channel[layer_name],\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0\n",
    "            )\n",
    "\n",
    "            nn.init.kaiming_normal_(adapter.weight, a=math.sqrt(5))\n",
    "            if adapter.bias is not None:\n",
    "                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(adapter.weight)\n",
    "                if fan_in != 0: # Tránh chia cho 0\n",
    "                    bound = 1 / math.sqrt(fan_in)\n",
    "                    nn.init.uniform_(adapter.bias, -bound, bound)\n",
    "                else:\n",
    "                    nn.init.constant_(adapter.bias, 0) # Fallback\n",
    "\n",
    "            self.adapters[layer_name] = adapter\n",
    "\n",
    "\n",
    "    def eval(self):\n",
    "        # super(KD_Model, self).eval()\n",
    "        self.training = False\n",
    "        self.student.eval()\n",
    "        self.teacher.eval()\n",
    "        self.adapters.eval()\n",
    "\n",
    "    def train(self):\n",
    "        # super(KD_Model, self).train()\n",
    "        self.training = True\n",
    "        self.student.train()\n",
    "        self.adapters.train()\n",
    "        self.teacher.eval()\n",
    "\n",
    "    def val(self, data_yaml_path, project, name, split='val', save=True):\n",
    "        yolo_to_val = copy.deepcopy(self.student.yolo)\n",
    "        metrics = yolo_to_val.val(\n",
    "            data=data_yaml_path,\n",
    "            split=split,\n",
    "            save_json=False,\n",
    "            project=project,\n",
    "            name=name,\n",
    "            save=save, \n",
    "        )\n",
    "        return metrics\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            _, teacher_features = self.teacher(x)\n",
    "\n",
    "        student_output, original_student_features = self.student(x)\n",
    "\n",
    "        adapted_student_features = {}\n",
    "        for layer_name in self.config.layers_name:\n",
    "            adapted_student_features[layer_name] = self.adapters[layer_name](original_student_features[layer_name])\n",
    "            # print(student_features[layer_name].shape)\n",
    "        return student_output, adapted_student_features, teacher_features\n",
    "\n",
    "    def get_distillation_loss(self, adapted_student_features, teacher_features):\n",
    "        loss = 0\n",
    "        for layer_name in self.config.layers_name:\n",
    "            loss += F.mse_loss(adapted_student_features[layer_name], teacher_features[layer_name])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a3e252",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T01:35:39.701982Z",
     "iopub.status.busy": "2025-05-18T01:35:39.701630Z",
     "iopub.status.idle": "2025-05-18T01:35:39.708089Z",
     "shell.execute_reply": "2025-05-18T01:35:39.707376Z"
    },
    "papermill": {
     "duration": 0.030544,
     "end_time": "2025-05-18T01:35:39.709233",
     "exception": false,
     "start_time": "2025-05-18T01:35:39.678689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "v9c_to_lsm = {\n",
    "    'layers_name': ['head_p3', 'head_p4', 'head_p5', 'backbone_p3', 'backbone_p4', 'backbone_p5'],\n",
    "    'student_layers_idx': {\n",
    "            'head_p3': 21,\n",
    "            'head_p4': 24,\n",
    "            'head_p5': 27,\n",
    "            'backbone_p3': 4,\n",
    "            'backbone_p4': 6,\n",
    "            'backbone_p5': 9\n",
    "    },\n",
    "    'teacher_layers_idx': {\n",
    "            'head_p3': 15,\n",
    "            'head_p4': 18,\n",
    "            'head_p5': 21,\n",
    "            'backbone_p3': 4,\n",
    "            'backbone_p4': 6,\n",
    "            'backbone_p5': 9\n",
    "    },\n",
    "    'student_layers_output_channel': {\n",
    "            'head_p3': 64,\n",
    "            'head_p4': 128,\n",
    "            'head_p5': 256,\n",
    "            'backbone_p3': 64,\n",
    "            'backbone_p4': 128,\n",
    "            'backbone_p5': 256\n",
    "    },\n",
    "    'teacher_layers_output_channel': {\n",
    "            'head_p3': 256,\n",
    "            'head_p4': 512,\n",
    "            'head_p5': 512,\n",
    "            'backbone_p3': 512,\n",
    "            'backbone_p4': 512,\n",
    "            'backbone_p5': 512\n",
    "    }\n",
    "}\n",
    "\n",
    "v8s_to_lsm = {\n",
    "    'layers_name': ['head_p3', 'head_p4', 'head_p5', 'backbone_p3', 'backbone_p4', 'backbone_p5'],\n",
    "    'student_layers_idx': {\n",
    "            'head_p3': 21,\n",
    "            'head_p4': 24,\n",
    "            'head_p5': 27,\n",
    "            'backbone_p3': 4,\n",
    "            'backbone_p4': 6,\n",
    "            'backbone_p5': 9\n",
    "    },\n",
    "    'teacher_layers_idx': {\n",
    "            'head_p3': 15,\n",
    "            'head_p4': 18,\n",
    "            'head_p5': 21,\n",
    "            'backbone_p3': 4,\n",
    "            'backbone_p4': 6,\n",
    "            'backbone_p5': 9\n",
    "    },\n",
    "    'student_layers_output_channel': {\n",
    "            'head_p3': 64,\n",
    "            'head_p4': 128,\n",
    "            'head_p5': 256,\n",
    "            'backbone_p3': 64,\n",
    "            'backbone_p4': 128,\n",
    "            'backbone_p5': 256\n",
    "    },\n",
    "    'teacher_layers_output_channel': {\n",
    "            'head_p3': 128,\n",
    "            'head_p4': 256,\n",
    "            'head_p5': 512,\n",
    "            'backbone_p3': 128,\n",
    "            'backbone_p4': 256,\n",
    "            'backbone_p5': 512\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6944705",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T01:35:39.757156Z",
     "iopub.status.busy": "2025-05-18T01:35:39.756937Z",
     "iopub.status.idle": "2025-05-18T01:35:39.766456Z",
     "shell.execute_reply": "2025-05-18T01:35:39.765912Z"
    },
    "papermill": {
     "duration": 0.035117,
     "end_time": "2025-05-18T01:35:39.767475",
     "exception": false,
     "start_time": "2025-05-18T01:35:39.732358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from lsmyolo.utils.loss import v8DetectionLoss\n",
    "\n",
    "def evaluate(kd_model, val_dataloader, student_loss_fn, device, lambda_kd, epoch_num=-1, num_epochs=-1):\n",
    "    kd_model.eval()  # Đặt model ở chế độ evaluation\n",
    "    total_val_loss_epoch = 0\n",
    "    main_val_loss_epoch = 0\n",
    "    kd_val_loss_epoch = 0\n",
    "\n",
    "    # Tắt tính toán gradient cho quá trình evaluation\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(val_dataloader):\n",
    "            # Di chuyển dữ liệu sang device\n",
    "            for key in batch_data:\n",
    "                if isinstance(batch_data[key], torch.Tensor):\n",
    "                    batch_data[key] = batch_data[key].to(device)\n",
    "\n",
    "            images = batch_data['img']\n",
    "\n",
    "            # 1. Forward pass\n",
    "            # Giả định kd_model.forward() trả về (student_raw_output, student_features_adapted, teacher_features)\n",
    "            # ngay cả trong chế độ eval. Nếu teacher_features không có sẵn, nó nên là None.\n",
    "            student_raw_output_for_loss_fn, student_features_adapted, teacher_features = kd_model(images)\n",
    "\n",
    "            # 2. Tính main loss (hiệu suất của student)\n",
    "            main_loss_total, main_loss_components = student_loss_fn(student_raw_output_for_loss_fn, batch_data)\n",
    "            main_loss = main_loss_total / images.shape[0]  # Chuẩn hóa theo batch size\n",
    "\n",
    "            # 3. Tính distillation loss\n",
    "            distillation_loss = kd_model.get_distillation_loss(student_features_adapted, teacher_features)\n",
    "\n",
    "            # 4. Kết hợp loss\n",
    "            combined_loss = main_loss + lambda_kd * distillation_loss\n",
    "\n",
    "            # 5. Cộng dồn loss\n",
    "            total_val_loss_epoch += combined_loss.item()\n",
    "            main_val_loss_epoch += main_loss.item()\n",
    "            kd_val_loss_epoch += distillation_loss.item()\n",
    "\n",
    "            # if batch_idx % 10 == 0:  # In log mỗi 10 batch cho validation\n",
    "            #     box_l, cls_l, dfl_l = main_loss_components\n",
    "            #     epoch_str = f\"Epoch {epoch_num+1}/{num_epochs} | \" if epoch_num != -1 else \"\"\n",
    "            #     print(f\"{epoch_str}Validation Batch {batch_idx}/{len(val_dataloader)} | \"\n",
    "            #           f\"Total Val Loss: {combined_loss.item():.4f} | \"\n",
    "            #           f\"Main Val Loss: {main_loss.item():.4f} (Box: {box_l.item():.4f}, \"\n",
    "            #           f\"Cls: {cls_l.item():.4f}, DFL: {dfl_l.item():.4f}) | \"\n",
    "            #           f\"KD Val Loss: {distillation_loss.item():.4f}\")\n",
    "\n",
    "    avg_total_val_loss = total_val_loss_epoch / len(val_dataloader)\n",
    "    avg_main_val_loss = main_val_loss_epoch / len(val_dataloader)\n",
    "    avg_kd_val_loss = kd_val_loss_epoch / len(val_dataloader)\n",
    "\n",
    "    # epoch_str_summary = f\"Epoch {epoch_num+1} \" if epoch_num != -1 else \"\"\n",
    "    # print(f\"--- {epoch_str_summary}Validation Summary ---\")\n",
    "    # print(f\"Avg Total Validation Loss: {avg_total_val_loss:.4f}\")\n",
    "    # print(f\"Avg Main Validation Loss: {avg_main_val_loss:.4f}\")\n",
    "    # print(f\"Avg KD Validation Loss: {avg_kd_val_loss:.4f}\")\n",
    "\n",
    "    return avg_total_val_loss, avg_main_val_loss, avg_kd_val_loss\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(kd_model, student_loss_fn, optimizer, dataloader, device, lambda_kd, epoch_num, num_epochs):\n",
    "    kd_model.train()\n",
    "    total_loss_epoch = 0\n",
    "    main_loss_epoch = 0\n",
    "    kd_loss_epoch = 0\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(dataloader):\n",
    "        # Move data to device\n",
    "        for key in batch_data:\n",
    "            if isinstance(batch_data[key], torch.Tensor):\n",
    "                batch_data[key] = batch_data[key].to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        images = batch_data['img']\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        student_raw_output_for_loss_fn, student_features_adapted, teacher_features = kd_model(images)\n",
    "\n",
    "        # 2. Calculate main loss\n",
    "        main_loss_total, main_loss_components = student_loss_fn(student_raw_output_for_loss_fn, batch_data)\n",
    "        # Main loss is calculated with hyp gains (box, cls, dfl), components are detached and not scaled by hyp\n",
    "        main_loss = main_loss_total / images.shape[0] # Normalize by batch size\n",
    "\n",
    "        # 3. Calculate distillation loss\n",
    "        distillation_loss = kd_model.get_distillation_loss(student_features_adapted, teacher_features)\n",
    "\n",
    "        # 4. Combine loss\n",
    "        combined_loss = main_loss + lambda_kd * distillation_loss\n",
    "\n",
    "        # 5. Backward pass\n",
    "        combined_loss.backward()\n",
    "\n",
    "        # 6. Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # 7. Log loss\n",
    "        total_loss_epoch += combined_loss.item()\n",
    "        main_loss_epoch += main_loss.item()\n",
    "        kd_loss_epoch += distillation_loss.item()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            box_l, cls_l, dfl_l = main_loss_components\n",
    "            # print(f\"Epoch {epoch_num+1}/{num_epochs} | Batch {batch_idx}/{len(dataloader)} | \"\n",
    "            #       f\"Total Loss: {combined_loss.item():.4f} | \"\n",
    "            #       f\"Main Loss (avg): {main_loss.item():.4f} (Box: {box_l.item():.4f}, \"\n",
    "            #       f\"Cls: {cls_l.item():.4f}, DFL: {dfl_l.item():.4f}) | \"\n",
    "            #       f\"KD Loss: {distillation_loss.item():.4f}\")\n",
    "\n",
    "    avg_total_loss = total_loss_epoch / len(dataloader)\n",
    "    avg_main_loss = main_loss_epoch / len(dataloader)\n",
    "    avg_kd_loss = kd_loss_epoch / len(dataloader)\n",
    "    # print(f\"--- Epoch {epoch_num+1} Summary ---\")\n",
    "    # print(f\"Avg Total Loss: {avg_total_loss:.4f}\")\n",
    "    # print(f\"Avg Main Loss: {avg_main_loss:.4f}\")\n",
    "    # print(f\"Avg KD Loss: {avg_kd_loss:.4f}\")\n",
    "    return avg_total_loss, avg_main_loss, avg_kd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce9a665a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T01:35:39.813902Z",
     "iopub.status.busy": "2025-05-18T01:35:39.813639Z",
     "iopub.status.idle": "2025-05-18T01:35:44.542482Z",
     "shell.execute_reply": "2025-05-18T01:35:44.541635Z"
    },
    "papermill": {
     "duration": 4.753182,
     "end_time": "2025-05-18T01:35:44.543705",
     "exception": false,
     "start_time": "2025-05-18T01:35:39.790523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ no model scale passed. Assuming scale='n'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       788  lsmyolo.nn.modules.RFAConv.RFAConv           [3, 16, 3, 2]                 \n",
      "  1                  -1  1      6400  lsmyolo.nn.modules.RFAConv.RFAConv           [16, 32, 3, 2]                \n",
      "  2                  -1  1      8736  lsmyolo.nn.modules.block.MSFM                [32, 32, 1, True]             \n",
      "  3                  -1  1     19776  lsmyolo.nn.modules.block.LAE                 [32]                          \n",
      "  4                  -1  2     58240  lsmyolo.nn.modules.block.MSFM                [32, 64, 2, True]             \n",
      "  5                  -1  1     41600  lsmyolo.nn.modules.block.LAE                 [64]                          \n",
      "  6                  -1  2    231168  lsmyolo.nn.modules.block.MSFM                [64, 128, 2, True]            \n",
      "  7                  -1  1     91392  lsmyolo.nn.modules.block.LAE                 [128]                         \n",
      "  8                  -1  1    510208  lsmyolo.nn.modules.block.MSFM                [128, 256, 1, True]           \n",
      "  9                  -1  1    164608  lsmyolo.nn.modules.block.SPPF                [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  lsmyolo.nn.modules.conv.Concat               [1]                           \n",
      " 12                  -1  1    169088  lsmyolo.nn.modules.block.MSFM                [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  lsmyolo.nn.modules.conv.Concat               [1]                           \n",
      " 15                  -1  1     42560  lsmyolo.nn.modules.block.MSFM                [192, 64, 1]                  \n",
      " 16                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 17             [-1, 2]  1         0  lsmyolo.nn.modules.conv.Concat               [1]                           \n",
      " 18                  -1  1     10784  lsmyolo.nn.modules.block.MSFM                [96, 32, 1]                   \n",
      " 19                  -1  1     19776  lsmyolo.nn.modules.block.LAE                 [32]                          \n",
      " 20            [-1, 15]  1         0  lsmyolo.nn.modules.conv.Concat               [1]                           \n",
      " 21                  -1  1     36416  lsmyolo.nn.modules.block.MSFM                [96, 64, 1]                   \n",
      " 22                  -1  1     41600  lsmyolo.nn.modules.block.LAE                 [64]                          \n",
      " 23            [-1, 12]  1         0  lsmyolo.nn.modules.conv.Concat               [1]                           \n",
      " 24                  -1  1    144512  lsmyolo.nn.modules.block.MSFM                [192, 128, 1]                 \n",
      " 25                  -1  1     91392  lsmyolo.nn.modules.block.LAE                 [128]                         \n",
      " 26             [-1, 9]  1         0  lsmyolo.nn.modules.conv.Concat               [1]                           \n",
      " 27                  -1  1    575744  lsmyolo.nn.modules.block.MSFM                [384, 256, 1]                 \n",
      " 28    [18, 21, 24, 27]  1    617364  lsmyolo.nn.modules.head.Detect               [1, [32, 64, 128, 256]]       \n",
      "LSM-YOLO summary: 503 layers, 2882152 parameters, 2882136 gradients, 12.6 GFLOPs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized v8DetectionLoss for student model.\n",
      "Building AdamW optimizer for student model: DetectionModel\n",
      "Optimizer: AdamW(lr=0.001, betas=(0.9,0.999)) with parameter groups:\n",
      "  - Group 0 (Main Weights): 124 params, weight_decay=1e-05\n",
      "  - Group 1 (BN Weights/logit_scale): 114 params, weight_decay=0.0\n",
      "  - Group 2 (Biases): 122 params, weight_decay=0.0\n",
      "Adding adapter parameters to the AdamW optimizer.\n",
      "  - Group Adapters: 12 params, weight_decay=1e-05, lr=0.001\n"
     ]
    }
   ],
   "source": [
    "# 1. Set device\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Setup model\n",
    "model_name = 'yolov8n_best.pt'\n",
    "teacher_model_path = os.path.join(working_dir, 'pretrained_model', model_name)\n",
    "student_model_cfg_path = 'LSM-YOLO/LSM-YOLO.yaml'\n",
    "config = KDModelConfig.from_dict(v8s_to_lsm)\n",
    "kd_model = KD_Model(teacher_model_path, student_model_cfg_path, config)\n",
    "\n",
    "# # 2.1. Check multi-gpu\n",
    "# if torch.cuda.device_count() > 1 and device == torch.device('cuda'):\n",
    "#     print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "#     kd_model = torch.nn.DataParallel(kd_model)\n",
    "\n",
    "kd_model.to(device)\n",
    "\n",
    "# 3. Setup loss fn\n",
    "try:\n",
    "    # v8DetectionLoss need an instance of ultralytics.nn.tasks.DectectionModel as parameter\n",
    "    student_loss_fn = v8DetectionLoss(kd_model.student.model)\n",
    "    print(\"Successfully initialized v8DetectionLoss for student model.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing student_loss_fn (v8DetectionLoss): {e}\")\n",
    "    print(\"Please ensure that:\")\n",
    "    print(\"1. `kd_model.student.model` is the correct LSM-YOLO model object (e.g., instance of DetectionModel).\")\n",
    "    print(\"2. The student model has a `model[-1]` (Detect layer) with `stride`, `nc`, `reg_max` attributes.\")\n",
    "    print(\"3. The student model has an `args` attribute (or `hyp`) containing hyperparameters like `box`, `cls`, `dfl` gains.\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# 4. Setup optimizer\n",
    "student_model_to_optimize = kd_model.student.model\n",
    "\n",
    "# Hyperparameters cho AdamW theo kiểu Ultralytics (giá trị mặc định/phổ biến)\n",
    "lr = 0.001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "default_weight_decay = 1e-5 # Sẽ áp dụng cho nhóm g0\n",
    "\n",
    "print(f\"Building AdamW optimizer for student model: {type(student_model_to_optimize).__name__}\")\n",
    "\n",
    "g0, g1, g2 = [], [], []  # optimizer parameter groups\n",
    "bn = tuple(v for k, v in nn.__dict__.items() if \"Norm\" in k)  # normalization layers\n",
    "\n",
    "for module_name, module in student_model_to_optimize.named_modules():\n",
    "    for param_name, param in module.named_parameters(recurse=False):\n",
    "        if not param.requires_grad:\n",
    "            continue\n",
    "        fullname = f\"{module_name}.{param_name}\" if module_name else param_name\n",
    "        if \"bias\" in fullname:\n",
    "            g2.append(param)  # Biases\n",
    "        elif isinstance(module, bn) or \"logit_scale\" in fullname:\n",
    "            g1.append(param)  # BatchNorm weights, logit_scale\n",
    "        else:\n",
    "            g0.append(param)  # Other weights\n",
    "\n",
    "# Khởi tạo AdamW\n",
    "# Nhóm g2 (biases) được truyền vào constructor với weight_decay=0.0\n",
    "optimizer = optim.AdamW(g2, lr=lr, betas=(beta1, beta2), weight_decay=0.0)\n",
    "\n",
    "# Thêm nhóm g0 (weights chính) với weight_decay đã định nghĩa\n",
    "optimizer.add_param_group({\"params\": g0, \"weight_decay\": default_weight_decay})\n",
    "\n",
    "# Thêm nhóm g1 (BatchNorm weights, etc.) với weight_decay=0.0\n",
    "optimizer.add_param_group({\"params\": g1, \"weight_decay\": 0.0})\n",
    "\n",
    "print(\n",
    "    f\"Optimizer: AdamW(lr={lr}, betas=({beta1},{beta2})) with parameter groups:\\n\"\n",
    "    f\"  - Group 0 (Main Weights): {len(g0)} params, weight_decay={default_weight_decay}\\n\"\n",
    "    f\"  - Group 1 (BN Weights/logit_scale): {len(g1)} params, weight_decay=0.0\\n\"\n",
    "    f\"  - Group 2 (Biases): {len(g2)} params, weight_decay=0.0\"\n",
    ")\n",
    "\n",
    "# Thêm tham số của adapters vào optimizer\n",
    "if hasattr(kd_model, 'adapters') and list(kd_model.adapters.parameters()):\n",
    "    adapter_params = list(kd_model.adapters.parameters())\n",
    "    if adapter_params:\n",
    "        print(f\"Adding adapter parameters to the AdamW optimizer.\")\n",
    "        adapter_weight_decay = default_weight_decay \n",
    "        adapter_lr = lr\n",
    "        optimizer.add_param_group({\n",
    "            \"params\": adapter_params,\n",
    "            \"weight_decay\": adapter_weight_decay,\n",
    "            \"lr\": adapter_lr,\n",
    "            \"name\": \"adapters\" \n",
    "        })\n",
    "        print(f\"  - Group Adapters: {len(adapter_params)} params, weight_decay={adapter_weight_decay}, lr={adapter_lr}\")\n",
    "    else:\n",
    "        print(\"No trainable parameters found in kd_model.adapters.\")\n",
    "else:\n",
    "    print(\"kd_model.adapters not found or has no parameters.\")\n",
    "\n",
    "# params_to_optimize = [\n",
    "#     {'params': kd_model.student.parameters()},\n",
    "#     {'params': kd_model.adapters.parameters()},\n",
    "# ]\n",
    "# optimizer = optim.AdamW(params_to_optimize, lr=5e-4)\n",
    "\n",
    "# 5. Set dataloader\n",
    "data_dir = os.path.join(working_dir, 'Br35H-Mask-Prepared')\n",
    "train_data_dir = os.path.join(data_dir, 'train')\n",
    "val_data_dir = os.path.join(data_dir, 'val')\n",
    "data_yaml_path = os.path.join(data_dir, 'data.yaml')\n",
    "batch_size = 16\n",
    "num_workers = 2\n",
    "train_dataloader = get_dataloader(train_data_dir, batch_size, num_workers)\n",
    "val_dataloader = get_dataloader(val_data_dir, batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc26ce7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T01:35:44.591088Z",
     "iopub.status.busy": "2025-05-18T01:35:44.590824Z",
     "iopub.status.idle": "2025-05-18T10:47:58.527202Z",
     "shell.execute_reply": "2025-05-18T10:47:58.525991Z"
    },
    "papermill": {
     "duration": 33133.961117,
     "end_time": "2025-05-18T10:47:58.528480",
     "exception": false,
     "start_time": "2025-05-18T01:35:44.567363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** START TRAINING WITH 300 EPOCHS, KD yolov8n_best.pt, LAMBDA_KD 3\n",
      "-------------------- EPOCH 1 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 15.59426754335814\n",
      "\tMAIN_LOSS: 12.899992037423049\n",
      "\tKD_LOSS: 0.898091854928415\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 15.241217295328775\n",
      "\tMAIN_LOSS: 13.095138708750406\n",
      "\tKD_LOSS: 0.7153595263759295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100%|██████████| 755k/755k [00:00<00:00, 17.7MB/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<00:00, 2000.15it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/Br35H-Mask-Prepared/val/labels.cache\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:09<00:00,  1.25it/s]\n",
      "                   all        376        181   0.000589      0.287   0.000536    0.00016\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 17.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: New best mAP: 0.0002, model saved.\n",
      "-------------------- EPOCH 1 END --------------------\n",
      "-------------------- EPOCH 2 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 12.316650125044811\n",
      "\tMAIN_LOSS: 10.420361180848714\n",
      "\tKD_LOSS: 0.6320963154865217\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 12.491517265637716\n",
      "\tMAIN_LOSS: 10.442134221394857\n",
      "\tKD_LOSS: 0.6831276789307594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.40it/s]\n",
      "                   all        376        181    0.00151      0.492     0.0162    0.00478\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: New best mAP: 0.0048, model saved.\n",
      "-------------------- EPOCH 2 END --------------------\n",
      "-------------------- EPOCH 3 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 11.107416744473614\n",
      "\tMAIN_LOSS: 9.390781571593466\n",
      "\tKD_LOSS: 0.5722117307065409\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 11.326274593671164\n",
      "\tMAIN_LOSS: 9.599076867103577\n",
      "\tKD_LOSS: 0.5757325937350591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181    0.00226      0.536     0.0941     0.0289\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: New best mAP: 0.0289, model saved.\n",
      "-------------------- EPOCH 3 END --------------------\n",
      "-------------------- EPOCH 4 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 10.590548515319824\n",
      "\tMAIN_LOSS: 8.98556633237042\n",
      "\tKD_LOSS: 0.5349940755699254\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 11.645959973335266\n",
      "\tMAIN_LOSS: 9.654433727264404\n",
      "\tKD_LOSS: 0.6638420969247818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.40it/s]\n",
      "                   all        376        181     0.0867      0.182      0.049     0.0161\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 4 END --------------------\n",
      "-------------------- EPOCH 5 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 9.861418687844578\n",
      "\tMAIN_LOSS: 8.338327462160134\n",
      "\tKD_LOSS: 0.5076970808868166\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 13.788251399993896\n",
      "\tMAIN_LOSS: 11.909088015556335\n",
      "\tKD_LOSS: 0.6263877662519614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181     0.0816      0.232       0.04     0.0135\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 5 END --------------------\n",
      "-------------------- EPOCH 6 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 9.29403861564926\n",
      "\tMAIN_LOSS: 7.811424738244165\n",
      "\tKD_LOSS: 0.4942046302028849\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 9.395620544751486\n",
      "\tMAIN_LOSS: 7.884124477704366\n",
      "\tKD_LOSS: 0.5038319776455561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181      0.447      0.343      0.342      0.109\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: New best mAP: 0.1095, model saved.\n",
      "-------------------- EPOCH 6 END --------------------\n",
      "-------------------- EPOCH 7 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 9.016200192366973\n",
      "\tMAIN_LOSS: 7.562074981158292\n",
      "\tKD_LOSS: 0.48470840423921996\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 9.078683455785116\n",
      "\tMAIN_LOSS: 7.4986625512441\n",
      "\tKD_LOSS: 0.5266736211876074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.523      0.431      0.401      0.149\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: New best mAP: 0.1485, model saved.\n",
      "-------------------- EPOCH 7 END --------------------\n",
      "-------------------- EPOCH 8 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 8.29080240032341\n",
      "\tMAIN_LOSS: 6.885422374628767\n",
      "\tKD_LOSS: 0.4684599947325791\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 8.65201630194982\n",
      "\tMAIN_LOSS: 7.205700000127156\n",
      "\tKD_LOSS: 0.48210544635852176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.469      0.474      0.391      0.147\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 8 END --------------------\n",
      "-------------------- EPOCH 9 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 7.555525200276435\n",
      "\tMAIN_LOSS: 6.191751860365083\n",
      "\tKD_LOSS: 0.4545911128007913\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 8.084715982278189\n",
      "\tMAIN_LOSS: 6.666765034198761\n",
      "\tKD_LOSS: 0.47265032306313515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.692      0.503       0.56      0.269\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.8ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: New best mAP: 0.2693, model saved.\n",
      "-------------------- EPOCH 9 END --------------------\n",
      "-------------------- EPOCH 10 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 7.161391330670707\n",
      "\tMAIN_LOSS: 5.825187248519704\n",
      "\tKD_LOSS: 0.44540135430384287\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 7.395600577195485\n",
      "\tMAIN_LOSS: 6.010024785995483\n",
      "\tKD_LOSS: 0.4618585954109828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.632      0.456      0.514      0.253\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch10\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 10 END --------------------\n",
      "-------------------- EPOCH 11 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 6.238925161240976\n",
      "\tMAIN_LOSS: 4.942924831486955\n",
      "\tKD_LOSS: 0.43200011004375505\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 6.742232342561086\n",
      "\tMAIN_LOSS: 5.461742242177327\n",
      "\tKD_LOSS: 0.42683002228538197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.713      0.618      0.661      0.373\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.6ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch11\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: New best mAP: 0.3730, model saved.\n",
      "-------------------- EPOCH 11 END --------------------\n",
      "-------------------- EPOCH 12 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 5.7186022287682645\n",
      "\tMAIN_LOSS: 4.449458188648466\n",
      "\tKD_LOSS: 0.4230480201636689\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 6.695407609144847\n",
      "\tMAIN_LOSS: 5.377615948518117\n",
      "\tKD_LOSS: 0.43926388397812843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.657      0.536      0.618      0.348\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch12\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 12 END --------------------\n",
      "-------------------- EPOCH 13 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 5.458320768573616\n",
      "\tMAIN_LOSS: 4.208160804796822\n",
      "\tKD_LOSS: 0.41671998666811594\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 6.33990091085434\n",
      "\tMAIN_LOSS: 5.0194153388341265\n",
      "\tKD_LOSS: 0.4401618614792824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.728      0.552      0.612      0.376\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch13\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: New best mAP: 0.3758, model saved.\n",
      "-------------------- EPOCH 13 END --------------------\n",
      "-------------------- EPOCH 14 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 5.033833425256271\n",
      "\tMAIN_LOSS: 3.8131538010850736\n",
      "\tKD_LOSS: 0.4068932080570656\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.973801612854004\n",
      "\tMAIN_LOSS: 4.694401403268178\n",
      "\tKD_LOSS: 0.42646673570076626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.867      0.685      0.761      0.454\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch14\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: New best mAP: 0.4537, model saved.\n",
      "-------------------- EPOCH 14 END --------------------\n",
      "-------------------- EPOCH 15 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 4.923166631143304\n",
      "\tMAIN_LOSS: 3.7206191292291955\n",
      "\tKD_LOSS: 0.4008491688136813\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.923094809055328\n",
      "\tMAIN_LOSS: 4.704565405845642\n",
      "\tKD_LOSS: 0.40617647518714267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.924      0.669      0.776      0.455\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch15\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: New best mAP: 0.4549, model saved.\n",
      "-------------------- EPOCH 15 END --------------------\n",
      "-------------------- EPOCH 16 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 4.706483255458783\n",
      "\tMAIN_LOSS: 3.5075226554387733\n",
      "\tKD_LOSS: 0.3996535335914998\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.8976032336552935\n",
      "\tMAIN_LOSS: 4.6589013040065765\n",
      "\tKD_LOSS: 0.4129006552199523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.879      0.684      0.759      0.472\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch16\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: New best mAP: 0.4718, model saved.\n",
      "-------------------- EPOCH 16 END --------------------\n",
      "-------------------- EPOCH 17 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 4.232370889639553\n",
      "\tMAIN_LOSS: 3.0803569872168044\n",
      "\tKD_LOSS: 0.38400463854210287\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 6.1217966477076216\n",
      "\tMAIN_LOSS: 4.925103187561035\n",
      "\tKD_LOSS: 0.39889781425396603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.811      0.641       0.74      0.451\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch17\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 17 END --------------------\n",
      "-------------------- EPOCH 18 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 4.272451947006998\n",
      "\tMAIN_LOSS: 3.1175387282914753\n",
      "\tKD_LOSS: 0.38497107919258405\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 7.4446737964948015\n",
      "\tMAIN_LOSS: 5.954111615816752\n",
      "\tKD_LOSS: 0.4968540407717228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.483      0.541      0.495      0.233\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch18\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 18 END --------------------\n",
      "-------------------- EPOCH 19 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 4.688473016400881\n",
      "\tMAIN_LOSS: 3.4693601010720942\n",
      "\tKD_LOSS: 0.4063709597044353\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.7259518802165985\n",
      "\tMAIN_LOSS: 4.479633043209712\n",
      "\tKD_LOSS: 0.4154396007458369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.861      0.729      0.783      0.475\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch19\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: New best mAP: 0.4746, model saved.\n",
      "-------------------- EPOCH 19 END --------------------\n",
      "-------------------- EPOCH 20 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 4.138295747056792\n",
      "\tMAIN_LOSS: 2.99291081066373\n",
      "\tKD_LOSS: 0.3817949864683272\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.3004118005434675\n",
      "\tMAIN_LOSS: 4.144979437192281\n",
      "\tKD_LOSS: 0.38514412691195804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.851       0.74      0.791      0.502\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch20\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: New best mAP: 0.5022, model saved.\n",
      "-------------------- EPOCH 20 END --------------------\n",
      "-------------------- EPOCH 21 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 3.95783841459057\n",
      "\tMAIN_LOSS: 2.8455539308016813\n",
      "\tKD_LOSS: 0.37076149069810216\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.174184739589691\n",
      "\tMAIN_LOSS: 4.037536422411601\n",
      "\tKD_LOSS: 0.3788827570776145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.865      0.724       0.79      0.521\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.8ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch21\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: New best mAP: 0.5209, model saved.\n",
      "-------------------- EPOCH 21 END --------------------\n",
      "-------------------- EPOCH 22 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 3.760465006285076\n",
      "\tMAIN_LOSS: 2.6665523293652114\n",
      "\tKD_LOSS: 0.3646375627457341\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.0773466030756635\n",
      "\tMAIN_LOSS: 3.972451408704122\n",
      "\tKD_LOSS: 0.3682983952263991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.839      0.775      0.809      0.529\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch22\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: New best mAP: 0.5288, model saved.\n",
      "-------------------- EPOCH 22 END --------------------\n",
      "-------------------- EPOCH 23 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 3.623008124436004\n",
      "\tMAIN_LOSS: 2.5445538050011742\n",
      "\tKD_LOSS: 0.3594847717617132\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.178357909123103\n",
      "\tMAIN_LOSS: 4.08194042245547\n",
      "\tKD_LOSS: 0.3654725005229314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.894      0.742       0.82      0.512\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch23\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 23 END --------------------\n",
      "-------------------- EPOCH 24 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 3.621293985390965\n",
      "\tMAIN_LOSS: 2.5502849258954012\n",
      "\tKD_LOSS: 0.3570030165624015\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.024024625619252\n",
      "\tMAIN_LOSS: 3.9400611023108163\n",
      "\tKD_LOSS: 0.3613211587071419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181       0.88      0.702      0.807      0.518\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch24\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 24 END --------------------\n",
      "-------------------- EPOCH 25 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 3.471521323240256\n",
      "\tMAIN_LOSS: 2.411292821546144\n",
      "\tKD_LOSS: 0.35340949553477613\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.155325045188268\n",
      "\tMAIN_LOSS: 4.08083380262057\n",
      "\tKD_LOSS: 0.3581637529035409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.854       0.71      0.797      0.526\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch25\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 25 END --------------------\n",
      "-------------------- EPOCH 26 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 3.4142421981956383\n",
      "\tMAIN_LOSS: 2.3666102840930603\n",
      "\tKD_LOSS: 0.34921063652521445\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.232114275296529\n",
      "\tMAIN_LOSS: 4.059316883484523\n",
      "\tKD_LOSS: 0.39093246931831044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181       0.89      0.713      0.782      0.508\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch26\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 26 END --------------------\n",
      "-------------------- EPOCH 27 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 3.392547196979764\n",
      "\tMAIN_LOSS: 2.351260452330867\n",
      "\tKD_LOSS: 0.3470955789089203\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.075500766436259\n",
      "\tMAIN_LOSS: 4.001242299874623\n",
      "\tKD_LOSS: 0.3580861526230971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.40it/s]\n",
      "                   all        376        181      0.908      0.713      0.783      0.515\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch27\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 27 END --------------------\n",
      "-------------------- EPOCH 28 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 3.3665825928313824\n",
      "\tMAIN_LOSS: 2.3267070356803603\n",
      "\tKD_LOSS: 0.3466251858427555\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.070733467737834\n",
      "\tMAIN_LOSS: 4.012211759885152\n",
      "\tKD_LOSS: 0.35284057383735973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.904      0.679      0.792      0.529\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch28\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: New best mAP: 0.5295, model saved.\n",
      "-------------------- EPOCH 28 END --------------------\n",
      "-------------------- EPOCH 29 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 3.304067038282563\n",
      "\tMAIN_LOSS: 2.282495214969297\n",
      "\tKD_LOSS: 0.3405239453798608\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.228691866000493\n",
      "\tMAIN_LOSS: 4.170063475767772\n",
      "\tKD_LOSS: 0.3528761441508929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.951      0.608      0.758      0.503\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.8ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch29\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 29 END --------------------\n",
      "-------------------- EPOCH 30 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 3.1625000796740568\n",
      "\tMAIN_LOSS: 2.1540051155452486\n",
      "\tKD_LOSS: 0.33616498867167705\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.109874347845714\n",
      "\tMAIN_LOSS: 4.084659695625305\n",
      "\tKD_LOSS: 0.3417382376889388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.915      0.718      0.824      0.552\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch30\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: New best mAP: 0.5522, model saved.\n",
      "-------------------- EPOCH 30 END --------------------\n",
      "-------------------- EPOCH 31 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 3.110950165157077\n",
      "\tMAIN_LOSS: 2.110696905775915\n",
      "\tKD_LOSS: 0.3334177513665791\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.95588939388593\n",
      "\tMAIN_LOSS: 3.921128044525782\n",
      "\tKD_LOSS: 0.34492044523358345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.824      0.748      0.799      0.537\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch31\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 31 END --------------------\n",
      "-------------------- EPOCH 32 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 3.0861842994448505\n",
      "\tMAIN_LOSS: 2.093587089188491\n",
      "\tKD_LOSS: 0.3308657351173932\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.81805020570755\n",
      "\tMAIN_LOSS: 3.80765766898791\n",
      "\tKD_LOSS: 0.3367975155512492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.959      0.707       0.81      0.531\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch32\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 32 END --------------------\n",
      "-------------------- EPOCH 33 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.9578373130363755\n",
      "\tMAIN_LOSS: 1.9801164201543302\n",
      "\tKD_LOSS: 0.32590696064731745\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.955806503693263\n",
      "\tMAIN_LOSS: 3.945536414782206\n",
      "\tKD_LOSS: 0.33675671244661015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.846      0.718      0.794      0.512\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch33\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 33 END --------------------\n",
      "-------------------- EPOCH 34 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.9824737355678894\n",
      "\tMAIN_LOSS: 2.0110263054883935\n",
      "\tKD_LOSS: 0.32381581279295907\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.086854537328084\n",
      "\tMAIN_LOSS: 4.0754395723342896\n",
      "\tKD_LOSS: 0.3371383150418599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.935       0.71       0.82      0.534\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch34\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 34 END --------------------\n",
      "-------------------- EPOCH 35 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.9788256144221825\n",
      "\tMAIN_LOSS: 2.0150732149051716\n",
      "\tKD_LOSS: 0.32125080688090263\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.912209292252858\n",
      "\tMAIN_LOSS: 3.8884051938851676\n",
      "\tKD_LOSS: 0.34126803899804753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.869      0.718      0.791      0.534\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch35\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 35 END --------------------\n",
      "-------------------- EPOCH 36 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.9758261909967736\n",
      "\tMAIN_LOSS: 2.019125452524499\n",
      "\tKD_LOSS: 0.31890024339096457\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.99422440926234\n",
      "\tMAIN_LOSS: 4.006336609522502\n",
      "\tKD_LOSS: 0.32929593821366626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.847      0.685      0.782       0.49\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch36\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 36 END --------------------\n",
      "-------------------- EPOCH 37 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.869973279252837\n",
      "\tMAIN_LOSS: 1.9239753771431838\n",
      "\tKD_LOSS: 0.31533263378505466\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.730258186658223\n",
      "\tMAIN_LOSS: 3.7456742028395333\n",
      "\tKD_LOSS: 0.3281946542362372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.822       0.79      0.812      0.547\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch37\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 37 END --------------------\n",
      "-------------------- EPOCH 38 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.809727691396882\n",
      "\tMAIN_LOSS: 1.8721972477586963\n",
      "\tKD_LOSS: 0.31251014901112906\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.727656831343968\n",
      "\tMAIN_LOSS: 3.7509538928667703\n",
      "\tKD_LOSS: 0.32556764284769696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.936       0.73      0.823      0.548\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch38\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 38 END --------------------\n",
      "-------------------- EPOCH 39 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.821709328059909\n",
      "\tMAIN_LOSS: 1.8885602996319155\n",
      "\tKD_LOSS: 0.31104968016660667\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.643013149499893\n",
      "\tMAIN_LOSS: 3.679816355307897\n",
      "\tKD_LOSS: 0.32106559723615646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.928      0.691       0.81      0.554\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch39\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: New best mAP: 0.5544, model saved.\n",
      "-------------------- EPOCH 39 END --------------------\n",
      "-------------------- EPOCH 40 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.8113897782337816\n",
      "\tMAIN_LOSS: 1.8836539199080649\n",
      "\tKD_LOSS: 0.30924528384510475\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.970606605211894\n",
      "\tMAIN_LOSS: 4.008232434590657\n",
      "\tKD_LOSS: 0.3207913798590501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.904      0.731       0.82      0.559\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch40\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: New best mAP: 0.5588, model saved.\n",
      "-------------------- EPOCH 40 END --------------------\n",
      "-------------------- EPOCH 41 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.757312077510206\n",
      "\tMAIN_LOSS: 1.8350793696657013\n",
      "\tKD_LOSS: 0.3074109003513674\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.771541913350423\n",
      "\tMAIN_LOSS: 3.8311980168024697\n",
      "\tKD_LOSS: 0.3134479708969593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.943      0.737      0.822      0.561\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch41\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: New best mAP: 0.5610, model saved.\n",
      "-------------------- EPOCH 41 END --------------------\n",
      "-------------------- EPOCH 42 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.8358667711668377\n",
      "\tMAIN_LOSS: 1.9198694576190998\n",
      "\tKD_LOSS: 0.3053324377234978\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.053786148627599\n",
      "\tMAIN_LOSS: 4.076216985781987\n",
      "\tKD_LOSS: 0.32585640003283817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.872      0.674      0.736      0.494\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.5ms preprocess, 16.8ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch42\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 42 END --------------------\n",
      "-------------------- EPOCH 43 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.9113513367085515\n",
      "\tMAIN_LOSS: 1.98580068576185\n",
      "\tKD_LOSS: 0.30851688641536085\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 5.056166052818298\n",
      "\tMAIN_LOSS: 4.036462088425954\n",
      "\tKD_LOSS: 0.33990132932861644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.876      0.729      0.803       0.52\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch43\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 43 END --------------------\n",
      "-------------------- EPOCH 44 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.7633792056313045\n",
      "\tMAIN_LOSS: 1.8451359347452092\n",
      "\tKD_LOSS: 0.30608108790614935\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.7110914289951324\n",
      "\tMAIN_LOSS: 3.782068987687429\n",
      "\tKD_LOSS: 0.30967414875825244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181       0.89      0.779      0.834      0.542\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch44\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 44 END --------------------\n",
      "-------------------- EPOCH 45 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.7044551976119418\n",
      "\tMAIN_LOSS: 1.811959372291082\n",
      "\tKD_LOSS: 0.2974986071828045\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.529338618119557\n",
      "\tMAIN_LOSS: 3.5987007121245065\n",
      "\tKD_LOSS: 0.3102126295367877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.951      0.749      0.819      0.555\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch45\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 45 END --------------------\n",
      "-------------------- EPOCH 46 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.649179558210735\n",
      "\tMAIN_LOSS: 1.7606277164024642\n",
      "\tKD_LOSS: 0.2961839505388767\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.707913766304652\n",
      "\tMAIN_LOSS: 3.788352201382319\n",
      "\tKD_LOSS: 0.3065205129484336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.919      0.713      0.809      0.547\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch46\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 46 END --------------------\n",
      "-------------------- EPOCH 47 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.6388038200668142\n",
      "\tMAIN_LOSS: 1.7548136318786234\n",
      "\tKD_LOSS: 0.29466339757170856\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.715402394533157\n",
      "\tMAIN_LOSS: 3.787155866622925\n",
      "\tKD_LOSS: 0.309415506819884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.832      0.741      0.803       0.54\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch47\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 47 END --------------------\n",
      "-------------------- EPOCH 48 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.6173385366608826\n",
      "\tMAIN_LOSS: 1.7397198661973206\n",
      "\tKD_LOSS: 0.2925395599648922\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.842408488194148\n",
      "\tMAIN_LOSS: 3.926638891299566\n",
      "\tKD_LOSS: 0.3052565244336923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.882      0.742       0.84      0.552\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch48\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 48 END --------------------\n",
      "-------------------- EPOCH 49 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.5789925388143033\n",
      "\tMAIN_LOSS: 1.711806491960453\n",
      "\tKD_LOSS: 0.2890620265580431\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.556968649228414\n",
      "\tMAIN_LOSS: 3.668707460165024\n",
      "\tKD_LOSS: 0.29608705391486484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.938      0.768      0.843      0.578\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch49\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: New best mAP: 0.5781, model saved.\n",
      "-------------------- EPOCH 49 END --------------------\n",
      "-------------------- EPOCH 50 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.565548131737528\n",
      "\tMAIN_LOSS: 1.7005573677111276\n",
      "\tKD_LOSS: 0.2883302580706681\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.757922222216924\n",
      "\tMAIN_LOSS: 3.8607184290885925\n",
      "\tKD_LOSS: 0.29906792504092056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.836      0.796      0.808      0.524\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch50\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 50 END --------------------\n",
      "-------------------- EPOCH 51 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.549621983419491\n",
      "\tMAIN_LOSS: 1.6947302576861805\n",
      "\tKD_LOSS: 0.2849639099610003\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.572169651587804\n",
      "\tMAIN_LOSS: 3.6911808053652444\n",
      "\tKD_LOSS: 0.2936629590888818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.954      0.746      0.852      0.582\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch51\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: New best mAP: 0.5816, model saved.\n",
      "-------------------- EPOCH 51 END --------------------\n",
      "-------------------- EPOCH 52 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.5516392762147926\n",
      "\tMAIN_LOSS: 1.6949241704578641\n",
      "\tKD_LOSS: 0.28557169550581823\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.478876968224843\n",
      "\tMAIN_LOSS: 3.572695324818293\n",
      "\tKD_LOSS: 0.3020605444908142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.925      0.753      0.835      0.557\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch52\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 52 END --------------------\n",
      "-------------------- EPOCH 53 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.5345306064509137\n",
      "\tMAIN_LOSS: 1.6852535839322247\n",
      "\tKD_LOSS: 0.2830923361868798\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.517095257838567\n",
      "\tMAIN_LOSS: 3.6303204397360482\n",
      "\tKD_LOSS: 0.2955915952722232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.954      0.768      0.845      0.588\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch53\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: New best mAP: 0.5883, model saved.\n",
      "-------------------- EPOCH 53 END --------------------\n",
      "-------------------- EPOCH 54 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.5274320041077045\n",
      "\tMAIN_LOSS: 1.6825169143797476\n",
      "\tKD_LOSS: 0.28163835972170287\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.393184840679169\n",
      "\tMAIN_LOSS: 3.5230082869529724\n",
      "\tKD_LOSS: 0.2900588425497214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.852      0.779       0.82      0.563\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch54\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 54 END --------------------\n",
      "-------------------- EPOCH 55 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.4915492549727234\n",
      "\tMAIN_LOSS: 1.6518820554395266\n",
      "\tKD_LOSS: 0.2798890709122525\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.956875771284103\n",
      "\tMAIN_LOSS: 4.088376015424728\n",
      "\tKD_LOSS: 0.2894999136527379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.827      0.739      0.809      0.539\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch55\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 55 END --------------------\n",
      "-------------------- EPOCH 56 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.4733000156245653\n",
      "\tMAIN_LOSS: 1.6393694771996028\n",
      "\tKD_LOSS: 0.2779768469590175\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.825514028469722\n",
      "\tMAIN_LOSS: 3.939943144718806\n",
      "\tKD_LOSS: 0.295190275957187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.939      0.707      0.795       0.54\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch56\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 56 END --------------------\n",
      "-------------------- EPOCH 57 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.4722810244258446\n",
      "\tMAIN_LOSS: 1.6400497457649135\n",
      "\tKD_LOSS: 0.27741042760354057\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.604676773150762\n",
      "\tMAIN_LOSS: 3.747656971216202\n",
      "\tKD_LOSS: 0.28567326193054515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.882      0.741      0.817       0.56\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch57\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 57 END --------------------\n",
      "-------------------- EPOCH 58 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.3929101696497277\n",
      "\tMAIN_LOSS: 1.5702099302147008\n",
      "\tKD_LOSS: 0.27423341421386865\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.639693935712178\n",
      "\tMAIN_LOSS: 3.7812934120496116\n",
      "\tKD_LOSS: 0.2861335178216298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.945      0.752      0.839      0.565\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch58\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 58 END --------------------\n",
      "-------------------- EPOCH 59 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.3995682800872418\n",
      "\tMAIN_LOSS: 1.5851826682875427\n",
      "\tKD_LOSS: 0.27146187236037433\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.5072082579135895\n",
      "\tMAIN_LOSS: 3.657557566960653\n",
      "\tKD_LOSS: 0.28321688373883563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.872      0.753      0.824      0.556\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch59\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 59 END --------------------\n",
      "-------------------- EPOCH 60 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.4188589597050147\n",
      "\tMAIN_LOSS: 1.6030434430400027\n",
      "\tKD_LOSS: 0.2719385056178781\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.56282714009285\n",
      "\tMAIN_LOSS: 3.7079987128575644\n",
      "\tKD_LOSS: 0.28494279955824214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.946       0.74      0.821      0.555\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch60\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 60 END --------------------\n",
      "-------------------- EPOCH 61 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.436843567256686\n",
      "\tMAIN_LOSS: 1.6201340397701989\n",
      "\tKD_LOSS: 0.2722365141292162\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.50616188844045\n",
      "\tMAIN_LOSS: 3.6614034473896027\n",
      "\tKD_LOSS: 0.28158614163597423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.857      0.764      0.828       0.55\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch61\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 61 END --------------------\n",
      "-------------------- EPOCH 62 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.3899042938329\n",
      "\tMAIN_LOSS: 1.5838592988026292\n",
      "\tKD_LOSS: 0.2686816650100901\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.492588599522908\n",
      "\tMAIN_LOSS: 3.6540056665738425\n",
      "\tKD_LOSS: 0.27952765735487145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181       0.92      0.751       0.84      0.571\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch62\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 62 END --------------------\n",
      "-------------------- EPOCH 63 START --------------------\n",
      "Training start ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a9dd01c2a20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a9dd01c2a20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a9dd01c2a20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a9dd01c2a20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a9dd01c2a20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      "\tAVG_LOSS: 2.430445861212815\n",
      "\tMAIN_LOSS: 1.622549701340591\n",
      "\tKD_LOSS: 0.26929871737957\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.543274809916814\n",
      "\tMAIN_LOSS: 3.6795645554860434\n",
      "\tKD_LOSS: 0.28790343801180523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.907      0.735      0.835       0.56\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch63\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 63 END --------------------\n",
      "-------------------- EPOCH 64 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.411680847783632\n",
      "\tMAIN_LOSS: 1.6040392993371697\n",
      "\tKD_LOSS: 0.2692138509282583\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.596754729747772\n",
      "\tMAIN_LOSS: 3.743888904651006\n",
      "\tKD_LOSS: 0.28428861995538074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.895      0.746      0.835      0.572\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch64\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 64 END --------------------\n",
      "-------------------- EPOCH 65 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.339993184125876\n",
      "\tMAIN_LOSS: 1.5433312986470475\n",
      "\tKD_LOSS: 0.2655539588083195\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.428734342257182\n",
      "\tMAIN_LOSS: 3.600379784901937\n",
      "\tKD_LOSS: 0.2761181766788165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.873      0.796      0.825      0.566\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch65\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 65 END --------------------\n",
      "-------------------- EPOCH 66 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.325850693485405\n",
      "\tMAIN_LOSS: 1.5363447190840034\n",
      "\tKD_LOSS: 0.2631686556188366\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.478929698467255\n",
      "\tMAIN_LOSS: 3.6552284558614097\n",
      "\tKD_LOSS: 0.27456708687047165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.879      0.762      0.823      0.548\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch66\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 66 END --------------------\n",
      "-------------------- EPOCH 67 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.30790637112871\n",
      "\tMAIN_LOSS: 1.5263475934161415\n",
      "\tKD_LOSS: 0.26051959357684173\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.643362134695053\n",
      "\tMAIN_LOSS: 3.8365199069182077\n",
      "\tKD_LOSS: 0.26894741132855415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.47it/s]\n",
      "                   all        376        181      0.916      0.757      0.851       0.59\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch67\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: New best mAP: 0.5898, model saved.\n",
      "-------------------- EPOCH 67 END --------------------\n",
      "-------------------- EPOCH 68 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.314845789836932\n",
      "\tMAIN_LOSS: 1.5332579386385181\n",
      "\tKD_LOSS: 0.2605292829154413\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.458792199691136\n",
      "\tMAIN_LOSS: 3.6433717807133994\n",
      "\tKD_LOSS: 0.2718068150182565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.933      0.769      0.849      0.569\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch68\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 68 END --------------------\n",
      "-------------------- EPOCH 69 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.3072602733781067\n",
      "\tMAIN_LOSS: 1.5251216707350332\n",
      "\tKD_LOSS: 0.2607128682393062\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.587842543919881\n",
      "\tMAIN_LOSS: 3.7885946134726205\n",
      "\tKD_LOSS: 0.2664159865429004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.956      0.757      0.838      0.588\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch69\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 69 END --------------------\n",
      "-------------------- EPOCH 70 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.255559167529963\n",
      "\tMAIN_LOSS: 1.4859634849089611\n",
      "\tKD_LOSS: 0.2565318928866447\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.4228314359982805\n",
      "\tMAIN_LOSS: 3.6186350385348\n",
      "\tKD_LOSS: 0.26806545940538246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.923      0.746      0.806      0.548\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch70\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 70 END --------------------\n",
      "-------------------- EPOCH 71 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.216933890234066\n",
      "\tMAIN_LOSS: 1.452684314945076\n",
      "\tKD_LOSS: 0.25474985339973544\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.445938259363174\n",
      "\tMAIN_LOSS: 3.6493645906448364\n",
      "\tKD_LOSS: 0.26552455065151054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.892      0.768      0.845      0.573\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch71\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 71 END --------------------\n",
      "-------------------- EPOCH 72 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.2447673263429087\n",
      "\tMAIN_LOSS: 1.4814033734647534\n",
      "\tKD_LOSS: 0.25445464857016936\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.491568018992742\n",
      "\tMAIN_LOSS: 3.6850423514842987\n",
      "\tKD_LOSS: 0.2688418986896674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.952      0.768       0.84      0.574\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch72\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 72 END --------------------\n",
      "-------------------- EPOCH 73 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.283311093909831\n",
      "\tMAIN_LOSS: 1.4985016750383982\n",
      "\tKD_LOSS: 0.2616031384920772\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.46750013033549\n",
      "\tMAIN_LOSS: 3.663948287566503\n",
      "\tKD_LOSS: 0.2678506051500638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.944      0.748      0.842      0.593\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch73\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: New best mAP: 0.5930, model saved.\n",
      "-------------------- EPOCH 73 END --------------------\n",
      "-------------------- EPOCH 74 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.2169604376901555\n",
      "\tMAIN_LOSS: 1.4550705997249749\n",
      "\tKD_LOSS: 0.2539632812708239\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.368464608987172\n",
      "\tMAIN_LOSS: 3.5824801524480185\n",
      "\tKD_LOSS: 0.261994822571675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.884      0.779       0.84      0.583\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch74\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 74 END --------------------\n",
      "-------------------- EPOCH 75 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.227282048780707\n",
      "\tMAIN_LOSS: 1.4694665127162692\n",
      "\tKD_LOSS: 0.25260517944263505\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.509823828935623\n",
      "\tMAIN_LOSS: 3.7168866197268167\n",
      "\tKD_LOSS: 0.2643123896171649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.969      0.694      0.821      0.568\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch75\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 75 END --------------------\n",
      "-------------------- EPOCH 76 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.2448797512658034\n",
      "\tMAIN_LOSS: 1.4864334667785257\n",
      "\tKD_LOSS: 0.2528154270935662\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.4708340764045715\n",
      "\tMAIN_LOSS: 3.669907569885254\n",
      "\tKD_LOSS: 0.2669755021731059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:59<00:00,  4.93s/it]\n",
      "                   all        376        181       0.84      0.779      0.839      0.545\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.9ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch76\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 76 END --------------------\n",
      "-------------------- EPOCH 77 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.3002008154422424\n",
      "\tMAIN_LOSS: 1.5414076047607614\n",
      "\tKD_LOSS: 0.25293106576309926\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.952233483393987\n",
      "\tMAIN_LOSS: 4.149754186471303\n",
      "\tKD_LOSS: 0.26749311077098054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.848      0.707      0.796      0.556\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch77\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 77 END --------------------\n",
      "-------------------- EPOCH 78 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.2871089539950407\n",
      "\tMAIN_LOSS: 1.5280113491830947\n",
      "\tKD_LOSS: 0.2530325362576714\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.562266131242116\n",
      "\tMAIN_LOSS: 3.7025372087955475\n",
      "\tKD_LOSS: 0.2865763045847416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.896      0.729      0.822      0.556\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch78\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 78 END --------------------\n",
      "-------------------- EPOCH 79 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.23271248461325\n",
      "\tMAIN_LOSS: 1.4847885822948022\n",
      "\tKD_LOSS: 0.24930796555325954\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.363621900478999\n",
      "\tMAIN_LOSS: 3.5899623533089957\n",
      "\tKD_LOSS: 0.257886507237951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.902      0.762      0.826      0.571\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch79\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 79 END --------------------\n",
      "-------------------- EPOCH 80 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.202847793132444\n",
      "\tMAIN_LOSS: 1.4653605781024015\n",
      "\tKD_LOSS: 0.2458290725569182\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.509692708651225\n",
      "\tMAIN_LOSS: 3.728596866130829\n",
      "\tKD_LOSS: 0.26036528622110683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.943      0.732      0.837      0.568\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch80\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 80 END --------------------\n",
      "-------------------- EPOCH 81 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.183796534055396\n",
      "\tMAIN_LOSS: 1.4489510632768463\n",
      "\tKD_LOSS: 0.24494848504096647\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.38923176129659\n",
      "\tMAIN_LOSS: 3.631705413262049\n",
      "\tKD_LOSS: 0.25250877750416595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.896      0.765      0.832      0.579\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch81\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 81 END --------------------\n",
      "-------------------- EPOCH 82 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.1451616755014733\n",
      "\tMAIN_LOSS: 1.4166903420339656\n",
      "\tKD_LOSS: 0.24282377543328684\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.218879530827205\n",
      "\tMAIN_LOSS: 3.4658761819203696\n",
      "\tKD_LOSS: 0.2510011059542497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.913      0.768       0.83      0.591\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch82\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 82 END --------------------\n",
      "-------------------- EPOCH 83 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.1363068871860262\n",
      "\tMAIN_LOSS: 1.4073019269146496\n",
      "\tKD_LOSS: 0.24300165549863742\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.554260979096095\n",
      "\tMAIN_LOSS: 3.783014545838038\n",
      "\tKD_LOSS: 0.25708214690287906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.906      0.757      0.828      0.576\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch83\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 83 END --------------------\n",
      "-------------------- EPOCH 84 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.129346062865438\n",
      "\tMAIN_LOSS: 1.4081481619726253\n",
      "\tKD_LOSS: 0.24039929916587058\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.355969627698262\n",
      "\tMAIN_LOSS: 3.607896020015081\n",
      "\tKD_LOSS: 0.24935785991450152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.902       0.76      0.841      0.581\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch84\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 84 END --------------------\n",
      "-------------------- EPOCH 85 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.1531134028977985\n",
      "\tMAIN_LOSS: 1.4324161221709433\n",
      "\tKD_LOSS: 0.24023242709757406\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.333691348632176\n",
      "\tMAIN_LOSS: 3.586383173863093\n",
      "\tKD_LOSS: 0.24910272223254046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181        0.9      0.735      0.828      0.579\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch85\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 85 END --------------------\n",
      "-------------------- EPOCH 86 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.1160042104841787\n",
      "\tMAIN_LOSS: 1.4005228477188303\n",
      "\tKD_LOSS: 0.23849379148664354\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.221422145764033\n",
      "\tMAIN_LOSS: 3.47145148118337\n",
      "\tKD_LOSS: 0.24999022980531058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.906      0.803      0.856      0.589\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch86\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 86 END --------------------\n",
      "-------------------- EPOCH 87 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.0944352904452552\n",
      "\tMAIN_LOSS: 1.3835687063917328\n",
      "\tKD_LOSS: 0.23695553216753126\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.36507452527682\n",
      "\tMAIN_LOSS: 3.6225578586260476\n",
      "\tKD_LOSS: 0.24750555803378424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.48it/s]\n",
      "                   all        376        181      0.964      0.739      0.847      0.593\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.5ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch87\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 87 END --------------------\n",
      "-------------------- EPOCH 88 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.0955989179731924\n",
      "\tMAIN_LOSS: 1.389323064043552\n",
      "\tKD_LOSS: 0.2354252840144725\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.518008550008138\n",
      "\tMAIN_LOSS: 3.768478810787201\n",
      "\tKD_LOSS: 0.24984324350953102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.922       0.74      0.844      0.579\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch88\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 88 END --------------------\n",
      "-------------------- EPOCH 89 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.1263645917554443\n",
      "\tMAIN_LOSS: 1.4172484180595302\n",
      "\tKD_LOSS: 0.23637205682977847\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.283265670140584\n",
      "\tMAIN_LOSS: 3.523081789414088\n",
      "\tKD_LOSS: 0.253394627943635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.944      0.751      0.838      0.574\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch89\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 89 END --------------------\n",
      "-------------------- EPOCH 90 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.1361791378335107\n",
      "\tMAIN_LOSS: 1.4214280028886432\n",
      "\tKD_LOSS: 0.23825037856645223\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.496779143810272\n",
      "\tMAIN_LOSS: 3.7517250776290894\n",
      "\tKD_LOSS: 0.24835134235521159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.965       0.74       0.84      0.593\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch90\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 90 END --------------------\n",
      "-------------------- EPOCH 91 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.0671985013575496\n",
      "\tMAIN_LOSS: 1.366515905042238\n",
      "\tKD_LOSS: 0.23356086770190468\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.3520208696524305\n",
      "\tMAIN_LOSS: 3.635620931784312\n",
      "\tKD_LOSS: 0.23879996997614703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.944      0.773      0.858      0.613\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch91\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: New best mAP: 0.6135, model saved.\n",
      "-------------------- EPOCH 91 END --------------------\n",
      "-------------------- EPOCH 92 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.0709433117999305\n",
      "\tMAIN_LOSS: 1.3778650941728037\n",
      "\tKD_LOSS: 0.2310260739884799\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.339303682247798\n",
      "\tMAIN_LOSS: 3.6114788353443146\n",
      "\tKD_LOSS: 0.24260827588538328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.928      0.778      0.857      0.595\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch92\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 92 END --------------------\n",
      "-------------------- EPOCH 93 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.0861987690382366\n",
      "\tMAIN_LOSS: 1.3917510562305209\n",
      "\tKD_LOSS: 0.23148257351374324\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.2207845946153\n",
      "\tMAIN_LOSS: 3.4832873890797296\n",
      "\tKD_LOSS: 0.2458324128141006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.906       0.79      0.851      0.591\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch93\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 93 END --------------------\n",
      "-------------------- EPOCH 94 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.1096781960016564\n",
      "\tMAIN_LOSS: 1.413908012305634\n",
      "\tKD_LOSS: 0.23192339041565038\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.276152819395065\n",
      "\tMAIN_LOSS: 3.5492241183916726\n",
      "\tKD_LOSS: 0.24230957527955374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.913      0.757      0.841      0.586\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch94\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 94 END --------------------\n",
      "-------------------- EPOCH 95 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.073885869376267\n",
      "\tMAIN_LOSS: 1.3853734082813505\n",
      "\tKD_LOSS: 0.22950415558452847\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.47928574681282\n",
      "\tMAIN_LOSS: 3.746209611495336\n",
      "\tKD_LOSS: 0.24435869914789995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181       0.91      0.724      0.806      0.554\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch95\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 95 END --------------------\n",
      "-------------------- EPOCH 96 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.3074005706400813\n",
      "\tMAIN_LOSS: 1.556307524065428\n",
      "\tKD_LOSS: 0.2503643447085272\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.550392031669617\n",
      "\tMAIN_LOSS: 3.785491555929184\n",
      "\tKD_LOSS: 0.2549668358018001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.874      0.735        0.8       0.54\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch96\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 96 END --------------------\n",
      "-------------------- EPOCH 97 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.1479475120954876\n",
      "\tMAIN_LOSS: 1.4311925097356868\n",
      "\tKD_LOSS: 0.23891833518879324\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.173209647337596\n",
      "\tMAIN_LOSS: 3.4258992274602256\n",
      "\tKD_LOSS: 0.24910348219176134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.942      0.718      0.823      0.562\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch97\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 97 END --------------------\n",
      "-------------------- EPOCH 98 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.0927996590167663\n",
      "\tMAIN_LOSS: 1.3939597455761101\n",
      "\tKD_LOSS: 0.23294663957402675\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.273048023382823\n",
      "\tMAIN_LOSS: 3.54525355497996\n",
      "\tKD_LOSS: 0.2425981443375349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.945      0.746      0.845      0.571\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch98\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 98 END --------------------\n",
      "-------------------- EPOCH 99 START --------------------\n",
      "Training start ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a9dd01c2a20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a9dd01c2a20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a9dd01c2a20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a9dd01c2a20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a9dd01c2a20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      "\tAVG_LOSS: 2.0338255498982685\n",
      "\tMAIN_LOSS: 1.3494610514821885\n",
      "\tKD_LOSS: 0.22812150098100492\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.305273542801539\n",
      "\tMAIN_LOSS: 3.592914491891861\n",
      "\tKD_LOSS: 0.23745302048822245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.956      0.724       0.85      0.607\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch99\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 99 END --------------------\n",
      "-------------------- EPOCH 100 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.023820252358159\n",
      "\tMAIN_LOSS: 1.3457623463642747\n",
      "\tKD_LOSS: 0.22601930476442167\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.303116748730342\n",
      "\tMAIN_LOSS: 3.6000866889953613\n",
      "\tKD_LOSS: 0.23434334682921568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.968      0.768      0.861      0.616\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch100\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: New best mAP: 0.6159, model saved.\n",
      "-------------------- EPOCH 100 END --------------------\n",
      "-------------------- EPOCH 101 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.152487522439112\n",
      "\tMAIN_LOSS: 1.4380569201481492\n",
      "\tKD_LOSS: 0.23814353365686874\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.587198098500569\n",
      "\tMAIN_LOSS: 3.7708590825398765\n",
      "\tKD_LOSS: 0.2721130009740591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.891      0.724      0.813      0.554\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch101\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 101 END --------------------\n",
      "-------------------- EPOCH 102 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.488315328767028\n",
      "\tMAIN_LOSS: 1.7031804081759876\n",
      "\tKD_LOSS: 0.2617116410143768\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.5765491127967834\n",
      "\tMAIN_LOSS: 3.789893388748169\n",
      "\tKD_LOSS: 0.26221856909493607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.948      0.712       0.83      0.553\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch102\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 102 END --------------------\n",
      "-------------------- EPOCH 103 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.165478593940976\n",
      "\tMAIN_LOSS: 1.4459004658686965\n",
      "\tKD_LOSS: 0.2398593761498415\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.4565389057000475\n",
      "\tMAIN_LOSS: 3.7200031876564026\n",
      "\tKD_LOSS: 0.24551190435886383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.958      0.761       0.86      0.604\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch103\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 103 END --------------------\n",
      "-------------------- EPOCH 104 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.0406031699120244\n",
      "\tMAIN_LOSS: 1.350072083593924\n",
      "\tKD_LOSS: 0.23017702770384052\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.367384682099025\n",
      "\tMAIN_LOSS: 3.6584960917631784\n",
      "\tKD_LOSS: 0.23629620733360449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.916      0.782      0.852      0.591\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch104\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 104 END --------------------\n",
      "-------------------- EPOCH 105 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9870212832583656\n",
      "\tMAIN_LOSS: 1.3077505057371115\n",
      "\tKD_LOSS: 0.22642359816575353\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.277616639931996\n",
      "\tMAIN_LOSS: 3.5764316668113074\n",
      "\tKD_LOSS: 0.23372831692298254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.953      0.782      0.863      0.599\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch105\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 105 END --------------------\n",
      "-------------------- EPOCH 106 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9617157616192782\n",
      "\tMAIN_LOSS: 1.2903432483914532\n",
      "\tKD_LOSS: 0.22379084025757223\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.337716648976008\n",
      "\tMAIN_LOSS: 3.643470197916031\n",
      "\tKD_LOSS: 0.2314154909302791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.937      0.796      0.866      0.615\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch106\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 106 END --------------------\n",
      "-------------------- EPOCH 107 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9917699083497253\n",
      "\tMAIN_LOSS: 1.3214607329308232\n",
      "\tKD_LOSS: 0.22343639312665672\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.2105040947596235\n",
      "\tMAIN_LOSS: 3.522680252790451\n",
      "\tKD_LOSS: 0.22927460571130118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.951      0.753      0.858      0.605\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch107\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 107 END --------------------\n",
      "-------------------- EPOCH 108 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9592520919027208\n",
      "\tMAIN_LOSS: 1.2957023457635808\n",
      "\tKD_LOSS: 0.22118324927891356\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.213363726933797\n",
      "\tMAIN_LOSS: 3.5309770504633584\n",
      "\tKD_LOSS: 0.22746223459641138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.975      0.762       0.87       0.62\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch108\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108: New best mAP: 0.6196, model saved.\n",
      "-------------------- EPOCH 108 END --------------------\n",
      "-------------------- EPOCH 109 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9617717507519299\n",
      "\tMAIN_LOSS: 1.2984068982208832\n",
      "\tKD_LOSS: 0.22112161977381645\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.180754731098811\n",
      "\tMAIN_LOSS: 3.4892856180667877\n",
      "\tKD_LOSS: 0.2304896948238214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.946      0.746      0.855      0.604\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch109\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 109 END --------------------\n",
      "-------------------- EPOCH 110 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9395295607892773\n",
      "\tMAIN_LOSS: 1.2835968974270398\n",
      "\tKD_LOSS: 0.21864422080637533\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.385481894016266\n",
      "\tMAIN_LOSS: 3.674127846956253\n",
      "\tKD_LOSS: 0.23711800823609033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.933       0.79       0.87      0.618\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch110\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 110 END --------------------\n",
      "-------------------- EPOCH 111 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9540028209927716\n",
      "\tMAIN_LOSS: 1.2985230156137972\n",
      "\tKD_LOSS: 0.21849326864828036\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.4605322778224945\n",
      "\tMAIN_LOSS: 3.7706619600454965\n",
      "\tKD_LOSS: 0.22995677528282008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.928      0.782      0.848      0.582\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch111\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 111 END --------------------\n",
      "-------------------- EPOCH 112 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9584881565238856\n",
      "\tMAIN_LOSS: 1.3057324765603753\n",
      "\tKD_LOSS: 0.21758522847785225\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.2326156596342726\n",
      "\tMAIN_LOSS: 3.5537887712319693\n",
      "\tKD_LOSS: 0.2262756358832121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.913      0.768      0.847      0.581\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch112\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 112 END --------------------\n",
      "-------------------- EPOCH 113 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9469896781293652\n",
      "\tMAIN_LOSS: 1.293977447702915\n",
      "\tKD_LOSS: 0.21767074303536477\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.139044473568599\n",
      "\tMAIN_LOSS: 3.467589924732844\n",
      "\tKD_LOSS: 0.22381818356613317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.47it/s]\n",
      "                   all        376        181       0.95      0.768      0.866      0.616\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch113\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 113 END --------------------\n",
      "-------------------- EPOCH 114 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9058370937274982\n",
      "\tMAIN_LOSS: 1.2626152310190322\n",
      "\tKD_LOSS: 0.21440728744374046\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.130851189295451\n",
      "\tMAIN_LOSS: 3.463595529397329\n",
      "\tKD_LOSS: 0.22241853860517344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.47it/s]\n",
      "                   all        376        181      0.986      0.777      0.867      0.613\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch114\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 114 END --------------------\n",
      "-------------------- EPOCH 115 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9133656462536583\n",
      "\tMAIN_LOSS: 1.2688099311876901\n",
      "\tKD_LOSS: 0.21485190640521956\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.097302118937175\n",
      "\tMAIN_LOSS: 3.4335149625937142\n",
      "\tKD_LOSS: 0.22126239848633608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.47it/s]\n",
      "                   all        376        181      0.924      0.785      0.857      0.607\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch115\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 115 END --------------------\n",
      "-------------------- EPOCH 116 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9207345813135557\n",
      "\tMAIN_LOSS: 1.280826609345931\n",
      "\tKD_LOSS: 0.21330265851714944\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.269140472014745\n",
      "\tMAIN_LOSS: 3.602605710426966\n",
      "\tKD_LOSS: 0.2221782598644495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.951      0.755      0.856      0.603\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch116\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 116 END --------------------\n",
      "-------------------- EPOCH 117 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9322815016855168\n",
      "\tMAIN_LOSS: 1.2937945791437655\n",
      "\tKD_LOSS: 0.21282897531231748\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.199056555827458\n",
      "\tMAIN_LOSS: 3.525560140609741\n",
      "\tKD_LOSS: 0.22449879782895246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.975      0.757      0.856      0.608\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch117\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 117 END --------------------\n",
      "-------------------- EPOCH 118 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.902965818779378\n",
      "\tMAIN_LOSS: 1.2683444189119943\n",
      "\tKD_LOSS: 0.2115404675655727\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.149932493766149\n",
      "\tMAIN_LOSS: 3.4914332131544747\n",
      "\tKD_LOSS: 0.2194997655848662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.959      0.782      0.869      0.617\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch118\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 118 END --------------------\n",
      "-------------------- EPOCH 119 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.887412277958061\n",
      "\tMAIN_LOSS: 1.2557913246034067\n",
      "\tKD_LOSS: 0.21054031935673725\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.06394828359286\n",
      "\tMAIN_LOSS: 3.4077523350715637\n",
      "\tKD_LOSS: 0.2187319758037726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.928      0.762      0.849      0.611\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch119\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 119 END --------------------\n",
      "-------------------- EPOCH 120 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9399625636354279\n",
      "\tMAIN_LOSS: 1.2957463226740873\n",
      "\tKD_LOSS: 0.21473874415777908\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.11267818013827\n",
      "\tMAIN_LOSS: 3.4482011000315347\n",
      "\tKD_LOSS: 0.2214923519641161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.47it/s]\n",
      "                   all        376        181      0.933      0.768      0.849       0.59\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch120\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 120 END --------------------\n",
      "-------------------- EPOCH 121 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9017770893966095\n",
      "\tMAIN_LOSS: 1.2711663729027858\n",
      "\tKD_LOSS: 0.21020357235323026\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.22830605506897\n",
      "\tMAIN_LOSS: 3.5745268960793815\n",
      "\tKD_LOSS: 0.2179263966778914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.959      0.782      0.867      0.617\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch121\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 121 END --------------------\n",
      "-------------------- EPOCH 122 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.8617643359341198\n",
      "\tMAIN_LOSS: 1.2340668726570998\n",
      "\tKD_LOSS: 0.20923248669014702\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.268617590268453\n",
      "\tMAIN_LOSS: 3.6067312558492026\n",
      "\tKD_LOSS: 0.22062878186504045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.947      0.773      0.863       0.62\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch122\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122: New best mAP: 0.6203, model saved.\n",
      "-------------------- EPOCH 122 END --------------------\n",
      "-------------------- EPOCH 123 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.894247738620903\n",
      "\tMAIN_LOSS: 1.2693481913095788\n",
      "\tKD_LOSS: 0.20829985054987896\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.189510216315587\n",
      "\tMAIN_LOSS: 3.535335789124171\n",
      "\tKD_LOSS: 0.2180581372231245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.47it/s]\n",
      "                   all        376        181      0.935      0.794      0.867      0.614\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch123\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 123 END --------------------\n",
      "-------------------- EPOCH 124 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.899335195746603\n",
      "\tMAIN_LOSS: 1.2741662641114826\n",
      "\tKD_LOSS: 0.2083896443813662\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.061302840709686\n",
      "\tMAIN_LOSS: 3.405370165904363\n",
      "\tKD_LOSS: 0.21864421293139458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.47it/s]\n",
      "                   all        376        181       0.96      0.779      0.866      0.618\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch124\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 124 END --------------------\n",
      "-------------------- EPOCH 125 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9360237000863763\n",
      "\tMAIN_LOSS: 1.3080781245533424\n",
      "\tKD_LOSS: 0.20931519077548497\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.399623016516368\n",
      "\tMAIN_LOSS: 3.7374963760375977\n",
      "\tKD_LOSS: 0.22070887995262942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.876      0.751      0.849      0.612\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 125 END --------------------\n",
      "-------------------- EPOCH 126 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.8691849784006047\n",
      "\tMAIN_LOSS: 1.2487512087520165\n",
      "\tKD_LOSS: 0.20681125736689265\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.135743310054143\n",
      "\tMAIN_LOSS: 3.489815870920817\n",
      "\tKD_LOSS: 0.2153091368575891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.952       0.77      0.858      0.609\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch126\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 126 END --------------------\n",
      "-------------------- EPOCH 127 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.8499124419840076\n",
      "\tMAIN_LOSS: 1.233029708077636\n",
      "\tKD_LOSS: 0.2056275768370568\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.243170231580734\n",
      "\tMAIN_LOSS: 3.6015020608901978\n",
      "\tKD_LOSS: 0.21388938340047994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.925      0.773       0.86      0.617\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch127\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 127 END --------------------\n",
      "-------------------- EPOCH 128 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9320862112166006\n",
      "\tMAIN_LOSS: 1.302780330935611\n",
      "\tKD_LOSS: 0.20976862801781185\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.071435580650966\n",
      "\tMAIN_LOSS: 3.428184986114502\n",
      "\tKD_LOSS: 0.2144168590505918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.919      0.768      0.843      0.593\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch128\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 128 END --------------------\n",
      "-------------------- EPOCH 129 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.86211881305598\n",
      "\tMAIN_LOSS: 1.2483689453028426\n",
      "\tKD_LOSS: 0.20458328837080847\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.127151757478714\n",
      "\tMAIN_LOSS: 3.4814225236574807\n",
      "\tKD_LOSS: 0.21524308125178018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.969      0.773      0.861      0.618\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch129\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 129 END --------------------\n",
      "-------------------- EPOCH 130 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.8874966871889332\n",
      "\tMAIN_LOSS: 1.2717176042025602\n",
      "\tKD_LOSS: 0.2052596905563451\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.280877113342285\n",
      "\tMAIN_LOSS: 3.6251516342163086\n",
      "\tKD_LOSS: 0.21857516281306744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181      0.872      0.718      0.744      0.516\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch130\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 130 END --------------------\n",
      "-------------------- EPOCH 131 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.8855065288422983\n",
      "\tMAIN_LOSS: 1.269545766371715\n",
      "\tKD_LOSS: 0.20532025151614902\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.166531801223755\n",
      "\tMAIN_LOSS: 3.5243727564811707\n",
      "\tKD_LOSS: 0.214053005600969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.979      0.773      0.869      0.609\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch131\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 131 END --------------------\n",
      "-------------------- EPOCH 132 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9205300536336778\n",
      "\tMAIN_LOSS: 1.2959672710563563\n",
      "\tKD_LOSS: 0.20818759312358084\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.491570025682449\n",
      "\tMAIN_LOSS: 3.8380641043186188\n",
      "\tKD_LOSS: 0.21783530339598656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181       0.94      0.774      0.847      0.576\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch132\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 132 END --------------------\n",
      "-------------------- EPOCH 133 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.864907448050342\n",
      "\tMAIN_LOSS: 1.2489132986793035\n",
      "\tKD_LOSS: 0.2053313830608054\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.951044410467148\n",
      "\tMAIN_LOSS: 3.3194519678751626\n",
      "\tKD_LOSS: 0.21053081626693407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181       0.88      0.768      0.844      0.612\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch133\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 133 END --------------------\n",
      "-------------------- EPOCH 134 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.832599552371834\n",
      "\tMAIN_LOSS: 1.2283331035058709\n",
      "\tKD_LOSS: 0.201422147924387\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9479437867800393\n",
      "\tMAIN_LOSS: 3.319946805636088\n",
      "\tKD_LOSS: 0.20933232208093008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.959      0.762      0.872       0.62\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch134\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 134 END --------------------\n",
      "-------------------- EPOCH 135 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.852000485492658\n",
      "\tMAIN_LOSS: 1.2490814924240112\n",
      "\tKD_LOSS: 0.20097299712368205\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.016949911912282\n",
      "\tMAIN_LOSS: 3.381897429625193\n",
      "\tKD_LOSS: 0.21168415683011213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.945       0.76      0.868      0.607\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch135\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 135 END --------------------\n",
      "-------------------- EPOCH 136 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.8496384892282607\n",
      "\tMAIN_LOSS: 1.2473424084578888\n",
      "\tKD_LOSS: 0.20076535962804964\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.176447083552678\n",
      "\tMAIN_LOSS: 3.537525157133738\n",
      "\tKD_LOSS: 0.21297397402425608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.47it/s]\n",
      "                   all        376        181       0.95      0.785      0.871      0.609\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch136\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 136 END --------------------\n",
      "-------------------- EPOCH 137 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.888884321043763\n",
      "\tMAIN_LOSS: 1.2739978002596506\n",
      "\tKD_LOSS: 0.2049621747264379\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.369419038295746\n",
      "\tMAIN_LOSS: 3.592990587155024\n",
      "\tKD_LOSS: 0.2588094733655453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.851      0.746      0.834      0.562\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch137\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 137 END --------------------\n",
      "-------------------- EPOCH 138 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.695860704289207\n",
      "\tMAIN_LOSS: 1.8824257548851302\n",
      "\tKD_LOSS: 0.2711449846436706\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.364572674036026\n",
      "\tMAIN_LOSS: 3.5817291140556335\n",
      "\tKD_LOSS: 0.26094787071148556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.924      0.737      0.841      0.556\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch138\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 138 END --------------------\n",
      "-------------------- EPOCH 139 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 2.130959118468852\n",
      "\tMAIN_LOSS: 1.4389435233949106\n",
      "\tKD_LOSS: 0.2306718654647658\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.416238139073054\n",
      "\tMAIN_LOSS: 3.7102707425753274\n",
      "\tKD_LOSS: 0.23532245929042497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.985      0.731      0.852      0.582\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch139\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 139 END --------------------\n",
      "-------------------- EPOCH 140 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9371455153332482\n",
      "\tMAIN_LOSS: 1.2881414075440998\n",
      "\tKD_LOSS: 0.21633470586583584\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.257754564285278\n",
      "\tMAIN_LOSS: 3.587207814057668\n",
      "\tKD_LOSS: 0.2235155695428451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.969       0.74      0.872      0.603\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch140\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 140 END --------------------\n",
      "-------------------- EPOCH 141 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.9341566396664969\n",
      "\tMAIN_LOSS: 1.289541279213338\n",
      "\tKD_LOSS: 0.2148717888925649\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.32872490088145\n",
      "\tMAIN_LOSS: 3.6731335719426474\n",
      "\tKD_LOSS: 0.2185304413239161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.921      0.768      0.858      0.596\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch141\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 141 END --------------------\n",
      "-------------------- EPOCH 142 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.83308531513697\n",
      "\tMAIN_LOSS: 1.2074096595184713\n",
      "\tKD_LOSS: 0.20855855243869975\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.051804502805074\n",
      "\tMAIN_LOSS: 3.4102487564086914\n",
      "\tKD_LOSS: 0.2138519256065289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181       0.95      0.762      0.874      0.603\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch142\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 142 END --------------------\n",
      "-------------------- EPOCH 143 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.8391209765325618\n",
      "\tMAIN_LOSS: 1.2241391252867784\n",
      "\tKD_LOSS: 0.20499395135837264\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.024379154046376\n",
      "\tMAIN_LOSS: 3.396363159020742\n",
      "\tKD_LOSS: 0.20933866066237292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.951      0.757      0.879      0.624\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch143\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143: New best mAP: 0.6235, model saved.\n",
      "-------------------- EPOCH 143 END --------------------\n",
      "-------------------- EPOCH 144 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.8002912605865091\n",
      "\tMAIN_LOSS: 1.1950519054750852\n",
      "\tKD_LOSS: 0.20174644849722898\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.025092959403992\n",
      "\tMAIN_LOSS: 3.3967397610346475\n",
      "\tKD_LOSS: 0.20945106881360212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.47it/s]\n",
      "                   all        376        181      0.949      0.768      0.887      0.615\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch144\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 144 END --------------------\n",
      "-------------------- EPOCH 145 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7697342256956463\n",
      "\tMAIN_LOSS: 1.1704013106189197\n",
      "\tKD_LOSS: 0.19977763766729378\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.110872954130173\n",
      "\tMAIN_LOSS: 3.4860864778359733\n",
      "\tKD_LOSS: 0.2082621535907189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.932      0.779      0.871      0.611\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch145\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 145 END --------------------\n",
      "-------------------- EPOCH 146 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7743838105020644\n",
      "\tMAIN_LOSS: 1.1774316467816317\n",
      "\tKD_LOSS: 0.19898405199563957\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.160083721081416\n",
      "\tMAIN_LOSS: 3.5425712168216705\n",
      "\tKD_LOSS: 0.20583749189972878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.917      0.762       0.87      0.608\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch146\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 146 END --------------------\n",
      "-------------------- EPOCH 147 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7770478997049453\n",
      "\tMAIN_LOSS: 1.184012921550606\n",
      "\tKD_LOSS: 0.1976783247310904\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.2056905428568525\n",
      "\tMAIN_LOSS: 3.591330031553904\n",
      "\tKD_LOSS: 0.20478682840863863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.953      0.751      0.863      0.601\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch147\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 147 END --------------------\n",
      "-------------------- EPOCH 148 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7805347487896304\n",
      "\tMAIN_LOSS: 1.1918974443327022\n",
      "\tKD_LOSS: 0.19621243469322783\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.081305623054504\n",
      "\tMAIN_LOSS: 3.465507080157598\n",
      "\tKD_LOSS: 0.20526618945101896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.909      0.762      0.858      0.611\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch148\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 148 END --------------------\n",
      "-------------------- EPOCH 149 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.788670076599604\n",
      "\tMAIN_LOSS: 1.2021505108362511\n",
      "\tKD_LOSS: 0.19550652292710316\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.033347855011622\n",
      "\tMAIN_LOSS: 3.4261801739533744\n",
      "\tKD_LOSS: 0.20238922163844109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181      0.889      0.796      0.864      0.608\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch149\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 149 END --------------------\n",
      "-------------------- EPOCH 150 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.8098721519301209\n",
      "\tMAIN_LOSS: 1.2171343715885017\n",
      "\tKD_LOSS: 0.1975792614342291\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.145207166671753\n",
      "\tMAIN_LOSS: 3.532486925522486\n",
      "\tKD_LOSS: 0.2042400762438774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.936      0.751       0.87      0.611\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch150\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 150 END --------------------\n",
      "-------------------- EPOCH 151 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7551655543001392\n",
      "\tMAIN_LOSS: 1.1704681296891803\n",
      "\tKD_LOSS: 0.1948991402795043\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.137174238761266\n",
      "\tMAIN_LOSS: 3.535364826520284\n",
      "\tKD_LOSS: 0.2006031380345424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.965      0.766      0.875      0.629\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch151\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151: New best mAP: 0.6285, model saved.\n",
      "-------------------- EPOCH 151 END --------------------\n",
      "-------------------- EPOCH 152 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7670330729665635\n",
      "\tMAIN_LOSS: 1.1868606338018104\n",
      "\tKD_LOSS: 0.19339081248905085\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.139088879028956\n",
      "\tMAIN_LOSS: 3.541630908846855\n",
      "\tKD_LOSS: 0.19915266645451388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.46it/s]\n",
      "                   all        376        181      0.961      0.751      0.881       0.63\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch152\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152: New best mAP: 0.6298, model saved.\n",
      "-------------------- EPOCH 152 END --------------------\n",
      "-------------------- EPOCH 153 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7624483153789858\n",
      "\tMAIN_LOSS: 1.1832111349588708\n",
      "\tKD_LOSS: 0.19307905925980098\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.120504220326741\n",
      "\tMAIN_LOSS: 3.5183311303456626\n",
      "\tKD_LOSS: 0.20072436146438122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.972      0.766      0.883      0.634\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch153\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: New best mAP: 0.6338, model saved.\n",
      "-------------------- EPOCH 153 END --------------------\n",
      "-------------------- EPOCH 154 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7588683412044863\n",
      "\tMAIN_LOSS: 1.1824437108220933\n",
      "\tKD_LOSS: 0.192141544969776\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.000717490911484\n",
      "\tMAIN_LOSS: 3.4069241086641946\n",
      "\tKD_LOSS: 0.19793113258977732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.965      0.772      0.876      0.625\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch154\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 154 END --------------------\n",
      "-------------------- EPOCH 155 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7457079766671868\n",
      "\tMAIN_LOSS: 1.175527170489106\n",
      "\tKD_LOSS: 0.19006027262422104\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.0741338928540545\n",
      "\tMAIN_LOSS: 3.479044477144877\n",
      "\tKD_LOSS: 0.19836314767599106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.971      0.768      0.886      0.628\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch155\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 155 END --------------------\n",
      "-------------------- EPOCH 156 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7575092677828632\n",
      "\tMAIN_LOSS: 1.1869429199001458\n",
      "\tKD_LOSS: 0.190188782313202\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.971599668264389\n",
      "\tMAIN_LOSS: 3.3862996896107993\n",
      "\tKD_LOSS: 0.1950999932984511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.914      0.801      0.872      0.618\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch156\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 156 END --------------------\n",
      "-------------------- EPOCH 157 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7336436374278008\n",
      "\tMAIN_LOSS: 1.1676566231099865\n",
      "\tKD_LOSS: 0.18866233621971518\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.968374570210775\n",
      "\tMAIN_LOSS: 3.382789591948191\n",
      "\tKD_LOSS: 0.19519499130547047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181      0.908      0.801       0.88      0.623\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch157\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 157 END --------------------\n",
      "-------------------- EPOCH 158 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7069275183013723\n",
      "\tMAIN_LOSS: 1.1407122483736352\n",
      "\tKD_LOSS: 0.1887384230577493\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.031146605809529\n",
      "\tMAIN_LOSS: 3.4364475707213082\n",
      "\tKD_LOSS: 0.1982330121099949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.918      0.785      0.876      0.619\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch158\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 158 END --------------------\n",
      "-------------------- EPOCH 159 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.732919519460654\n",
      "\tMAIN_LOSS: 1.1669672825668431\n",
      "\tKD_LOSS: 0.18865074292768405\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.006840268770854\n",
      "\tMAIN_LOSS: 3.4188169836997986\n",
      "\tKD_LOSS: 0.19600775899986425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.952      0.759      0.881      0.624\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch159\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 159 END --------------------\n",
      "-------------------- EPOCH 160 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7513482495199275\n",
      "\tMAIN_LOSS: 1.182809448694881\n",
      "\tKD_LOSS: 0.18951293279098558\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.012332836786906\n",
      "\tMAIN_LOSS: 3.4234443803628287\n",
      "\tKD_LOSS: 0.19629615110655627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181       0.92      0.773      0.873      0.614\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch160\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 160 END --------------------\n",
      "-------------------- EPOCH 161 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.764671971526327\n",
      "\tMAIN_LOSS: 1.2013279441036755\n",
      "\tKD_LOSS: 0.18778134165685387\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.352834343910217\n",
      "\tMAIN_LOSS: 3.768399884303411\n",
      "\tKD_LOSS: 0.1948114801198244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.959       0.79      0.872       0.62\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch161\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 161 END --------------------\n",
      "-------------------- EPOCH 162 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7299130189267895\n",
      "\tMAIN_LOSS: 1.1684301571000981\n",
      "\tKD_LOSS: 0.18716095218175574\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.130993882815043\n",
      "\tMAIN_LOSS: 3.539384757479032\n",
      "\tKD_LOSS: 0.1972030426065127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:46<00:00,  3.86s/it]\n",
      "                   all        376        181      0.952      0.773      0.876      0.629\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 17.5ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch162\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 162 END --------------------\n",
      "-------------------- EPOCH 163 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7432897739772555\n",
      "\tMAIN_LOSS: 1.1839221806465825\n",
      "\tKD_LOSS: 0.18645586205434195\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.026210695505142\n",
      "\tMAIN_LOSS: 3.4136994183063507\n",
      "\tKD_LOSS: 0.204170444359382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.927      0.771      0.876      0.602\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch163\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 163 END --------------------\n",
      "-------------------- EPOCH 164 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.754845761045625\n",
      "\tMAIN_LOSS: 1.1936206598825092\n",
      "\tKD_LOSS: 0.1870750354815133\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.356454352537791\n",
      "\tMAIN_LOSS: 3.7428219417730966\n",
      "\tKD_LOSS: 0.20454414375126362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.903      0.724      0.863      0.589\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch164\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 164 END --------------------\n",
      "-------------------- EPOCH 165 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7680461451977114\n",
      "\tMAIN_LOSS: 1.2036387769481804\n",
      "\tKD_LOSS: 0.1881357902967477\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.202951997518539\n",
      "\tMAIN_LOSS: 3.5853364070256553\n",
      "\tKD_LOSS: 0.2058718539774418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.931      0.724       0.86      0.607\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch165\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 165 END --------------------\n",
      "-------------------- EPOCH 166 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7490423751782767\n",
      "\tMAIN_LOSS: 1.191809261901469\n",
      "\tKD_LOSS: 0.18574436970903904\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.06526396671931\n",
      "\tMAIN_LOSS: 3.483117093642553\n",
      "\tKD_LOSS: 0.1940489485859871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.40it/s]\n",
      "                   all        376        181      0.978       0.75       0.87      0.613\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.2ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch166\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 166 END --------------------\n",
      "-------------------- EPOCH 167 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.735063377814957\n",
      "\tMAIN_LOSS: 1.1829630513734455\n",
      "\tKD_LOSS: 0.18403344158130355\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8747844298680625\n",
      "\tMAIN_LOSS: 3.2810217340787253\n",
      "\tKD_LOSS: 0.19792088493704796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.969       0.79      0.877       0.61\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch167\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 167 END --------------------\n",
      "-------------------- EPOCH 168 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7530104238775712\n",
      "\tMAIN_LOSS: 1.199193519882009\n",
      "\tKD_LOSS: 0.1846056354196766\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.00187752644221\n",
      "\tMAIN_LOSS: 3.4313414792219796\n",
      "\tKD_LOSS: 0.19017868178586164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.957      0.768      0.883       0.62\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch168\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 168 END --------------------\n",
      "-------------------- EPOCH 169 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.71783545047422\n",
      "\tMAIN_LOSS: 1.1692194667043565\n",
      "\tKD_LOSS: 0.18287199264085746\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9419891138871512\n",
      "\tMAIN_LOSS: 3.365947117408117\n",
      "\tKD_LOSS: 0.19201399572193623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.927      0.768      0.864      0.602\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch169\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 169 END --------------------\n",
      "-------------------- EPOCH 170 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.734818186186537\n",
      "\tMAIN_LOSS: 1.1804723105853117\n",
      "\tKD_LOSS: 0.18478195897386043\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.045957545439403\n",
      "\tMAIN_LOSS: 3.457636003692945\n",
      "\tKD_LOSS: 0.19610718016823134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.883       0.79      0.887      0.622\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch170\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 170 END --------------------\n",
      "-------------------- EPOCH 171 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7951339121106304\n",
      "\tMAIN_LOSS: 1.2291771007489554\n",
      "\tKD_LOSS: 0.18865227152275132\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8948378761609397\n",
      "\tMAIN_LOSS: 3.2904971639315286\n",
      "\tKD_LOSS: 0.2014468957980474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.965       0.77      0.868      0.621\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch171\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 171 END --------------------\n",
      "-------------------- EPOCH 172 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7976558163196226\n",
      "\tMAIN_LOSS: 1.2362275538565237\n",
      "\tKD_LOSS: 0.1871427557890928\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.072616696357727\n",
      "\tMAIN_LOSS: 3.476442982753118\n",
      "\tKD_LOSS: 0.19872457906603813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181      0.934      0.751      0.863      0.609\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch172\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 172 END --------------------\n",
      "-------------------- EPOCH 173 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7401268934901757\n",
      "\tMAIN_LOSS: 1.1872714757919312\n",
      "\tKD_LOSS: 0.18428514067885243\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.924556920925776\n",
      "\tMAIN_LOSS: 3.3557113806406655\n",
      "\tKD_LOSS: 0.1896151682982842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.921      0.777      0.885      0.634\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch173\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173: New best mAP: 0.6339, model saved.\n",
      "-------------------- EPOCH 173 END --------------------\n",
      "-------------------- EPOCH 174 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7177156028868277\n",
      "\tMAIN_LOSS: 1.1734987263438068\n",
      "\tKD_LOSS: 0.18140562425685836\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9913650155067444\n",
      "\tMAIN_LOSS: 3.4202205737431846\n",
      "\tKD_LOSS: 0.19038147293031216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.937      0.733      0.862      0.617\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch174\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 174 END --------------------\n",
      "-------------------- EPOCH 175 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.756416228753102\n",
      "\tMAIN_LOSS: 1.2044112395636644\n",
      "\tKD_LOSS: 0.18400166155416756\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.030488342046738\n",
      "\tMAIN_LOSS: 3.4589947362740836\n",
      "\tKD_LOSS: 0.1904978690048059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.40it/s]\n",
      "                   all        376        181      0.965      0.773      0.892      0.619\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch175\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 175 END --------------------\n",
      "-------------------- EPOCH 176 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7190892786919316\n",
      "\tMAIN_LOSS: 1.1689004392563542\n",
      "\tKD_LOSS: 0.18339627962323685\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.033201475938161\n",
      "\tMAIN_LOSS: 3.4572684516509375\n",
      "\tKD_LOSS: 0.19197767972946167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.887      0.796      0.879      0.623\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch176\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 176 END --------------------\n",
      "-------------------- EPOCH 177 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7022096831587297\n",
      "\tMAIN_LOSS: 1.1596377439136747\n",
      "\tKD_LOSS: 0.1808573130188109\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9788531064987183\n",
      "\tMAIN_LOSS: 3.4196425080299377\n",
      "\tKD_LOSS: 0.18640354027350745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.932      0.755      0.867      0.617\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch177\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 177 END --------------------\n",
      "-------------------- EPOCH 178 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7091187932823277\n",
      "\tMAIN_LOSS: 1.1696117550511904\n",
      "\tKD_LOSS: 0.17983567884451226\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.243654529253642\n",
      "\tMAIN_LOSS: 3.6645914812882743\n",
      "\tKD_LOSS: 0.19302102364599705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.932      0.755      0.846      0.593\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch178\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 178 END --------------------\n",
      "-------------------- EPOCH 179 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7577730341802669\n",
      "\tMAIN_LOSS: 1.2094785374931143\n",
      "\tKD_LOSS: 0.1827648327320437\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.045450518528621\n",
      "\tMAIN_LOSS: 3.4569573203722634\n",
      "\tKD_LOSS: 0.19616438945134482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.962      0.751      0.873      0.631\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch179\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 179 END --------------------\n",
      "-------------------- EPOCH 180 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.715428027925612\n",
      "\tMAIN_LOSS: 1.1743102654626099\n",
      "\tKD_LOSS: 0.1803725854128222\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.906462788581848\n",
      "\tMAIN_LOSS: 3.3422259291013083\n",
      "\tKD_LOSS: 0.18807895543674627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181      0.897      0.768      0.874      0.617\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch180\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 180 END --------------------\n",
      "-------------------- EPOCH 181 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7051826353314556\n",
      "\tMAIN_LOSS: 1.1707426354854922\n",
      "\tKD_LOSS: 0.17814666636382478\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9407889346281686\n",
      "\tMAIN_LOSS: 3.3536616265773773\n",
      "\tKD_LOSS: 0.19570910496016344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.882      0.829      0.886      0.626\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch181\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 181 END --------------------\n",
      "-------------------- EPOCH 182 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.695798557015914\n",
      "\tMAIN_LOSS: 1.1615065426766118\n",
      "\tKD_LOSS: 0.17809733729573746\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9419363935788474\n",
      "\tMAIN_LOSS: 3.3847744464874268\n",
      "\tKD_LOSS: 0.1857206498583158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.902      0.779      0.867      0.609\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch182\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 182 END --------------------\n",
      "-------------------- EPOCH 183 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6886823871467687\n",
      "\tMAIN_LOSS: 1.1564657273171823\n",
      "\tKD_LOSS: 0.1774055523962914\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.048868238925934\n",
      "\tMAIN_LOSS: 3.492600232362747\n",
      "\tKD_LOSS: 0.18542266885439554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.40it/s]\n",
      "                   all        376        181      0.891      0.768      0.864      0.615\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch183\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 183 END --------------------\n",
      "-------------------- EPOCH 184 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6748006343841553\n",
      "\tMAIN_LOSS: 1.1473691757721236\n",
      "\tKD_LOSS: 0.17581048796448526\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.926238918056091\n",
      "\tMAIN_LOSS: 3.375447561343511\n",
      "\tKD_LOSS: 0.1835971319427093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.979      0.771       0.89      0.638\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch184\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184: New best mAP: 0.6377, model saved.\n",
      "-------------------- EPOCH 184 END --------------------\n",
      "-------------------- EPOCH 185 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6677682565737375\n",
      "\tMAIN_LOSS: 1.14343727766713\n",
      "\tKD_LOSS: 0.17477699378623238\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.857892155647278\n",
      "\tMAIN_LOSS: 3.307963341474533\n",
      "\tKD_LOSS: 0.18330960099895796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.945      0.759      0.878      0.627\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch185\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 185 END --------------------\n",
      "-------------------- EPOCH 186 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6617148028144353\n",
      "\tMAIN_LOSS: 1.1350192925598048\n",
      "\tKD_LOSS: 0.17556516958188406\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.014167815446854\n",
      "\tMAIN_LOSS: 3.4520053962866464\n",
      "\tKD_LOSS: 0.1873874720185995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.885      0.767      0.863      0.615\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch186\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 186 END --------------------\n",
      "-------------------- EPOCH 187 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7020203327830834\n",
      "\tMAIN_LOSS: 1.1708513068247446\n",
      "\tKD_LOSS: 0.17705634330646902\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.155746748050054\n",
      "\tMAIN_LOSS: 3.5994954854249954\n",
      "\tKD_LOSS: 0.1854170976827542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.945      0.729      0.858      0.605\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch187\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 187 END --------------------\n",
      "-------------------- EPOCH 188 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6609734281708923\n",
      "\tMAIN_LOSS: 1.1342139364797859\n",
      "\tKD_LOSS: 0.17558649635013146\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.99555371205012\n",
      "\tMAIN_LOSS: 3.4406486650307975\n",
      "\tKD_LOSS: 0.1849683467298746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.911      0.795      0.875      0.623\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch188\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 188 END --------------------\n",
      "-------------------- EPOCH 189 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6960187245018874\n",
      "\tMAIN_LOSS: 1.1663658151143714\n",
      "\tKD_LOSS: 0.17655096778386756\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.040072123209636\n",
      "\tMAIN_LOSS: 3.4326282093922296\n",
      "\tKD_LOSS: 0.20248130212227503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181       0.94      0.801      0.878      0.617\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch189\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 189 END --------------------\n",
      "-------------------- EPOCH 190 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7133104710639278\n",
      "\tMAIN_LOSS: 1.172652689716484\n",
      "\tKD_LOSS: 0.18021926264974136\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.046292831500371\n",
      "\tMAIN_LOSS: 3.4974952240784964\n",
      "\tKD_LOSS: 0.1829325413952271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181      0.972      0.767      0.886      0.627\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch190\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 190 END --------------------\n",
      "-------------------- EPOCH 191 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6794071016432364\n",
      "\tMAIN_LOSS: 1.155085169816319\n",
      "\tKD_LOSS: 0.1747739756409126\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.111649662256241\n",
      "\tMAIN_LOSS: 3.567509909470876\n",
      "\tKD_LOSS: 0.18137992111345133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.884      0.798      0.879      0.618\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch191\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 191 END --------------------\n",
      "-------------------- EPOCH 192 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6530138812487638\n",
      "\tMAIN_LOSS: 1.1347663198845297\n",
      "\tKD_LOSS: 0.17274918605255174\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.058327714602153\n",
      "\tMAIN_LOSS: 3.492022693157196\n",
      "\tKD_LOSS: 0.18876833841204643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.899      0.783       0.86      0.604\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch192\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 192 END --------------------\n",
      "-------------------- EPOCH 193 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6655959502051148\n",
      "\tMAIN_LOSS: 1.147662107703052\n",
      "\tKD_LOSS: 0.17264461460747296\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9722646673520408\n",
      "\tMAIN_LOSS: 3.4227392872174582\n",
      "\tKD_LOSS: 0.18317513292034468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.899      0.783      0.873      0.617\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch193\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 193 END --------------------\n",
      "-------------------- EPOCH 194 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6251040802726262\n",
      "\tMAIN_LOSS: 1.1123062809811364\n",
      "\tKD_LOSS: 0.17093259869497032\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.195294916629791\n",
      "\tMAIN_LOSS: 3.6572702328364053\n",
      "\tKD_LOSS: 0.17934157885611057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.867      0.807      0.867       0.61\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.2ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch194\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 194 END --------------------\n",
      "-------------------- EPOCH 195 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6531646704371972\n",
      "\tMAIN_LOSS: 1.1406567836109596\n",
      "\tKD_LOSS: 0.17083596183529384\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.931986848513285\n",
      "\tMAIN_LOSS: 3.3972648282845817\n",
      "\tKD_LOSS: 0.17824067237476507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.899      0.796      0.872      0.619\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch195\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 195 END --------------------\n",
      "-------------------- EPOCH 196 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6476844760436047\n",
      "\tMAIN_LOSS: 1.1392969179757033\n",
      "\tKD_LOSS: 0.16946251765836642\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.068506687879562\n",
      "\tMAIN_LOSS: 3.527592053016027\n",
      "\tKD_LOSS: 0.18030487125118574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.905      0.796      0.882      0.636\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch196\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 196 END --------------------\n",
      "-------------------- EPOCH 197 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6342271136332163\n",
      "\tMAIN_LOSS: 1.121946057186851\n",
      "\tKD_LOSS: 0.17076035164579562\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.157656560341517\n",
      "\tMAIN_LOSS: 3.601339270671209\n",
      "\tKD_LOSS: 0.18543908558785915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.911      0.779      0.891      0.622\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch197\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 197 END --------------------\n",
      "-------------------- EPOCH 198 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.653618128239354\n",
      "\tMAIN_LOSS: 1.1299173635772513\n",
      "\tKD_LOSS: 0.17456691985643363\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.033236215511958\n",
      "\tMAIN_LOSS: 3.432550917069117\n",
      "\tKD_LOSS: 0.20022842474281788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.914      0.762      0.845      0.589\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch198\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 198 END --------------------\n",
      "-------------------- EPOCH 199 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7268408914155597\n",
      "\tMAIN_LOSS: 1.200048258787469\n",
      "\tKD_LOSS: 0.17559754508960096\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.384426226218541\n",
      "\tMAIN_LOSS: 3.8182399769624076\n",
      "\tKD_LOSS: 0.18872875099380812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181       0.89       0.74      0.838      0.592\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch199\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 199 END --------------------\n",
      "-------------------- EPOCH 200 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.732303729540185\n",
      "\tMAIN_LOSS: 1.2040728051451188\n",
      "\tKD_LOSS: 0.17607697750194162\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.00824440519015\n",
      "\tMAIN_LOSS: 3.4623986581961312\n",
      "\tKD_LOSS: 0.18194857239723206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.966      0.777      0.889      0.639\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch200\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: New best mAP: 0.6393, model saved.\n",
      "-------------------- EPOCH 200 END --------------------\n",
      "-------------------- EPOCH 201 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7095876343642609\n",
      "\tMAIN_LOSS: 1.1894333415393588\n",
      "\tKD_LOSS: 0.1733847637719746\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.1535924077034\n",
      "\tMAIN_LOSS: 3.6014724473158517\n",
      "\tKD_LOSS: 0.184039997557799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.906       0.79       0.88      0.622\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch201\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 201 END --------------------\n",
      "-------------------- EPOCH 202 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6875323253341867\n",
      "\tMAIN_LOSS: 1.1689849141277844\n",
      "\tKD_LOSS: 0.1728491373831713\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9578984677791595\n",
      "\tMAIN_LOSS: 3.3915629585584006\n",
      "\tKD_LOSS: 0.18877850162486234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.956      0.746      0.863      0.612\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch202\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 202 END --------------------\n",
      "-------------------- EPOCH 203 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6784839449049551\n",
      "\tMAIN_LOSS: 1.161791361585448\n",
      "\tKD_LOSS: 0.17223086217536202\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.13222982486089\n",
      "\tMAIN_LOSS: 3.5900641481081643\n",
      "\tKD_LOSS: 0.18072188273072243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.933      0.768      0.878      0.625\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch203\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 203 END --------------------\n",
      "-------------------- EPOCH 204 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6542641301698322\n",
      "\tMAIN_LOSS: 1.1441799311698237\n",
      "\tKD_LOSS: 0.1700280652016024\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8674978613853455\n",
      "\tMAIN_LOSS: 3.3332321643829346\n",
      "\tKD_LOSS: 0.17808856380482516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181      0.914      0.773       0.86      0.619\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch204\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 204 END --------------------\n",
      "-------------------- EPOCH 205 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6568261415143557\n",
      "\tMAIN_LOSS: 1.1509887100775031\n",
      "\tKD_LOSS: 0.16861247922046274\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8724756936232247\n",
      "\tMAIN_LOSS: 3.337927629550298\n",
      "\tKD_LOSS: 0.1781826913356781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.958      0.757      0.882       0.62\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch205\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 205 END --------------------\n",
      "-------------------- EPOCH 206 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6675877963440329\n",
      "\tMAIN_LOSS: 1.1546244470379021\n",
      "\tKD_LOSS: 0.1709877854283852\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.84181738893191\n",
      "\tMAIN_LOSS: 3.3039087851842246\n",
      "\tKD_LOSS: 0.17930287308990955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181       0.87      0.773      0.858      0.621\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch206\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 206 END --------------------\n",
      "-------------------- EPOCH 207 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.645253975180131\n",
      "\tMAIN_LOSS: 1.1437761896773229\n",
      "\tKD_LOSS: 0.1671592598851723\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8695856432120004\n",
      "\tMAIN_LOSS: 3.342662533124288\n",
      "\tKD_LOSS: 0.1756410375237465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.944      0.751      0.866      0.631\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch207\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 207 END --------------------\n",
      "-------------------- EPOCH 208 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6328164610681655\n",
      "\tMAIN_LOSS: 1.1327903534792647\n",
      "\tKD_LOSS: 0.16667537240287925\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.0666224360466\n",
      "\tMAIN_LOSS: 3.5397180716196694\n",
      "\tKD_LOSS: 0.17563479890426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.934       0.78      0.886      0.634\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch208\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 208 END --------------------\n",
      "-------------------- EPOCH 209 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6246999155116986\n",
      "\tMAIN_LOSS: 1.127786290042008\n",
      "\tKD_LOSS: 0.16563787490506715\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9875035683314004\n",
      "\tMAIN_LOSS: 3.460780809322993\n",
      "\tKD_LOSS: 0.17557424493134022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.942      0.779      0.878       0.62\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch209\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 209 END --------------------\n",
      "-------------------- EPOCH 210 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.631411006179037\n",
      "\tMAIN_LOSS: 1.1357386640355558\n",
      "\tKD_LOSS: 0.16522411492806446\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.052677532037099\n",
      "\tMAIN_LOSS: 3.526053696870804\n",
      "\tKD_LOSS: 0.17554129163424173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181       0.91      0.796      0.883      0.634\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch210\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 210 END --------------------\n",
      "-------------------- EPOCH 211 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6300655444966088\n",
      "\tMAIN_LOSS: 1.1340118171293525\n",
      "\tKD_LOSS: 0.16535124427910092\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.98494345943133\n",
      "\tMAIN_LOSS: 3.4700941046079\n",
      "\tKD_LOSS: 0.171616455540061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181       0.94       0.79      0.881      0.629\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch211\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 211 END --------------------\n",
      "-------------------- EPOCH 212 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6253140168853952\n",
      "\tMAIN_LOSS: 1.1299996934359586\n",
      "\tKD_LOSS: 0.16510477398015275\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.845591127872467\n",
      "\tMAIN_LOSS: 3.3349551409482956\n",
      "\tKD_LOSS: 0.17021198632816473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.905      0.788      0.882      0.634\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch212\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 212 END --------------------\n",
      "-------------------- EPOCH 213 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6157674291465856\n",
      "\tMAIN_LOSS: 1.1247426595868943\n",
      "\tKD_LOSS: 0.16367492607877224\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.843183197081089\n",
      "\tMAIN_LOSS: 3.3247512181599936\n",
      "\tKD_LOSS: 0.17281066998839378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.39it/s]\n",
      "                   all        376        181      0.929      0.785       0.87      0.614\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch213\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 213 END --------------------\n",
      "-------------------- EPOCH 214 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6233059982710247\n",
      "\tMAIN_LOSS: 1.1320472729356983\n",
      "\tKD_LOSS: 0.1637529083822347\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.086121728022893\n",
      "\tMAIN_LOSS: 3.5761780937512717\n",
      "\tKD_LOSS: 0.16998121390740076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.923      0.794      0.881      0.635\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch214\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 214 END --------------------\n",
      "-------------------- EPOCH 215 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6175154839889914\n",
      "\tMAIN_LOSS: 1.130818576752385\n",
      "\tKD_LOSS: 0.16223230146909062\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.11331723133723\n",
      "\tMAIN_LOSS: 3.5983992417653403\n",
      "\tKD_LOSS: 0.17163932075103125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.928      0.778      0.867      0.621\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch215\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 215 END --------------------\n",
      "-------------------- EPOCH 216 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.610445478294469\n",
      "\tMAIN_LOSS: 1.1211573798445207\n",
      "\tKD_LOSS: 0.1630960350172429\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.257496039072673\n",
      "\tMAIN_LOSS: 3.723153680562973\n",
      "\tKD_LOSS: 0.1781141310930252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.873      0.799      0.873      0.606\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch216\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 216 END --------------------\n",
      "-------------------- EPOCH 217 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5999484103691728\n",
      "\tMAIN_LOSS: 1.1129597251928305\n",
      "\tKD_LOSS: 0.16232956247993663\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.094680776198705\n",
      "\tMAIN_LOSS: 3.573549638191859\n",
      "\tKD_LOSS: 0.17371039216717085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.877      0.746      0.855      0.619\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch217\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 217 END --------------------\n",
      "-------------------- EPOCH 218 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5919428837450245\n",
      "\tMAIN_LOSS: 1.110329598565645\n",
      "\tKD_LOSS: 0.1605377638641792\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9851849575837455\n",
      "\tMAIN_LOSS: 3.4724558293819427\n",
      "\tKD_LOSS: 0.17090971892078718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181      0.946      0.751      0.874      0.627\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch218\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 218 END --------------------\n",
      "-------------------- EPOCH 219 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5847559216656262\n",
      "\tMAIN_LOSS: 1.1038741197767137\n",
      "\tKD_LOSS: 0.16029393691805344\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.127235561609268\n",
      "\tMAIN_LOSS: 3.6176862716674805\n",
      "\tKD_LOSS: 0.1698497465501229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.905      0.785      0.884      0.622\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch219\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 219 END --------------------\n",
      "-------------------- EPOCH 220 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.60013927236388\n",
      "\tMAIN_LOSS: 1.1162178320220755\n",
      "\tKD_LOSS: 0.16130714646623104\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8154530127843223\n",
      "\tMAIN_LOSS: 3.305013249317805\n",
      "\tKD_LOSS: 0.17014658078551292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.914       0.79      0.885      0.631\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch220\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 220 END --------------------\n",
      "-------------------- EPOCH 221 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6049591046345384\n",
      "\tMAIN_LOSS: 1.1128648089457163\n",
      "\tKD_LOSS: 0.1640314318334\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9420289397239685\n",
      "\tMAIN_LOSS: 3.429475804169973\n",
      "\tKD_LOSS: 0.17085105118652186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.948      0.806      0.888      0.629\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch221\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 221 END --------------------\n",
      "-------------------- EPOCH 222 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5977221667012083\n",
      "\tMAIN_LOSS: 1.117049995856949\n",
      "\tKD_LOSS: 0.16022405575347853\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9235961039861045\n",
      "\tMAIN_LOSS: 3.421649754047394\n",
      "\tKD_LOSS: 0.16731544894476733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181       0.96       0.79      0.887      0.631\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch222\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 222 END --------------------\n",
      "-------------------- EPOCH 223 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.593627869328366\n",
      "\tMAIN_LOSS: 1.1158013155188742\n",
      "\tKD_LOSS: 0.15927551894248287\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9963513811429343\n",
      "\tMAIN_LOSS: 3.485220650831858\n",
      "\tKD_LOSS: 0.17037692107260227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.921      0.777      0.868      0.614\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch223\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 223 END --------------------\n",
      "-------------------- EPOCH 224 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5717026945910877\n",
      "\tMAIN_LOSS: 1.0956617691848851\n",
      "\tKD_LOSS: 0.15868030922322335\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9677965342998505\n",
      "\tMAIN_LOSS: 3.459193820754687\n",
      "\tKD_LOSS: 0.16953423619270325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.944      0.779      0.865      0.628\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch224\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 224 END --------------------\n",
      "-------------------- EPOCH 225 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5822510658940183\n",
      "\tMAIN_LOSS: 1.104345384277875\n",
      "\tKD_LOSS: 0.15930189286606222\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.012177914381027\n",
      "\tMAIN_LOSS: 3.504963129758835\n",
      "\tKD_LOSS: 0.16907158307731152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.946      0.768      0.881      0.633\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch225\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 225 END --------------------\n",
      "-------------------- EPOCH 226 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6006225038178359\n",
      "\tMAIN_LOSS: 1.1151001227052906\n",
      "\tKD_LOSS: 0.1618407932640631\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.096523821353912\n",
      "\tMAIN_LOSS: 3.5808277825514474\n",
      "\tKD_LOSS: 0.1718986885001262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181      0.908      0.768      0.864      0.604\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.2ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch226\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 226 END --------------------\n",
      "-------------------- EPOCH 227 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5741407961785039\n",
      "\tMAIN_LOSS: 1.0990908553328695\n",
      "\tKD_LOSS: 0.15834998028187813\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.7444569704433284\n",
      "\tMAIN_LOSS: 3.252582142750422\n",
      "\tKD_LOSS: 0.16395827817420164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181       0.94      0.785      0.884      0.629\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch227\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 227 END --------------------\n",
      "-------------------- EPOCH 228 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5720994306516043\n",
      "\tMAIN_LOSS: 1.0979941992820064\n",
      "\tKD_LOSS: 0.1580350778148144\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.147600789864858\n",
      "\tMAIN_LOSS: 3.6378263036410012\n",
      "\tKD_LOSS: 0.1699248297760884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181       0.89      0.762      0.855      0.602\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch228\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 228 END --------------------\n",
      "-------------------- EPOCH 229 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.598321938062016\n",
      "\tMAIN_LOSS: 1.1134929423090778\n",
      "\tKD_LOSS: 0.16160966663420956\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8616998294989267\n",
      "\tMAIN_LOSS: 3.320520281791687\n",
      "\tKD_LOSS: 0.18039318670829138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.929      0.785      0.857      0.604\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch229\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 229 END --------------------\n",
      "-------------------- EPOCH 230 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6203517974177493\n",
      "\tMAIN_LOSS: 1.1332973332344731\n",
      "\tKD_LOSS: 0.1623514868036101\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.118660181760788\n",
      "\tMAIN_LOSS: 3.6085408329963684\n",
      "\tKD_LOSS: 0.17003978105882803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.952       0.77       0.87      0.618\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch230\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 230 END --------------------\n",
      "-------------------- EPOCH 231 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5986994542653048\n",
      "\tMAIN_LOSS: 1.1213888865482957\n",
      "\tKD_LOSS: 0.15910352332682548\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.052280445893605\n",
      "\tMAIN_LOSS: 3.5368166267871857\n",
      "\tKD_LOSS: 0.17182127634684244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.966      0.796      0.888      0.628\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch231\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 231 END --------------------\n",
      "-------------------- EPOCH 232 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5797487195534041\n",
      "\tMAIN_LOSS: 1.109337403804441\n",
      "\tKD_LOSS: 0.15680376940135715\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.640388856331507\n",
      "\tMAIN_LOSS: 3.147077073653539\n",
      "\tKD_LOSS: 0.16443725489079952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.934      0.785      0.886      0.634\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch232\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 232 END --------------------\n",
      "-------------------- EPOCH 233 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5741131366053713\n",
      "\tMAIN_LOSS: 1.104348682150056\n",
      "\tKD_LOSS: 0.15658814959888218\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.115755081176758\n",
      "\tMAIN_LOSS: 3.6223975817362466\n",
      "\tKD_LOSS: 0.16445249505341053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181       0.91      0.778      0.863       0.62\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch233\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 233 END --------------------\n",
      "-------------------- EPOCH 234 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5851065886171558\n",
      "\tMAIN_LOSS: 1.1119605340535128\n",
      "\tKD_LOSS: 0.1577153502008583\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.941705127557119\n",
      "\tMAIN_LOSS: 3.427239845196406\n",
      "\tKD_LOSS: 0.17148842724661031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.896       0.79      0.871       0.62\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch234\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 234 END --------------------\n",
      "-------------------- EPOCH 235 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5746646259404435\n",
      "\tMAIN_LOSS: 1.1014411079732678\n",
      "\tKD_LOSS: 0.15774117372458493\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.939477950334549\n",
      "\tMAIN_LOSS: 3.44432399670283\n",
      "\tKD_LOSS: 0.1650513205677271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.922      0.788       0.89      0.631\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch235\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 235 END --------------------\n",
      "-------------------- EPOCH 236 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5635337437255472\n",
      "\tMAIN_LOSS: 1.0944528640071047\n",
      "\tKD_LOSS: 0.1563602940568441\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9763337771097818\n",
      "\tMAIN_LOSS: 3.4844556152820587\n",
      "\tKD_LOSS: 0.16395936782161394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.944      0.762      0.877      0.639\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch236\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 236 END --------------------\n",
      "-------------------- EPOCH 237 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.567958812170391\n",
      "\tMAIN_LOSS: 1.1014425166045563\n",
      "\tKD_LOSS: 0.15550543273551554\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.898343692223231\n",
      "\tMAIN_LOSS: 3.4087354938189187\n",
      "\tKD_LOSS: 0.16320272162556648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.951      0.753      0.876      0.646\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch237\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237: New best mAP: 0.6459, model saved.\n",
      "-------------------- EPOCH 237 END --------------------\n",
      "-------------------- EPOCH 238 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5941844952257374\n",
      "\tMAIN_LOSS: 1.119905308077607\n",
      "\tKD_LOSS: 0.15809306238271012\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.94788392384847\n",
      "\tMAIN_LOSS: 3.431074778238932\n",
      "\tKD_LOSS: 0.17226971996327242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181       0.89      0.757      0.851      0.614\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch238\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 238 END --------------------\n",
      "-------------------- EPOCH 239 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5870060754727713\n",
      "\tMAIN_LOSS: 1.1141988393626636\n",
      "\tKD_LOSS: 0.1576024118480803\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9407509664694467\n",
      "\tMAIN_LOSS: 3.434719050923983\n",
      "\tKD_LOSS: 0.1686773163576921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.937      0.785      0.883      0.634\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch239\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 239 END --------------------\n",
      "-------------------- EPOCH 240 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5702213626119155\n",
      "\tMAIN_LOSS: 1.1012805790840825\n",
      "\tKD_LOSS: 0.1563135936290403\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.11098234852155\n",
      "\tMAIN_LOSS: 3.6286984582742057\n",
      "\tKD_LOSS: 0.1607612930238247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.946      0.772      0.873      0.643\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch240\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 240 END --------------------\n",
      "-------------------- EPOCH 241 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6095296008677422\n",
      "\tMAIN_LOSS: 1.1245382035834879\n",
      "\tKD_LOSS: 0.16166379915762552\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9922297994295755\n",
      "\tMAIN_LOSS: 3.4605000813802085\n",
      "\tKD_LOSS: 0.1772432296226422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181      0.943      0.751      0.874      0.599\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch241\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 241 END --------------------\n",
      "-------------------- EPOCH 242 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.603615317163588\n",
      "\tMAIN_LOSS: 1.1273142046566251\n",
      "\tKD_LOSS: 0.1587670377538174\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.88420241077741\n",
      "\tMAIN_LOSS: 3.3891792744398117\n",
      "\tKD_LOSS: 0.16500771356125674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.922      0.757      0.861      0.618\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch242\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 242 END --------------------\n",
      "-------------------- EPOCH 243 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5777391165117673\n",
      "\tMAIN_LOSS: 1.1127848874164532\n",
      "\tKD_LOSS: 0.1549847420257858\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8632767299811044\n",
      "\tMAIN_LOSS: 3.3688412408034005\n",
      "\tKD_LOSS: 0.16481181917091212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.869      0.785      0.864      0.616\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch243\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 243 END --------------------\n",
      "-------------------- EPOCH 244 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5471820740760127\n",
      "\tMAIN_LOSS: 1.0869227979756608\n",
      "\tKD_LOSS: 0.15341975964322874\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.94630899031957\n",
      "\tMAIN_LOSS: 3.4231964747111\n",
      "\tKD_LOSS: 0.17437083957095942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.939       0.76      0.871      0.638\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch244\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 244 END --------------------\n",
      "-------------------- EPOCH 245 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.8501657896404025\n",
      "\tMAIN_LOSS: 1.2854086190839358\n",
      "\tKD_LOSS: 0.18825238886513287\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.86854887008667\n",
      "\tMAIN_LOSS: 3.3200595130523047\n",
      "\tKD_LOSS: 0.18282978050410748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.40it/s]\n",
      "                   all        376        181      0.953      0.768      0.858      0.597\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch245\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 245 END --------------------\n",
      "-------------------- EPOCH 246 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6952027927471112\n",
      "\tMAIN_LOSS: 1.1933742821971072\n",
      "\tKD_LOSS: 0.16727616798274125\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.020218541224797\n",
      "\tMAIN_LOSS: 3.485836694637934\n",
      "\tKD_LOSS: 0.17812729813158512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.965      0.761      0.843      0.592\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch246\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 246 END --------------------\n",
      "-------------------- EPOCH 247 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6268783355061012\n",
      "\tMAIN_LOSS: 1.1404281334031987\n",
      "\tKD_LOSS: 0.16215006573290763\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.879140535990397\n",
      "\tMAIN_LOSS: 3.372039943933487\n",
      "\tKD_LOSS: 0.16903354662160078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.919       0.79      0.878      0.618\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch247\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 247 END --------------------\n",
      "-------------------- EPOCH 248 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5855014475086067\n",
      "\tMAIN_LOSS: 1.1111284411406215\n",
      "\tKD_LOSS: 0.15812433558174327\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.790885160366694\n",
      "\tMAIN_LOSS: 3.2893225948015847\n",
      "\tKD_LOSS: 0.167187529305617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.948      0.768      0.873      0.627\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch248\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 248 END --------------------\n",
      "-------------------- EPOCH 249 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5614209280738347\n",
      "\tMAIN_LOSS: 1.0934804376167586\n",
      "\tKD_LOSS: 0.1559801612850986\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8334206342697144\n",
      "\tMAIN_LOSS: 3.344973067442576\n",
      "\tKD_LOSS: 0.16281585271159807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.951      0.773      0.878      0.628\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch249\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 249 END --------------------\n",
      "-------------------- EPOCH 250 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5264896569372732\n",
      "\tMAIN_LOSS: 1.0653875326808495\n",
      "\tKD_LOSS: 0.1537007108519349\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.850724011659622\n",
      "\tMAIN_LOSS: 3.3756357530752816\n",
      "\tKD_LOSS: 0.1583627431342999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.918       0.79      0.878      0.635\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch250\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 250 END --------------------\n",
      "-------------------- EPOCH 251 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5226816738708109\n",
      "\tMAIN_LOSS: 1.068997003609621\n",
      "\tKD_LOSS: 0.15122822379764123\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8793951968352\n",
      "\tMAIN_LOSS: 3.4083972175916037\n",
      "\tKD_LOSS: 0.15699932103355727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.905       0.79      0.875      0.632\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch251\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 251 END --------------------\n",
      "-------------------- EPOCH 252 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.513138182555573\n",
      "\tMAIN_LOSS: 1.0610426166389562\n",
      "\tKD_LOSS: 0.1506985237326803\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8516564667224884\n",
      "\tMAIN_LOSS: 3.376264125108719\n",
      "\tKD_LOSS: 0.1584641064206759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.916       0.78      0.872      0.629\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch252\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 252 END --------------------\n",
      "-------------------- EPOCH 253 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.487662854828412\n",
      "\tMAIN_LOSS: 1.0382898185826555\n",
      "\tKD_LOSS: 0.1497910135908972\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.816400557756424\n",
      "\tMAIN_LOSS: 3.3466662764549255\n",
      "\tKD_LOSS: 0.1565780850748221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.914      0.768      0.875      0.631\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch253\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 253 END --------------------\n",
      "-------------------- EPOCH 254 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5184522882292542\n",
      "\tMAIN_LOSS: 1.0675109526779079\n",
      "\tKD_LOSS: 0.15031377839136728\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8575276732444763\n",
      "\tMAIN_LOSS: 3.3790347079435983\n",
      "\tKD_LOSS: 0.1594976627578338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.922      0.782      0.879      0.633\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch254\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 254 END --------------------\n",
      "-------------------- EPOCH 255 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4981822454476659\n",
      "\tMAIN_LOSS: 1.0509049869790863\n",
      "\tKD_LOSS: 0.14909241886078556\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.049249351024628\n",
      "\tMAIN_LOSS: 3.5820798774560294\n",
      "\tKD_LOSS: 0.15572315889100233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.895      0.807      0.874      0.631\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch255\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 255 END --------------------\n",
      "-------------------- EPOCH 256 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4950186919562425\n",
      "\tMAIN_LOSS: 1.0515798134139822\n",
      "\tKD_LOSS: 0.14781296026857593\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.807852248350779\n",
      "\tMAIN_LOSS: 3.3437436719735465\n",
      "\tKD_LOSS: 0.15470285713672638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.958       0.76      0.867      0.634\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch256\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 256 END --------------------\n",
      "-------------------- EPOCH 257 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5002959302709074\n",
      "\tMAIN_LOSS: 1.0557195695140693\n",
      "\tKD_LOSS: 0.14819211956066422\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.785748372475306\n",
      "\tMAIN_LOSS: 3.3214591443538666\n",
      "\tKD_LOSS: 0.15476308142145476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.939      0.773      0.879      0.633\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch257\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 257 END --------------------\n",
      "-------------------- EPOCH 258 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4980628083023844\n",
      "\tMAIN_LOSS: 1.0558111169670201\n",
      "\tKD_LOSS: 0.14741722956488404\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.7633492747942605\n",
      "\tMAIN_LOSS: 3.297809590895971\n",
      "\tKD_LOSS: 0.15517988801002502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.915       0.79      0.876      0.628\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch258\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 258 END --------------------\n",
      "-------------------- EPOCH 259 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5110605457161046\n",
      "\tMAIN_LOSS: 1.0683872722372223\n",
      "\tKD_LOSS: 0.14755775807779045\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.946996957063675\n",
      "\tMAIN_LOSS: 3.444920023282369\n",
      "\tKD_LOSS: 0.16735899137953916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.909      0.801      0.888      0.633\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch259\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 259 END --------------------\n",
      "-------------------- EPOCH 260 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5187560621696183\n",
      "\tMAIN_LOSS: 1.0691739577281325\n",
      "\tKD_LOSS: 0.1498607010403766\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.780923346678416\n",
      "\tMAIN_LOSS: 3.3126361270745597\n",
      "\tKD_LOSS: 0.15609575000902018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.928      0.787      0.877      0.641\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch260\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 260 END --------------------\n",
      "-------------------- EPOCH 261 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.512973047509978\n",
      "\tMAIN_LOSS: 1.0708056937290142\n",
      "\tKD_LOSS: 0.1473891156006463\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.026145766178767\n",
      "\tMAIN_LOSS: 3.553854395945867\n",
      "\tKD_LOSS: 0.15743047247330347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.891      0.785      0.888      0.649\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch261\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261: New best mAP: 0.6493, model saved.\n",
      "-------------------- EPOCH 261 END --------------------\n",
      "-------------------- EPOCH 262 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5235350267796577\n",
      "\tMAIN_LOSS: 1.0794276640385012\n",
      "\tKD_LOSS: 0.14803578864924516\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8019743859767914\n",
      "\tMAIN_LOSS: 3.33983384569486\n",
      "\tKD_LOSS: 0.15404684096574783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.928      0.788      0.885      0.632\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch262\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 262 END --------------------\n",
      "-------------------- EPOCH 263 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5059153837493704\n",
      "\tMAIN_LOSS: 1.0665315683883956\n",
      "\tKD_LOSS: 0.1464612731073476\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.75925878683726\n",
      "\tMAIN_LOSS: 3.297099287311236\n",
      "\tKD_LOSS: 0.15405316837131977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181      0.916      0.785      0.881      0.641\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch263\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 263 END --------------------\n",
      "-------------------- EPOCH 264 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5245981661579278\n",
      "\tMAIN_LOSS: 1.0748463454125803\n",
      "\tKD_LOSS: 0.14991727320453788\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.1123640437920885\n",
      "\tMAIN_LOSS: 3.541084041198095\n",
      "\tKD_LOSS: 0.1904266712566217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.972      0.718      0.856      0.614\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch264\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 264 END --------------------\n",
      "-------------------- EPOCH 265 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.7184378240681901\n",
      "\tMAIN_LOSS: 1.2169890132131456\n",
      "\tKD_LOSS: 0.16714960412134097\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.01531199614207\n",
      "\tMAIN_LOSS: 3.4382951805988946\n",
      "\tKD_LOSS: 0.19233892175058523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.921      0.735       0.84      0.555\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch265\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 265 END --------------------\n",
      "-------------------- EPOCH 266 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6650587984278231\n",
      "\tMAIN_LOSS: 1.1782444836218147\n",
      "\tKD_LOSS: 0.162271436633943\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9629560808340707\n",
      "\tMAIN_LOSS: 3.472533086935679\n",
      "\tKD_LOSS: 0.16347432819505534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181       0.89      0.762      0.866      0.606\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch266\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 266 END --------------------\n",
      "-------------------- EPOCH 267 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5823632192008104\n",
      "\tMAIN_LOSS: 1.1190179073357884\n",
      "\tKD_LOSS: 0.15444843735121475\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.699155086030563\n",
      "\tMAIN_LOSS: 3.214234600464503\n",
      "\tKD_LOSS: 0.16164016164839268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.911       0.79      0.876      0.631\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch267\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 267 END --------------------\n",
      "-------------------- EPOCH 268 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5471405394469635\n",
      "\tMAIN_LOSS: 1.093879884556879\n",
      "\tKD_LOSS: 0.15108688496336153\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.0751793384552\n",
      "\tMAIN_LOSS: 3.604642689228058\n",
      "\tKD_LOSS: 0.1568455509841442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.926       0.76      0.869      0.625\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch268\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 268 END --------------------\n",
      "-------------------- EPOCH 269 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5414142412475393\n",
      "\tMAIN_LOSS: 1.0944983068900773\n",
      "\tKD_LOSS: 0.14897197654730157\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.017069727182388\n",
      "\tMAIN_LOSS: 3.5492854615052543\n",
      "\tKD_LOSS: 0.1559280933191379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.874      0.802      0.874      0.629\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch269\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 269 END --------------------\n",
      "-------------------- EPOCH 270 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5038295969178406\n",
      "\tMAIN_LOSS: 1.06068395964707\n",
      "\tKD_LOSS: 0.14771521355532394\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9226887126763663\n",
      "\tMAIN_LOSS: 3.4606038133303323\n",
      "\tKD_LOSS: 0.1540282896409432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.929      0.789      0.879      0.634\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch270\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 270 END --------------------\n",
      "-------------------- EPOCH 271 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5031124232690545\n",
      "\tMAIN_LOSS: 1.0572881585435023\n",
      "\tKD_LOSS: 0.1486080875502357\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9185456335544586\n",
      "\tMAIN_LOSS: 3.448594868183136\n",
      "\tKD_LOSS: 0.1566502625743548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181       0.94      0.777      0.866      0.625\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch271\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 271 END --------------------\n",
      "-------------------- EPOCH 272 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4755439637582513\n",
      "\tMAIN_LOSS: 1.038904140267191\n",
      "\tKD_LOSS: 0.14554660776747932\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.898645887772242\n",
      "\tMAIN_LOSS: 3.4414654870827994\n",
      "\tKD_LOSS: 0.15239346461991468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.932      0.757      0.862      0.625\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch272\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 272 END --------------------\n",
      "-------------------- EPOCH 273 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4691265549840806\n",
      "\tMAIN_LOSS: 1.036031646064565\n",
      "\tKD_LOSS: 0.14436496982846078\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.888627996047338\n",
      "\tMAIN_LOSS: 3.43708835542202\n",
      "\tKD_LOSS: 0.15051321126520634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.909       0.79      0.879      0.624\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch273\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 273 END --------------------\n",
      "-------------------- EPOCH 274 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4810053683534454\n",
      "\tMAIN_LOSS: 1.049568785142295\n",
      "\tKD_LOSS: 0.14381219484383548\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.925475537776947\n",
      "\tMAIN_LOSS: 3.4629237949848175\n",
      "\tKD_LOSS: 0.15418391736845175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.926      0.779      0.881      0.636\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch274\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 274 END --------------------\n",
      "-------------------- EPOCH 275 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4893462084516693\n",
      "\tMAIN_LOSS: 1.0553788210772261\n",
      "\tKD_LOSS: 0.14465579447112506\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8688391943772635\n",
      "\tMAIN_LOSS: 3.4106035629908242\n",
      "\tKD_LOSS: 0.1527452108760675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.922      0.786       0.88      0.622\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch275\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 275 END --------------------\n",
      "-------------------- EPOCH 276 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4867408818836454\n",
      "\tMAIN_LOSS: 1.0527355618114713\n",
      "\tKD_LOSS: 0.14466843537137478\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8093648155530295\n",
      "\tMAIN_LOSS: 3.3408252149820328\n",
      "\tKD_LOSS: 0.1561798652013143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.898      0.778      0.868      0.621\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch276\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 276 END --------------------\n",
      "-------------------- EPOCH 277 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5158770084381104\n",
      "\tMAIN_LOSS: 1.0641866816750056\n",
      "\tKD_LOSS: 0.15056343885916698\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9602277676264444\n",
      "\tMAIN_LOSS: 3.3818492591381073\n",
      "\tKD_LOSS: 0.19279283719758192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181       0.89      0.761      0.851      0.605\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch277\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 277 END --------------------\n",
      "-------------------- EPOCH 278 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.8195871597603908\n",
      "\tMAIN_LOSS: 1.298153635821765\n",
      "\tKD_LOSS: 0.17381117238274105\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 4.019154936075211\n",
      "\tMAIN_LOSS: 3.4795797566572824\n",
      "\tKD_LOSS: 0.17985839893420538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.881       0.79      0.861      0.592\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch278\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 278 END --------------------\n",
      "-------------------- EPOCH 279 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.6624773484242112\n",
      "\tMAIN_LOSS: 1.1839730875401557\n",
      "\tKD_LOSS: 0.1595014197916924\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.945278078317642\n",
      "\tMAIN_LOSS: 3.375784029563268\n",
      "\tKD_LOSS: 0.18983135682841143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.897      0.768      0.857      0.592\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch279\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 279 END --------------------\n",
      "-------------------- EPOCH 280 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5628103561039213\n",
      "\tMAIN_LOSS: 1.103094211862057\n",
      "\tKD_LOSS: 0.15323871675925918\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.848319182793299\n",
      "\tMAIN_LOSS: 3.3754126081864038\n",
      "\tKD_LOSS: 0.15763552486896515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.917      0.779      0.873      0.634\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch280\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 280 END --------------------\n",
      "-------------------- EPOCH 281 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4883650073522254\n",
      "\tMAIN_LOSS: 1.0451933726479736\n",
      "\tKD_LOSS: 0.14772387678864635\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8534387052059174\n",
      "\tMAIN_LOSS: 3.3882954915364585\n",
      "\tKD_LOSS: 0.15504774078726768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.922      0.783      0.871      0.627\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch281\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 281 END --------------------\n",
      "-------------------- EPOCH 282 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4717305642140062\n",
      "\tMAIN_LOSS: 1.0360840860801408\n",
      "\tKD_LOSS: 0.1452154905735692\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.907312572002411\n",
      "\tMAIN_LOSS: 3.452928066253662\n",
      "\tKD_LOSS: 0.15146148763597012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181       0.94      0.762      0.886      0.641\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch282\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 282 END --------------------\n",
      "-------------------- EPOCH 283 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4904639630378047\n",
      "\tMAIN_LOSS: 1.0549377225622345\n",
      "\tKD_LOSS: 0.14517541437209408\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.7351055443286896\n",
      "\tMAIN_LOSS: 3.284845530986786\n",
      "\tKD_LOSS: 0.15008667297661304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.903      0.807      0.884      0.632\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch283\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 283 END --------------------\n",
      "-------------------- EPOCH 284 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4811787001694305\n",
      "\tMAIN_LOSS: 1.0499091857596288\n",
      "\tKD_LOSS: 0.14375650467751902\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.7632616261641183\n",
      "\tMAIN_LOSS: 3.311955784757932\n",
      "\tKD_LOSS: 0.1504352819174528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.917       0.79      0.885      0.638\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch284\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 284 END --------------------\n",
      "-------------------- EPOCH 285 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4808006407339362\n",
      "\tMAIN_LOSS: 1.0512386220919936\n",
      "\tKD_LOSS: 0.14318733992455882\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.613611767689387\n",
      "\tMAIN_LOSS: 3.1587842106819153\n",
      "\tKD_LOSS: 0.15160918546219668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.933      0.785      0.883      0.637\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch285\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 285 END --------------------\n",
      "-------------------- EPOCH 286 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4656548560420168\n",
      "\tMAIN_LOSS: 1.0398277074475832\n",
      "\tKD_LOSS: 0.14194238346211518\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.636939818660418\n",
      "\tMAIN_LOSS: 3.19608827928702\n",
      "\tKD_LOSS: 0.14695051064093909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181      0.907      0.796       0.88      0.646\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch286\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 286 END --------------------\n",
      "-------------------- EPOCH 287 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4732240317743035\n",
      "\tMAIN_LOSS: 1.045923646492294\n",
      "\tKD_LOSS: 0.1424334622636626\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.792980213960012\n",
      "\tMAIN_LOSS: 3.349347233772278\n",
      "\tKD_LOSS: 0.14787766616791487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.921      0.777      0.866       0.62\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch287\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 287 END --------------------\n",
      "-------------------- EPOCH 288 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4770790459234504\n",
      "\tMAIN_LOSS: 1.0513892098318172\n",
      "\tKD_LOSS: 0.1418966139796414\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.768866926431656\n",
      "\tMAIN_LOSS: 3.3197517096996307\n",
      "\tKD_LOSS: 0.14970507907370725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.919      0.785      0.877      0.644\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch288\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 288 END --------------------\n",
      "-------------------- EPOCH 289 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.5207152136518984\n",
      "\tMAIN_LOSS: 1.0793935203854041\n",
      "\tKD_LOSS: 0.14710723165469833\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.901511321465174\n",
      "\tMAIN_LOSS: 3.4489542742570243\n",
      "\tKD_LOSS: 0.15085235983133316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.925      0.768      0.859      0.622\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch289\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 289 END --------------------\n",
      "-------------------- EPOCH 290 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4999957522259484\n",
      "\tMAIN_LOSS: 1.0741756218898146\n",
      "\tKD_LOSS: 0.14194004218789597\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.7548200289408364\n",
      "\tMAIN_LOSS: 3.3025207221508026\n",
      "\tKD_LOSS: 0.1507664422194163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181       0.91       0.79      0.872      0.639\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch290\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 290 END --------------------\n",
      "-------------------- EPOCH 291 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.497091756591314\n",
      "\tMAIN_LOSS: 1.0664398934267745\n",
      "\tKD_LOSS: 0.14355062268957308\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9870156248410544\n",
      "\tMAIN_LOSS: 3.5335916777451835\n",
      "\tKD_LOSS: 0.15114132252832255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.908       0.76      0.861      0.622\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch291\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 291 END --------------------\n",
      "-------------------- EPOCH 292 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.504655681078947\n",
      "\tMAIN_LOSS: 1.0747404973718184\n",
      "\tKD_LOSS: 0.14330506258750264\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.7539231181144714\n",
      "\tMAIN_LOSS: 3.2913878013690314\n",
      "\tKD_LOSS: 0.1541784442961216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        181       0.89      0.805      0.882      0.633\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch292\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 292 END --------------------\n",
      "-------------------- EPOCH 293 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4818580905093421\n",
      "\tMAIN_LOSS: 1.0537928999224795\n",
      "\tKD_LOSS: 0.14268839661079116\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.826053579648336\n",
      "\tMAIN_LOSS: 3.3801674842834473\n",
      "\tKD_LOSS: 0.14862869990368685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.925       0.75      0.869      0.618\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch293\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 293 END --------------------\n",
      "-------------------- EPOCH 294 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4494357923918133\n",
      "\tMAIN_LOSS: 1.0286269037029412\n",
      "\tKD_LOSS: 0.14026963088331343\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.69646746913592\n",
      "\tMAIN_LOSS: 3.2491345504919686\n",
      "\tKD_LOSS: 0.1491109784692526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.939      0.762       0.87      0.629\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch294\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 294 END --------------------\n",
      "-------------------- EPOCH 295 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4432745613629305\n",
      "\tMAIN_LOSS: 1.0241528787190401\n",
      "\tKD_LOSS: 0.13970722861682314\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.9086653689543405\n",
      "\tMAIN_LOSS: 3.4509530266126\n",
      "\tKD_LOSS: 0.15257078843812147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.855      0.762      0.858      0.621\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch295\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 295 END --------------------\n",
      "-------------------- EPOCH 296 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4282339087015465\n",
      "\tMAIN_LOSS: 1.0107628235334083\n",
      "\tKD_LOSS: 0.13915702615734898\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.818507840236028\n",
      "\tMAIN_LOSS: 3.381835415959358\n",
      "\tKD_LOSS: 0.14555746813615164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.897      0.779      0.871      0.628\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch296\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 296 END --------------------\n",
      "-------------------- EPOCH 297 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4504607553723492\n",
      "\tMAIN_LOSS: 1.034075205839133\n",
      "\tKD_LOSS: 0.138795183334924\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.6125350358585515\n",
      "\tMAIN_LOSS: 3.173343539237976\n",
      "\tKD_LOSS: 0.14639715912441412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n",
      "                   all        376        181      0.928      0.781      0.881      0.638\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch297\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 297 END --------------------\n",
      "-------------------- EPOCH 298 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.4428820776034006\n",
      "\tMAIN_LOSS: 1.027026718930353\n",
      "\tKD_LOSS: 0.1386184548086758\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8123622834682465\n",
      "\tMAIN_LOSS: 3.3810814718405404\n",
      "\tKD_LOSS: 0.14376026888688406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n",
      "                   all        376        181      0.891       0.79      0.875      0.627\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch298\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 298 END --------------------\n",
      "-------------------- EPOCH 299 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.427992750572253\n",
      "\tMAIN_LOSS: 1.0150103425677819\n",
      "\tKD_LOSS: 0.1376608029196534\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.800172130266825\n",
      "\tMAIN_LOSS: 3.366276423136393\n",
      "\tKD_LOSS: 0.14463188871741295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n",
      "                   all        376        181      0.913      0.779      0.872      0.639\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch299\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 299 END --------------------\n",
      "-------------------- EPOCH 300 START --------------------\n",
      "Training start ...\n",
      "TRAIN:\n",
      "\tAVG_LOSS: 1.430712735351128\n",
      "\tMAIN_LOSS: 1.0177372173417973\n",
      "\tKD_LOSS: 0.13765850493425055\n",
      "Evaluating start ...\n",
      "VAL:\n",
      "\tAVG_LOSS: 3.8738101720809937\n",
      "\tMAIN_LOSS: 3.439344217379888\n",
      "\tKD_LOSS: 0.14482197165489197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.931      0.762      0.876      0.633\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/epoch300\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- EPOCH 300 END --------------------\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# 6. Training loop\n",
    "num_epochs = 300\n",
    "lambda_kd = 3 # distillation loss weight\n",
    "\n",
    "best_map = 0\n",
    "maps = []\n",
    "train_avg_losses = []\n",
    "train_main_losses = []\n",
    "train_kd_losses = []\n",
    "val_avg_losses = []\n",
    "val_main_losses = []\n",
    "val_kd_losses = []\n",
    "\n",
    "print(f'***** START TRAINING WITH {num_epochs} EPOCHS, KD {model_name}, LAMBDA_KD {lambda_kd}')\n",
    "for epoch in range(num_epochs):\n",
    "    print('-' * 20 + f' EPOCH {epoch+1} START ' + '-' * 20)\n",
    "    # TRAIN\n",
    "    print('Training start ...')\n",
    "    train_avg_loss, train_main_loss, train_kd_loss = train_one_epoch(\n",
    "        kd_model, student_loss_fn, optimizer, train_dataloader, device, lambda_kd, epoch, num_epochs\n",
    "    )\n",
    "    print(f'TRAIN:\\n\\tAVG_LOSS: {train_avg_loss}\\n\\tMAIN_LOSS: {train_main_loss}\\n\\tKD_LOSS: {train_kd_loss}')\n",
    "    train_avg_losses.append(train_avg_loss)\n",
    "    train_main_losses.append(train_main_loss)\n",
    "    train_kd_losses.append(train_kd_loss)\n",
    "\n",
    "    # EVALUATE\n",
    "    print('Evaluating start ...')\n",
    "    val_avg_loss, val_main_loss, val_kd_loss = evaluate(\n",
    "        kd_model, val_dataloader, student_loss_fn, device, lambda_kd, epoch, num_epochs\n",
    "    )\n",
    "    print(f'VAL:\\n\\tAVG_LOSS: {val_avg_loss}\\n\\tMAIN_LOSS: {val_main_loss}\\n\\tKD_LOSS: {val_kd_loss}')\n",
    "    val_avg_losses.append(val_avg_loss)\n",
    "    val_main_losses.append(val_main_loss)\n",
    "    val_kd_losses.append(val_kd_loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        metrics = kd_model.val('/kaggle/working/Br35H-Mask-Prepared/data.yaml', split='val', project='runs', name='epoch', save=False)\n",
    "\n",
    "    maps.append(metrics.box.map)\n",
    "\n",
    "    if best_map <= metrics.box.map:\n",
    "        best_map = metrics.box.map\n",
    "        torch.save(kd_model.student.model.state_dict(), 'lsm_best.pt')\n",
    "        print(f\"Epoch {epoch+1}: New best mAP: {best_map:.4f}, model saved.\")\n",
    "    print('-' * 20 + f' EPOCH {epoch+1} END ' + '-' * 20)\n",
    "    \n",
    "torch.save(kd_model.student.model.state_dict(), 'lsm_last.pt')\n",
    "    \n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "199f47e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T10:47:59.342469Z",
     "iopub.status.busy": "2025-05-18T10:47:59.341109Z",
     "iopub.status.idle": "2025-05-18T10:48:00.809224Z",
     "shell.execute_reply": "2025-05-18T10:48:00.808514Z"
    },
    "papermill": {
     "duration": 1.879264,
     "end_time": "2025-05-18T10:48:00.810602",
     "exception": false,
     "start_time": "2025-05-18T10:47:58.931338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABjYAAAScCAYAAAAoOLYFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3hUxdvG8Xuz2fRCGr33KiCgdFCadBAEBJQqFkD8YQMbYBeUF0Ww0lQQkWYDISA2QAUEVJr0XkIo6clm97x/xKysKSQhybLk+7muXLJz5sx5dmfBM3nOzJgMwzAEAAAAAAAAAADgBjxcHQAAAAAAAAAAAEBOkdgAAAAAAAAAAABug8QGAAAAAAAAAABwGyQ2AAAAAAAAAACA2yCxAQAAAAAAAAAA3AaJDQAAAAAAAAAA4DZIbAAAAAAAAAAAALdBYgMAAAAAAAAAALgNEhsAAAAAAAAAAMBtkNgAAABwMyaTKdc/bdu2LZBYJk+eLJPJpMmTJ+dLe0eOHJHJZFLFihXzpb2iom3btjKZTPr++++vWve7776TyWSSr6+vLl26dNX6586dk5eXl0wmk3777bc8xTd//nyZTCYNHTrUqfxa+rtixYoymUw6cuRInmLKrazew/Xk+++/d/p7v3379mzr16lTx1F35MiRhRRlzuT3vy0AAAC4sXi6OgAAAADkzpAhQzKUnTlzRmvWrMnyeM2aNQs8LriH2267TZUqVdLhw4e1aNEiPfTQQ9nW//jjj2W1WlW3bl3dcssthRRl4Tpy5IgqVaqkChUqFFqipDDMnTtXM2fOzPTYL7/8ot27d+f7NSdPnqwpU6Zo0qRJJCUAAABQYEhsAAAAuJn58+dnKPv+++8diY3MjheUMWPGaMCAAQoPD8+X9sqUKaM9e/bIYrHkS3vIyGQyafjw4Xr22Wc1d+7cqyY25s2bJ0kaMWJEvsfiTv3du3dvNW3aVMHBwa4O5arKly+vpKQkLVq0SK+//rq8vb0z1Jk7d64kqUmTJtqyZUthh3hV+f1vCwAAAG4sLEUFAACAPAsPD1fNmjXz7ZePFotFNWvWVJUqVfKlPWRu6NChMpvN2rZtm/78888s6/3222/atWuXvLy8NHjw4HyPw536Ozg4WDVr1lSpUqVcHcpVWSwWDR48WBcuXNDKlSszHE9ISNDixYtVpkwZderUqfADzIH8/rcFAAAANxYSGwAAADe4K9eqP3bsmEaMGKFy5crJYrE47RewfPlyjRw5UnXr1lVISIh8fHxUqVIlDR8+XPv27btq21e6cj+C+Ph4TZw4UVWrVpW3t7dKliypIUOG6OTJkxnay27PhfS9ACRp2bJlatmypYKCguTv768WLVpo1apVWX4GR48e1dChQ1WyZEn5+PioWrVqmjRpkpKSknK1P0W6qKgovfXWW+rSpYsqVaokX19fBQUFqXHjxnrttdeUlJSU6XnX8h6OHz+u4cOHq1SpUo738PTTTysxMTHHcacrW7as4xfa6U/uZyb9WI8ePRy/YF63bp3Gjh2rBg0aKDw8XN7e3ipbtqz69++f6yf/r7bHxu7du3XXXXcpPDxcvr6+qlu3rl5//XXZbLYs29y9e7cmTZqkFi1aqEyZMvLy8lJYWJjat2+vJUuWZKg/dOhQVapUSVLa9+S/+9Oku9oeG7/99pv69eun0qVLy8vLS8WLF1f37t0VGRmZaf2hQ4fKZDJp/vz5Onz4sO655x6VLFlS3t7eqlKlip555hklJydn+T6vZvjw4ZIy79/PP/9csbGxuvfee2U2m7Nt59SpUxo/frxq1aolPz8/BQYGqkmTJnr77beVmprqVNdkMmnKlCmSpClTpjh9jld+blfuj/LFF1/o9ttvV2hoqNPfw6vtsfH333/roYceUo0aNeTn56egoCDVrl1bDz30kP766y+nutu2bVP//v1VtmxZeXl5KSgoSJUrV1afPn30xRdfZPv+AQAAcH1iKSoAAIAiYv/+/WrYsKG8vLzUokULGYbh9DR0v3795O3trdq1a+v2229Xamqq/vrrL82bN09LlizR2rVr1bx581xd8/Lly2revLmOHTumVq1aqW7dutq8ebM++ugj/fDDD9q5c2eul/aZNGmSXnjhBTVv3lxdunTR3r17tWnTJnXr1k3Lli1T7969nerv3r1bbdq00fnz51W6dGn17NlT8fHxeuONN/Tdd9/Jbrfn6vqStGbNGo0bN05lypRR1apV1bRpU0VFRenXX3/VhAkT9MUXX2jDhg2ZLgGUl/ewd+9etWnTRufOnVOpUqXUo0cPxcfH6//+7/+0YcOGXMcvpS0ttWrVKn3yySeaOnVqhuWgEhMTtXjxYkfddA888ICOHz+uOnXqqEWLFvL09NTevXu1ZMkSLV++XIsXL1afPn3yFNOVfv75Z91xxx2Kj49X5cqV1aFDB50/f15PPfWUfvnllyzPmz59uubMmaOaNWuqXr16KlasmI4dO6YNGzZo/fr1+uWXXzR9+nRH/ZYtWyouLk7Lli2Tv7+/+vbtm+tYP/jgAz3wwAOy2+1q2LCh2rZtq6NHj+rrr7/W119/rcmTJ2vSpEmZnrtjxw6NGzdOISEhatOmjS5cuKCNGzfqpZde0q5du7RixYpcxyOlbQx+yy23aN26dTp+/LjKlSvnODZnzhxJ0rBhw7Rw4cIs2/jxxx/Vq1cvXbx4URUrVlSHDh2UnJys3377TWPHjtVXX32lr7/+2vHdGTJkiHbs2KGdO3eqfv36atCggaOtli1bZmj/jTfe0Ntvv63GjRvrjjvu0KlTp66aaJGkRYsWafjw4UpOTlb58uXVpUsX2e12HTp0SO+++66KFy+uunXrSpLWr1+vzp07y2q1qn79+mrWrJlsNptOnjypb775RjabTT179szRZwoAAIDriAEAAAC3t2HDBkOSkdnt3aRJkxzHBg8ebCQlJWXaxuLFi424uDinMrvdbsyaNcuQZNSpU8ew2+2Ztj1p0iSn8nnz5jmu2alTJ+Py5cuOYxcuXDAaNGhgSDJefvllp/MOHz5sSDIqVKiQIb709ooVK2b88ssvmcZRvXr1DOfdfPPNhiRjwIABTu/9xIkTRo0aNRztbtiwIdPPJTO7d+82Nm/enKH8woULRseOHQ1JxtSpU/PtPTRp0sSQZPTr189ITEx0lB89etSoUqVKnt5DSkqKERERYUgyli1bluH4J598YkgyypUrZ9hsNkf5ihUrjAsXLmSov2LFCsPT09MICwszEhISnI6lfx+GDBniVJ5VfycmJhrlypUzJBmPPPKIkZqa6ji2c+dOIzw83PGeDx8+7HTu999/bxw8eDBDfHv37jXKli1rSDJ+/fXXHMWRk/fwxx9/GJ6enobJZDI++ugjp2OrVq0yvLy8DEnG2rVrnY4NGTLE8R6efvppp/f4559/Gv7+/oYkY9OmTVnG9F/p/w5UqVLFMAzDeO+99wxJxvPPP++o8/fffxuSjNatWxuG8e/3bsSIEU5tnT592ggLCzNMJpMxe/Zsp+/A+fPnjdtvv92QZEyZMsXpvKz+TbhShQoVDEmG2Ww2vvjii0zrZNXO1q1bDYvFYphMJuOtt95yisswDOPIkSPG1q1bHa9vu+02Q5LxySefZLjGpUuXMv17DAAAgOsfS1EBAAAUEaGhoXr77beznEXQv39/+fv7O5WZTCY99NBDatasmXbt2qU9e/bk6pr+/v6aN2+egoKCHGUhISGaMGGCpLRljXLr+eef16233upUNnHiRAUHB+vvv//W8ePHHeU//fSTfv/9dwUEBGjWrFlO771MmTJ64403cn19SapVq5aaNm2aoTwkJEQzZ86UlLbcT368h40bN2rLli3y9/fX7Nmz5ePj4zhWvnx5vf7663l6DxaLRffee6+kzJcrSi8bMmSIPDz+HTb06tVLISEhGer36tVLd911l6Kjo/M8iyTdsmXLHLMMpk6d6vQU/0033aSnn346y3PbtGmjypUrZyivUaOGnn32WUnS0qVLrym+K7355ptKTU1V7969dc899zgd69y5s0aNGiVJmjZtWqbnN2rUSC+88ILTe6xbt66jrbz8HUk3YMAA+fn5af78+TIMQ9K//Zq+VFVWZsyYoejoaI0ePVoPPvig03cgLCxMH330kSwWi95++21H27k1ZMgQ9ejRI1fnvPjii7JarRozZozGjh3rFJckVahQQY0aNXK8Pnv2rCSpS5cuGdoKDg7O9O8xAAAArn8sRQUAAFBEtG/f/qrLPh04cEDffvutDhw4oNjYWMdeBum/HNy3b59q166d42s2btw4082Wa9WqJUmZ7rNxNd27d89Q5u3trcqVK2v79u06efKkY9mdH374QZJ0xx13KDQ0NMN5Xbt2VbFixXTp0qVcx2Gz2fT9999r06ZNOn36tBITE2UYhuOXvFntS5Lb95C+58Add9yhsLCwDOf17NlTwcHBunz5cq7fw8iRI/XGG2/o22+/1enTpx19deTIEW3YsEEmk0nDhg3LcN6pU6f0zTffaO/evbp8+bJjr4Vdu3ZJSnvvmf0iOafS33O/fv0yLJElpf1C/H//+1+W58fFxWn16tXavn27zp8/r5SUFEnS6dOnHfHll/RYs9p7Y8SIEXr77bf1008/yWazZVhqqVu3bk57eaS7lr8j6YKCgtSnTx99/PHH+v7779W6dWt99NFHCgwM1F133ZXtud98842ktIRnZsqUKaNq1app9+7d2r9/v6pXr57r+HK77JfNZnPsWZKeMLqaW265Rbt379agQYP01FNPqWnTpvL0ZBgMAADg7rijAwAAKCKy2qBZSvuF4ZgxY/Tee+9l+/R1TExMrq5Zvnz5TMvTZ3Bktcl2frV54sQJSdm/9woVKuQ6sbF//3717t3b8Yv8zGT3WeXlPaRvcP1f6Ztv79y586px/1fNmjXVvHlzbdq0SQsWLHDMpJk3b54Mw9Dtt9+eYfbDlClT9NJLL8lqtWbZbm6/J/91tfccEhKSZTLnq6++0rBhwxQdHV1g8V0pPfGQVaxVqlSRlNan0dHRKl68uNPxgvg7cqXhw4fr448/1ty5c5WQkKBTp05p5MiR8vPzy/a8Q4cOSZJatWp11WtERUXlKbGR3d/LzERHRys+Pl5S2gycnHjllVf0xx9/aPXq1Vq9erV8fX118803q23btho0aJAjgQQAAAD3wlJUAAAARYSvr2+Wx9588029++67KlGihBYtWqQjR444zUC4++67JSnXS878d5mY/JCXNjN7Ij4nx7LSt29f7dq1S926ddOPP/7omBVgGIaSk5Oven5BfC55lb4x+Pz58yWl9fGCBQucjqVbvny5Jk+eLG9vb7333nvav3+/4uPjZbfbZRiGJk6c6GjDFU6ePKn+/fsrOjpaTzzxhHbu3KnLly/LZrPJMAytWbPGpfFlpqC/C23atFGVKlW0bNkyzZgxQ9LVl6GSJLvdLintuz5kyJBsfzKbSZQT2f2blF9KliyprVu3asOGDXr66ad166236vfff9dLL72kOnXq6LXXXivwGAAAAJD/mLEBAAAALVmyRJL03nvvZbrm/f79+ws7pHxRpkwZSWlLK2Xl6NGjuWpz7969+uOPP1S8eHGtWLEiw7I2+f1ZFcR7uFK/fv00btw47du3Txs3blRiYqKOHj2qYsWK6c4773Sqm/49eemllzJdCii/3vvV3vOlS5eynK2RmJio3r17Z/oL64L4HpcpU0YHDx7UoUOHVLdu3QzH02c++Pj4ZLocWkEzmUwaOnSonn32Wa1bt061atVSs2bNrnpeuXLltH//fj355JNq3LhxIUR6dWFhYfLz81NCQoL27duX6eedGZPJpLZt26pt27aS0mbBzJ8/X6NHj9ZTTz2lvn37OmbWAAAAwD1cP4+KAQAAwGUuXLggKW1Zpv/atWuXduzYUcgR5Y/WrVtLkr799ltdvHgxw/HVq1dnWp6d9M+qdOnSma7V/8knn+Qh0qy1adNGUtp7SL/2lb788ss87RGSLiAgQAMGDJCUtrF0+ubSAwcOdNqoXMr+e3Lu3DnH/gfXKv09L1myJNMlrz766KNMz8suPsMwtGjRokzP8/LykiTHXiG5kf7L8vQZL/+V/nm2atXKZXs7DB06VBEREQoLC9P999+fo3M6d+4s6d9kVk5dy2d5NWazWR06dJAkffDBB3lux8fHRw888IBuuukm2e12/fHHH/kVIgAAAAoJiQ0AAAA41pmfNWuWYwkaKW2z5XvvvbdAfklZGFq3bq369esrNjZWY8eOdWwiLaVtgP3oo4/mus3q1avLbDbrzz//dGwcne6rr77S//3f/11r2E5atWqlm2++WXFxcRo9erTTUlfHjx/XY489ds3XSF9yasmSJVqxYoVT2ZXSvyfvv/++02d5+fJlDRkyJE8bmGemb9++KlOmjI4dO6aJEyc6fSf/+usvvfjii5melx7f0qVLHRuFS2l7yDz33HPatGlTpudFRETIy8tLZ86cyTR5lJ1x48bJ09NTK1euzJDUWrt2rd577z1Jypd+yquyZcvq3LlzOn/+vMaNG5ejcx5//HEVK1ZM06dP1xtvvOHU3+kOHz6c4T2XLVtWkrLdf+ZaPP300/L09NTbb7+t2bNnZ1hW7OjRo9q2bZvj9euvv65jx45laGfv3r2OGTyZJcIAAABwfSOxAQAAAD311FPy8vLSBx98oBo1aqh///7q3LmzqlSpouTkZPXu3dvVIeaJyWTSJ598otDQUC1cuFCVK1dW//791b17d1WvXl2hoaGOZXnSnzS/mvDwcI0ZM0Y2m03t2rVT27ZtNXDgQDVq1Eg9evTQ448/nu/v4+OPP1ZERIQWL17s9B5q1qypsLCwHC0tlJ2mTZuqdu3aiouLU1JSkho0aKCbb745Q71HHnlExYoV06pVq1S5cmX17dtXPXv2VIUKFbRz584c7d2QE76+vlq4cKH8/Pz0xhtvqHr16rr77rvVsWNH3XzzzWrVqlWmv4zu3r27GjVqpBMnTqh69erq1q2b+vfvrypVqui1117Tk08+men1LBaLevToIZvNpgYNGmjgwIEaOXKkRo4cedVY69Wrp1mzZslkMumee+5Ro0aNNGjQILVs2VJ33HGHkpOTNXnyZHXs2PGaP5fCVLZsWX3xxRcKCQnRY489pnLlyqldu3YaPHiwunfvrqpVq6py5cp6++23nc7r1KmT/P39tXLlSrVs2VLDhg3TyJEjNW/evHyJq0mTJpozZ47MZrNGjx6tSpUq6a677lKfPn3UsGFDVapUSV999ZWj/osvvqgKFSqoVq1auvPOOzVo0CDddtttqlevnuLj43Xvvfdm+l0HAADA9Y3EBgAAAHTrrbdq69at6tGjh+Lj4/Xll1/q4MGDGjt2rDZv3qygoCBXh5hndevW1bZt23TPPffIarVq5cqV2rNnj8aNG6fIyEidPXtWUlrCIqf+7//+T3PmzFHDhg21bds2rVq1Sn5+flq8eLFeeOGFfH8PtWvX1tatWzV06FDZbDatXLlSu3fv1tixY7V+/focJ2Wyc+UMjawSFJUqVdL27ds1aNAgmc1mff3119q5c6fuvvtubd++XeXKlbvmONK1adNGv/76q+68805dvHhRK1as0IkTJ/T888/rs88+y/QcT09Pff/993rqqadUpkwZrV+/Xt9//70aNmyozZs364477sjyeu+9957uv/9+mUwmLV26VHPmzNGcOXNyFOuoUaO0adMm9e3bV6dOndKSJUu0d+9edenSRWvXrtWkSZPy9Bm4WuvWrbVr1y49++yzKlu2rLZs2aLPP/9cO3bsUIkSJTRp0qQMS0KVKFFCq1evVvv27bV792599NFHmjNnjn744Yd8i+vee+/Vjh07NGLECHl4eOirr77S+vXrlZKSotGjR6tfv36OurNmzdKwYcPk6empH374QcuWLdPhw4fVoUMHrVixIsslxAAAAHB9Mxn/nbsLAAAAFBGHDx9W1apVFRgYqAsXLsjDg+d+AAAAAOB6x8gNAAAAN7T4+PhM1/s/evSoBg0aJLvdriFDhpDUAAAAAAA3wYwNAAAA3NCOHDmiSpUqqUqVKqpevbqCgoJ07Ngx/f7770pOTlb9+vX1448/uvVyWwAAAABQlJDYAAAAwA0tLi5OU6ZM0Xfffadjx47p0qVL8vPzU40aNdSnTx+NHTtWfn5+rg4TAAAAAJBDJDYAAAAAAAAAAIDbYCFhAAAAAAAAAADgNkhsAAAAAAAAAAAAt0FiAwAAAAAAAAAAuA0SGwAAAAAAAAAAwG2Q2AAAAAAAAAAAAG6DxAYAAAAAAAAAAHAbJDYAAAAAAAAAAIDbILEBAAAAAAAAAADcBokNAAAAAAAAAADgNkhsAAAAAAAAAAAAt0FiAwAAAAAAAAAAuA0SGwAAAAAAAAAAwG2Q2AAAAAAAAAAAAG6DxAYAAAAAAAAAAHAbJDYAAAAAAAAAAIDbILEBAAAAAAAAAADcBokNAAAAAAAAAADgNkhsAAAAAAAAAAAAt0FiAwAAAAAAAAAAuA0SGwAAAAAAAAAAwG2Q2AAAAAAAAAAAAG6DxAYAAAAAAAAAAHAbJDYAAAAAAAAAAIDbILEBAAAAAAAAAADcBokNAAAAAAAAAADgNkhsAAAAAAAAAAAAt0FiAwAAAAAAAAAAuA0SGwAAAAAAAAAAwG2Q2AAAAAAAAAAAAG6DxAYAAAAAAAAAAHAbJDYAAAAAAAAAAIDbILEBAAAAAAAAAADcBokNAAAAAAAAAADgNkhsAAAAAAAAAAAAt0FiAwAAAAAAAAAAuA0SGwAAAAAAAAAAwG2Q2AAAAAAAAAAAAG6DxAYAAAAAAAAAAHAbJDYAAAAAAAAAAIDbILEBAAAAAAAAAADcBokNAAAAAAAAAADgNkhsAAAAAAAAAAAAt0FiAwAAAAAAAAAAuA0SGwAAAAAAAAAAwG2Q2AAAAAAAAAAAAG6DxAYAAAAAAAAAAHAbJDYAAAAAAAAAAIDbILEBAAAAAAAAAADcBokNAAAAAAAAAADgNkhsAAAAAAAAAAAAt0FiAwAAAAAAAAAAuA0SGwAAAAAAAAAAwG2Q2AAAAAAAAAAAAG6DxAYAAAAAAEABqlixooYOHerqMG4IXbp00X333efqMDIoyn08efJkmUwmnT9/3tWh5IumTZvqiSeecHUYAK6CxAYAwGH27NkymUy69dZbXR3KdadixYrq1q2bq8MAAABAPps/f75MJpNMJpN+/vnnDMcNw1C5cuVkMpmum/vBG+0XyTm1ceNGrV27Vk8++aRT+ZEjRzRs2DBVqVJFPj4+KlmypFq3bq1JkyY51Zs9e7bmz59fiBHnr1WrVmny5MlXrXfldzq7n4oVKxZ4zDmNdevWra4OxeHJJ5/UrFmzdObMGVeHAiAbnq4OAABw/Vi4cKEqVqyo3377TQcOHFDVqlVdHRIAAABQKHx8fLRo0SK1bNnSqfyHH37QiRMn5O3tnee29+3bJw8Pni29VtOmTVO7du2cxikHDhxQkyZN5Ovrq+HDh6tixYo6ffq0fv/9d7322muaMmWKo+7s2bMVHh7utjMrVq1apVmzZl01udG6dWt9/PHHTmUjR47ULbfcolGjRjnKAgICCiJMt9ezZ08FBQVp9uzZev75510dDoAskNgAAEiSDh8+rE2bNmn58uW6//77tXDhwgxPOBU0u92ulJQU+fj4FOp1AQAAgC5duujzzz/XW2+9JU/Pf39dsmjRIjVq1OiaZkdcS1IEac6dO6dvvvlG7777rlP5//3f/ykuLk47duxQhQoVMpxTFFWuXFmVK1d2KnvggQdUuXJlDR482EVRuQ8PDw/17dtXH330kaZMmSKTyeTqkABkgscFAACS0mZrhISEqGvXrurbt68WLlzoOGa1WhUaGqphw4ZlOC8mJkY+Pj567LHHHGXJycmaNGmSqlatKm9vb5UrV05PPPGEkpOTnc41mUwaM2aMFi5cqDp16sjb21vffvutJOn1119X8+bNFRYWJl9fXzVq1EhLly7NcP3ExEQ9/PDDCg8PV2BgoHr06KGTJ0/KZDJleJLp5MmTGj58uEqUKCFvb2/VqVNHc+fOvZaPzUlqaqpeeOEFValSRd7e3qpYsaKeeuqpDO9769at6tSpk8LDw+Xr66tKlSpp+PDhTnUWL16sRo0aKTAwUEFBQapXr57efPNNpzqXLl3SI488onLlysnb21tVq1bVa6+9Jrvdnuu2AAAAirq7775b0dHRioyMdJSlpKRo6dKlGjhwYKbn5PSe9b/7L6Qvv7Nx40aNHz9eERER8vf3V+/evRUVFZVv7+m7775Tq1at5O/vr2LFiqlnz57as2ePU53Y2Fg98sgjqlixory9vVW8eHF16NBBv//+u6PO/v371adPH5UsWVI+Pj4qW7asBgwYoMuXLzu19cknn6hRo0by9fVVaGioBgwYoOPHjzvVyWlb//XNN98oNTVV7du3dyo/ePCgypYtmyGpIUnFixd3/LlixYratWuXfvjhB8dSTG3btpX079Je/5XeT0eOHHGUGYahF198UWXLlpWfn59uu+027dq1K9OYc3K/fuTIEZlMJr3++ut6//33HWOJJk2aaMuWLY56Q4cO1axZsyTJaTmpvLpw4YIee+wx1atXTwEBAQoKClLnzp21c+fODHVnzpypOnXqyM/PTyEhIWrcuLEWLVqUbftHjx5V1apVVbduXZ09ezbPcabbvn27OnfurKCgIAUEBKhdu3b65ZdfnOpYrVZNmTJF1apVk4+Pj8LCwtSyZUunv9NnzpzRsGHDVLZsWXl7e6tUqVLq2bOnUx9LUocOHXT06FHt2LHjmmMHUDCYsQEAkJSW2Ljzzjvl5eWlu+++W++88462bNmiJk2ayGKxqHfv3lq+fLnee+89eXl5Oc5buXKlkpOTNWDAAElpsy569Oihn3/+WaNGjVKtWrX0559/6v/+7//0999/a+XKlU7X/e6777RkyRKNGTNG4eHhjnVe33zzTfXo0UODBg1SSkqKFi9erLvuuktff/21unbt6jh/6NChWrJkie655x41bdpUP/zwg9PxdGfPnlXTpk0dyZSIiAitXr1aI0aMUExMjB555JFr/gxHjhypBQsWqG/fvnr00Uf166+/6pVXXtGePXu0YsUKSWlPjXXs2FERERGaMGGCihUrpiNHjmj58uWOdiIjI3X33XerXbt2eu211yRJe/bs0caNGzVu3DhJUkJCgtq0aaOTJ0/q/vvvV/ny5bVp0yZNnDhRp0+f1owZM3LcFgAAANJ+8d2sWTN9+umn6ty5syRp9erVunz5sgYMGKC33norwzk5vWfNytixYxUSEqJJkybpyJEjmjFjhsaMGaPPPvvsmt/PunXr1LlzZ1WuXFmTJ09WYmKiZs6cqRYtWuj333933Hc/8MADWrp0qcaMGaPatWsrOjpaP//8s/bs2aObb75ZKSkp6tSpk5KTkzV27FiVLFlSJ0+e1Ndff61Lly4pODhYkvTSSy/p2WefVb9+/TRy5EhFRUVp5syZat26tbZv365ixYrluK3MbNq0SWFhYRkSGBUqVNC6dev03Xff6fbbb8/y/BkzZmjs2LEKCAjQ008/LUkqUaJErj/X5557Ti+++KK6dOmiLl266Pfff1fHjh2VkpLiVC+n9+vpFi1apNjYWN1///0ymUyaOnWq7rzzTh06dEgWi0X333+/Tp06pcjIyAzLTOXFoUOHtHLlSt11112qVKmSzp49q/fee09t2rTR7t27Vbp0aUnSBx98oIcfflh9+/bVuHHjlJSUpD/++EO//vprlgm/gwcP6vbbb1doaKgiIyMVHh5+TbHu2rVLrVq1UlBQkJ544glZLBa99957atu2rX744QfHHpGTJ0/WK6+84lh2KyYmRlu3btXvv/+uDh06SJL69OmjXbt2aezYsapYsaLOnTunyMhIHTt2zGnPkUaNGklK29elYcOG1xQ/gAJiAACKvK1btxqSjMjISMMwDMNutxtly5Y1xo0b56izZs0aQ5Lx1VdfOZ3bpUsXo3Llyo7XH3/8seHh4WH89NNPTvXeffddQ5KxceNGR5kkw8PDw9i1a1eGmBISEpxep6SkGHXr1jVuv/12R9m2bdsMScYjjzziVHfo0KGGJGPSpEmOshEjRhilSpUyzp8/71R3wIABRnBwcIbr/VeFChWMrl27Znl8x44dhiRj5MiRTuWPPfaYIcn47rvvDMMwjBUrVhiSjC1btmTZ1rhx44ygoCAjNTU1yzovvPCC4e/vb/z9999O5RMmTDDMZrNx7NixHLcFAABQlM2bN89xf/b2228bgYGBjnvDu+66y7jtttsMw8j8fjAn96zp5w4ZMiTDNdu3b2/Y7XZH+f/+9z/DbDYbly5dyjbmSZMmGZKMqKioLOs0aNDAKF68uBEdHe0o27lzp+Hh4WHce++9jrLg4GBj9OjRWbazfft2Q5Lx+eefZ1nnyJEjhtlsNl566SWn8j///NPw9PR0lOekray0bNnSaNSoUYbyv/76y/D19TUkGQ0aNDDGjRtnrFy50oiPj89Qt06dOkabNm0ylKd/nv+V3k+HDx82DMMwzp07Z3h5eRldu3Z16rennnrKkOTUxzm9Xz98+LAhyQgLCzMuXLjgqPfFF19kGH+NHj060zhzwt/f3ym+pKQkw2azOdU5fPiw4e3tbTz//POOsp49exp16tTJtu0rv4979uwxSpcubTRp0sTp/WTlyr9/WenVq5fh5eVlHDx40FF26tQpIzAw0GjdurWjrH79+tmO2S5evGhIMqZNm3bVuAzDMLy8vIwHH3wwR3UBFD6WogIAaOHChSpRooRuu+02SWlTm/v376/FixfLZrNJkm6//XaFh4c7PT128eJFRUZGqn///o6yzz//XLVq1VLNmjV1/vx5x0/601MbNmxwunabNm1Uu3btDDH5+vo6Xefy5ctq1aqV05T49GWrHnroIadzx44d6/TaMAwtW7ZM3bt3l2EYTnF16tRJly9fdmo3L1atWiVJGj9+vFP5o48+Kilt6rwkFStWTJL09ddfy2q1ZtpWsWLFFB8f7zRl+r8+//xztWrVSiEhIU7vp3379rLZbPrxxx9z3BYAAADS9OvXT4mJifr6668VGxurr7/+Osun0qWc3bNmZ9SoUU7LCbVq1Uo2m01Hjx7N+5uQdPr0ae3YsUNDhw5VaGioo/ymm25Shw4dHPeuUtr94q+//qpTp05l2lb6LIo1a9YoISEh0zrLly+X3W5Xv379nO5NS5YsqWrVqjnGADlpKyvR0dEKCQnJUF6nTh3t2LFDgwcP1pEjR/Tmm2+qV69eKlGihD744INcXeNq1q1bp5SUFI0dO9ap3zKb/Z3T+/V0/fv3d3p/rVq1kpQ2s6IgeHt7Oza0t9lsio6OVkBAgGrUqOH0/S1WrJhOnDjhtCxWVv766y+1adNGFStW1Lp16zLtr9yy2Wxau3atevXq5bRvSKlSpTRw4ED9/PPPiomJccS6a9cu7d+/P9O2fH195eXlpe+//14XL1686rXT+w7A9YnEBgAUcTabTYsXL9Ztt92mw4cP68CBAzpw4IBuvfVWnT17VuvXr5ckeXp6qk+fPvriiy8ce0YsX75cVqvVKbGxf/9+7dq1SxEREU4/1atXl5RxA79KlSplGtfXX3+tpk2bysfHR6GhoYqIiNA777zjtPbu0aNH5eHhkaGNqlWrOr2OiorSpUuX9P7772eIK33fkGvdWDA9lv9eu2TJkipWrJhjcNqmTRv16dNHU6ZMUXh4uHr27Kl58+Y57cPx0EMPqXr16urcubPKli2r4cOHO5I46fbv369vv/02w/tJX3M4/f3kpC0AAACkSb+fWrRokZYvXy6bzaa+fftmWT8n96zZKV++vNPr9F8E5+SXrtlJv/esUaNGhmO1atXS+fPnFR8fL0maOnWq/vrrL5UrV0633HKLJk+e7PTL9EqVKmn8+PH68MMPFR4erk6dOmnWrFlO73H//v0yDEPVqlXLcH+6Z88ex71pTtrKjmEYmZZXr15dH3/8sc6fP68//vhDL7/8sjw9PTVq1CitW7cuZx9aDqR/rtWqVXMqj4iIyPBL/Jzer6crqO9CVux2u/7v//5P1apVk7e3t8LDwxUREaE//vjDqT+efPJJBQQE6JZbblG1atU0evRobdy4MdM2u3fvrsDAQK1Zs0ZBQUH5EmdUVJQSEhKy/C7b7XbHPi7PP/+8Ll26pOrVq6tevXp6/PHH9ccffzjqe3t767XXXtPq1atVokQJtW7dWlOnTtWZM2cyvbZhGGwcDlzHSGwAQBH33Xff6fTp01q8eLGqVavm+OnXr58kOW0iPmDAAMXGxmr16tWSpCVLlqhmzZqqX7++o47dble9evUUGRmZ6c9/Z1dc+ZRbup9++kk9evSQj4+PZs+erVWrVikyMlIDBw7McjCTnfTN+QYPHpxlXC1atMh1u5m52o2vyWTS0qVLtXnzZo0ZM8axoXmjRo0UFxcnKW2Twx07dujLL79Ujx49tGHDBnXu3FlDhgxxek8dOnTI8v306dMnx20BAADgXwMHDtTq1av17rvvqnPnzo4Zt/+VH/esZrM50/K83PPmVb9+/XTo0CHNnDlTpUuX1rRp01SnTh3HPb8kvfHGG/rjjz/01FNPKTExUQ8//LDq1KmjEydOSEq7NzWZTPr2228zvTd97733ctxWVsLCwq76S36z2ax69epp4sSJjj3urhzPZCWre/j02et5kdP79Stjz0xBfRdefvlljR8/Xq1bt9Ynn3yiNWvWKDIyUnXq1HHa3LxWrVrat2+fFi9erJYtW2rZsmVq2bKlJk2alKHNPn366ODBgzn6zAtC69atdfDgQc2dO1d169bVhx9+qJtvvlkffviho84jjzyiv//+W6+88op8fHz07LPPqlatWtq+fXuG9i5dunTN+4MAKDhsHg4ARdzChQtVvHhxzZo1K8Ox5cuXa8WKFXr33Xfl6+ur1q1bq1SpUvrss8/UsmVLfffdd46N99JVqVJFO3fuVLt27fL8dMuyZcvk4+OjNWvWyNvb21E+b948p3oVKlSQ3W7X4cOHnZ6aOnDggFO9iIgIBQYGymazOZ6Qym/psezfv1+1atVylJ89e1aXLl3KsMlh06ZN1bRpU7300ktatGiRBg0apMWLF2vkyJGSJC8vL3Xv3l3du3eX3W7XQw89pPfee0/PPvusqlatqipVqiguLi5H7+dqbQEAAOBfvXv31v33369ffvkl2028c3rP6grp95779u3LcGzv3r0KDw+Xv7+/o6xUqVJ66KGH9NBDD+ncuXO6+eab9dJLLzk2UZekevXqqV69enrmmWe0adMmtWjRQu+++65efPFFValSRYZhqFKlSo6Z2tnJrq2s1KxZU8uWLcvxZ9C4cWNJactypctqfJI+O+LSpUtOiaz/LgmW/rnu37/faVmkqKioDEmX3Nyv51R+zh5YunSpbrvtNs2ZM8epPLNf5vv7+6t///7q37+/UlJSdOedd+qll17SxIkT5ePj46g3bdo0eXp66qGHHlJgYGC2y7jlVEREhPz8/LL8Lnt4eKhcuXKOstDQUA0bNkzDhg1TXFycWrdurcmTJzvGWVJa3zz66KN69NFHtX//fjVo0EBvvPGGPvnkE0edkydPKiUlxWlsB+D6wowNACjCEhMTtXz5cnXr1k19+/bN8DNmzBjFxsbqyy+/lCR5eHiob9+++uqrr/Txxx8rNTXVaRkqKe2Jr5MnT2a6nm1iYqJjynt2zGazTCaT0xNSR44c0cqVK53qderUSZI0e/Zsp/KZM2dmaK9Pnz5atmyZ/vrrrwzXi4qKumpMV9OlSxdJ0owZM5zKp0+fLknq2rWrpLSp5P996qpBgwaS5FiOKjo62um4h4eHbrrpJqc6/fr10+bNm7VmzZoMsVy6dEmpqak5bgsAAAD/CggI0DvvvKPJkyere/fuWdbL6T2rK5QqVUoNGjTQggULdOnSJUf5X3/9pbVr1zruXW02W4ZloIoXL67SpUs77hVjYmIc95bp6tWrJw8PD0edO++8U2azWVOmTMlwr2sYhuOeNCdtZaVZs2a6ePFihj0nfvrpp0z3rkvfR+TKJYz8/f2dPo90VapUkSSnfS/i4+O1YMECp3rt27eXxWLRzJkznd7nf8cAUs7v13MjPRmV2XvILbPZnKGvPv/8c508edKp7L/jCS8vL9WuXVuGYWT43E0mk95//3317dtXQ4YMcYwjrzXOjh076osvvtCRI0cc5WfPntWiRYvUsmVLx7JX/401ICBAVatWdXy3EhISlJSU5FSnSpUqCgwMzPD927ZtmySpefPm1/weABQMZmwAQBH25ZdfKjY2Vj169Mj0eNOmTRUREaGFCxc6Ehj9+/fXzJkzNWnSJNWrVy/DEyz33HOPlixZogceeEAbNmxQixYtZLPZtHfvXi1ZskRr1qxxPD2Vla5du2r69Om64447NHDgQJ07d06zZs1S1apVndZIbdSokfr06aMZM2YoOjpaTZs21Q8//KC///5bkvMTTa+++qo2bNigW2+9Vffdd59q166tCxcu6Pfff9e6det04cKFq35eBw4cyPQpsoYNG6pr164aMmSI3n//fV26dElt2rTRb7/9pgULFqhXr16OjdkXLFig2bNnq3fv3qpSpYpiY2P1wQcfKCgoyDHAHDlypC5cuKDbb79dZcuW1dGjRzVz5kw1aNDA8Xk//vjj+vLLL9WtWzcNHTpUjRo1Unx8vP78808tXbpUR44cUXh4eI7aAgAAgLOcLNuZ03vWgjR9+nT5+fk5lXl4eOipp57StGnT1LlzZzVr1kwjRoxQYmKiZs6cqeDgYE2ePFmSFBsbq7Jly6pv376qX7++AgICtG7dOm3ZskVvvPGGpLSla8eMGaO77rpL1atXV2pqqj7++GPHw0NS2i+HX3zxRU2cOFFHjhxRr169FBgYqMOHD2vFihUaNWqUHnvssRy1lZWuXbvK09NT69at06hRoxzlr732mrZt26Y777zT8QDP77//ro8++kihoaFOG3s3atRI77zzjl588UVVrVpVxYsX1+23366OHTuqfPnyGjFihB5//HGZzWbNnTtXEREROnbsmOP8iIgIPfbYY3rllVfUrVs3denSRdu3b9fq1aszzHLI6f16bjRq1EiS9PDDD6tTp04ym80aMGBArtpI161bNz3//PMaNmyYmjdvrj///FMLFy50mokiSR07dlTJkiXVokULlShRQnv27NHbb7+trl27KjAwMEO7Hh4e+uSTT9SrVy/169dPq1at0u23337VeObOnZvpXoDjxo3Tiy++qMjISLVs2VIPPfSQPD099d577yk5OVlTp0511K1du7batm2rRo0aKTQ0VFu3btXSpUs1ZswYSdLff/+tdu3aqV+/fqpdu7Y8PT21YsUKnT17NsPnGBkZqfLly6thw4Y5+jwBuIABACiyunfvbvj4+Bjx8fFZ1hk6dKhhsViM8+fPG4ZhGHa73ShXrpwhyXjxxRczPSclJcV47bXXjDp16hje3t5GSEiI0ahRI2PKlCnG5cuXHfUkGaNHj860jTlz5hjVqlUzvL29jZo1axrz5s0zJk2aZPz3f13x8fHG6NGjjdDQUCMgIMDo1auXsW/fPkOS8eqrrzrVPXv2rDF69GijXLlyhsViMUqWLGm0a9fOeP/996/6WVWoUMGQlOnPiBEjDMMwDKvVakyZMsWoVKmSYbFYjHLlyhkTJ040kpKSHO38/vvvxt13322UL1/e8Pb2NooXL25069bN2Lp1q6PO0qVLjY4dOxrFixc3vLy8jPLlyxv333+/cfr0aaeYYmNjjYkTJxpVq1Y1vLy8jPDwcKN58+bG66+/bqSkpOSqLQAAgKJq3rx5hiRjy5Yt2darUKGC0bVrV6eynN6zVqhQwRgyZMhVr7lhwwZDkrFhw4ZsY0m/RmY/ZrPZUW/dunVGixYtDF9fXyMoKMjo3r27sXv3bsfx5ORk4/HHHzfq169vBAYGGv7+/kb9+vWN2bNnO+ocOnTIGD58uFGlShXDx8fHCA0NNW677TZj3bp1GeJatmyZ0bJlS8Pf39/w9/c3atasaYwePdrYt29frtvKTI8ePYx27do5lW3cuNEYPXq0UbduXSM4ONiwWCxG+fLljaFDhxoHDx50qnvmzBmja9euRmBgoCHJaNOmjePYtm3bjFtvvdVxzzx9+nRHPx0+fNhRz2azGVOmTDFKlSpl+Pr6Gm3btjX++uuvDH1sGDm7Xz98+LAhyZg2bVqG9yvJmDRpkuN1amqqMXbsWCMiIsIwmUwZvmfZ8ff3d4ovKSnJePTRRx3vo0WLFsbmzZuNNm3aOH0u7733ntG6dWsjLCzM8Pb2NqpUqWI8/vjjTuO69O9jVFSUoywhIcFo06aNERAQYPzyyy9ZxpX+GWf1c/z4ccMw0sZRnTp1MgICAgw/Pz/jtttuMzZt2uTU1osvvmjccsstRrFixQxfX1+jZs2axksvveT4rM+fP2+MHj3aqFmzpuHv728EBwcbt956q7FkyRKndmw2m1GqVCnjmWeeyfHnC6DwmQyjEHekAgCgEOzYsUMNGzbUJ598okGDBrk6HAAAAAD54KefflLbtm21d+9epz32gPy0cuVKDRw4UAcPHlSpUqVcHQ6ALLDHBgDArSUmJmYomzFjhjw8PNS6dWsXRAQAAACgILRq1UodO3Z0Wn4IyG+vvfaaxowZQ1IDuM4xYwMA4NamTJmibdu26bbbbpOnp6dWr16t1atXa9SoUXrvvfdcHR4AAAAAAADyGYkNAIBbi4yM1JQpU7R7927FxcWpfPnyuueee/T000/L09PT1eEBAAAAAAAgn5HYAAAAAAAAAAAAboM9NgAAAAAAAAAAgNtgjQ4XstvtOnXqlAIDA2UymVwdDgAAAFBoDMNQbGysSpcuLQ8PnrdKxxgBAAAARVVuxggkNlzo1KlTKleunKvDAAAAAFzm+PHjKlu2rKvDuG4wRgAAAEBRl5MxAokNFwoMDJSU1lFBQUGFdl2r1aq1a9eqY8eOslgshXZd5A395T7oK/dCf7kP+sq90F/uw9V9FRMTo3LlyjnuiZGGMQKuhr5yL/SX+6Cv3Av95T7oK/fi6v7KzRiBxIYLpU8tDwoKKvRBi5+fn4KCgvgHxQ3QX+6DvnIv9Jf7oK/cC/3lPq6XvmK5JWeMEXA19JV7ob/cB33lXugv90FfuZfrpb9yMkZgMVsAAAAAAAAAAOA2SGwAAAAAAAAAAAC3QWIDAAAAAAAAAAC4DfbYAAAAQKZsNpusVmuuzrFarfL09FRSUpJsNlsBRYb8UBh95eXlJQ8PnqUCAABwF3kZA2SH8YF7Kej+slgsMpvN+dIWiQ0AAAA4MQxDZ86c0aVLl/J0bsmSJXX8+HE2hb7OFUZfeXh4qFKlSvLy8iqQ9gEAAJA/rmUMcLV2GR+4j8Lor2LFiqlkyZLX3D6JDQAAADhJH9AUL15cfn5+ubrhtNvtiouLU0BAAE/qX+cKuq/sdrtOnTql06dPq3z58gxkAQAArmPXMgbIDuMD91KQ/WUYhhISEnTu3DlJUqlSpa6pPRIbAAAAcLDZbI4BTVhYWK7Pt9vtSklJkY+PDwOX61xh9FVERIROnTql1NRUWSyWArkGAAAArs21jgGyw/jAvRR0f/n6+kqSzp07p+LFi1/TslR8mwAAAOCQvp6un5+fiyPBjSB9CSrWUwYAALh+MQZAYUr/nl3rXi4kNgAAAJABywYhP/A9AgAAcB/cu6Ew5Nf3jMQGAAAAAAAAAABwGyQ2AAAAAAAAAACA2yCxAQAAgHxnsxv688B5/fD7Cf154LxsdsPVIeVaxYoVNWPGDFeHAQAAAFz3zl1M0IETlzL8HDxxSUdOxyrqYoKrQ8yx63Ec8P3338tkMunSpUuuDuW64enqAAAAAHBj2bInSgsjf1X05SRHWViwj0b1qqfmN5XO9+tdbY3WSZMmafLkyblud8uWLfL3989jVM4+/fRTDR48WA888IBmzZqVL21mZ/LkyVq5cqV27NhR4NcCAABA0XbuYoIeeHW9rKn2LOtYPD307oR2Kh6SfxuUX8/jgLZt2+qHH37QK6+8ogkTJjgd69q1q1atWpWr+Jo3b67Tp08rODg4zzEdOXJElSpV0vbt29WgQYM8t3O9YMYGAAAA8s3mP0/rraW7nZIakhR9OUmvLNiiTX+cyvdrnj592vEzY8YMBQUFOZU99thjjrqGYSg1NTVH7UZERMjPL38GXnPmzNETTzyhTz/9VElJSVc/AQAAAHATMfEp2SY1JMmaaldMfEq+Xvd6HweUK1dO8+fPdyo7efKk1q9fr1KlSuWqLS8vL5UsWZIN3q9AYqOIshvSXwej3Xp5CAAAUPAMw1BScmqOfuITrXp/5V/Ztvf+yj8Vn2jNUXuGkbP7k5IlSzp+goODZTKZHK/37t2rwMBArV69Wo0aNZK3t7d+/vlnHTx4UD179lSJEiUUEBCgJk2aaN26dU7t/ncKuslk0ocffqjevXvLz89P1apV05dffnnV+A4fPqxNmzZpwoQJql69upYvX+441rx5cz355JNO9aOiomSxWPTjjz9KShuwde3aVb6+vqpUqZIWLVp0zdPj//zzT7Vv316lSpVSRESERo0apbi4OMfx77//Xrfccov8/f1VrFgxtWjRQkePHpUk7dy5U7fddpsCAwMVFBSkRo0aaevWrXmOBa6XHBWl+EOHZT4frfhDhxV38JDTT3JUlKtDBAAAhSw344CUFFuO2kxJsRWpcUC3bt10/vx5bdy40VG2YMECdezYUcWLF3eq+/HHH6tx48YKDAxUyZIlNXDgQJ07d85x/L9LUc2fP1/FihXTmjVrVKtWLQUEBOiOO+7Q6dOnc/TZZSY5OVnjxo1TtWrV5Ofnp5YtW2rLli2O4xcvXtSgQYMUEREhX19fVatWTfPmzZMkpaSkaMyYMSpVqpR8fHxUoUIFvfLKK3mOJSdYiqoI+uWvM/rsVyn+p18dZQW5PAQAAHBfySk23fXUN/nWXvTlJA14ZlWO6n7+clf5eOfP7eqECRP0+uuvq3LlygoJCdHx48fVpUsXvfTSS/L29tZHH32k7t27a9++fSpfvnyW7UyZMkVTp07VtGnTNHPmTA0aNEhHjx5VaGholufMmzdPXbt2VXBwsAYPHqw5c+Zo4MCBkqRBgwZp6tSpevXVVx1PX3322WcqXbq0WrVqJUm69957df78eX3//feyWCwaP3680yAnt+Lj49WpUyc1bdpU69evV0JCgkaNGqUxY8Zo/vz5Sk1NVa9evXTffffp008/VUpKin777TdHfIMGDVLDhg31zjvvyGw2a8eOHbJYLHmOB66VHBWlbQ+OlWG1KkTSri8z/n03WSxq9M5MeUdEFH6AAADAJfJ7HCBJT876OUf1bpRxgJeXlwYNGqR58+apRYsWktISElOnTs2wBJXVatULL7ygGjVq6Ny5cxo/fryGDh2qVauyHjslJCTo9ddf18cffywPDw8NHjxYjz32mBYuXJi7D+kfTzzxhJYvX67Zs2erVq1aev3119WpUycdOHBAoaGhevbZZ7V7926tXr1a4eHhOnDggBITEyVJb731lr788kstWbJE5cuX1/Hjx3X8+PE8xZFTzNgoYjb9cUpTP/ld/535VZDLQwAAALja888/rw4dOqhKlSoKDQ1V/fr1df/996tu3bqqVq2aXnjhBVWpUuWqT14NHTpUd999t6pWraqXX35ZcXFx+u2337Ksb7fbNX/+fA0ePFiSNGDAAP388886fPiwJKlfv346deqUfv7530HeokWLdPfdd8tkMmnv3r1at26dPvjgA9166626+eab9eGHHzoGEHmxaNEiJSUlacGCBapdu7Zuv/12vf322/r444919uxZxcTE6PLly+rWrZuqVKmiWrVqaciQIY6B3rFjx9S+fXvVrFlT1apV01133aX69evnOR64ljUmVobVmm0dw2qVNSa2kCICAADIP64aB6QbPny4lixZovj4eP3444+O++zM6nXu3FmVK1dW06ZN9dZbb2n16tVOs6r/y2q16t1331Xjxo118803a8yYMVq/fv3VP5RMxMfH65133tFrr72mDh06qHbt2vrggw/k6+urOXPmSEobBzRs2FCNGzdWxYoV1b59e3Xv3t1xrFq1amrZsqUqVKigli1b6u67785TLDnFjI0ixGY39P7KP7Ot88EXf+nWuqVk9mC9NgAAIHl7mfX5y11zVHfXoWhN/vCXq9abPLKp6lQOy9G180vjxo2dXsfFxWny5Mn65ptvdPr0aaWmpioxMVHHjh3Ltp2bbrrJ8Wd/f38FBQVlO3siMjJS8fHx6tKliyQpPDxcHTp00Ny5c/XCCy8oIiJCHTt21MKFC9WqVSsdPnxYmzdv1nvvvSdJ2rdvnzw9PXXzzTc72qxatapCQkJy/Rmk27Nnj+rXry9/f3/FxMRIklq0aCG73a59+/apdevWGjp0qDp16qQOHTqoffv26tevn2Md4PHjx2vkyJH6+OOP1b59e911112qUqVKnuOBa12IydmeLxdikhRQwLEAAIDrR27GAYdOXs7RbIzXRrdU5TJX3/z6RhgHpKtfv76qVaumpUuXasOGDbrnnnvk6ZnxV/Lbtm3T5MmTtXPnTl28eFF2e9qeJceOHVPt2rUzbdvPz8/pPrxUqVJ5ntl98OBBWa1Wx8wSSbJYLLrlllu0Z88eSdKDDz6oPn366Pfff1fHjh3Vq1cvNW/eXFJa4qdDhw6qUaOG7rjjDnXr1k0dO3bMUyw5xYyNImT3oWjHRp4mw67yCWdUK/awyieckclI+8ty/lKidh+KdmWYAADgOmIymeTj7ZmjnwY1iiss2Cfb9sKL+apBjeI5ai8/N8bz9/d3ev3YY49pxYoVevnll/XTTz9px44dqlevnlJSst/Q8L9LLplMJsegIzNz5szRhQsX5OvrK09PT3l6emrVqlVasGCB47xBgwZp6dKlslqtWrRokerVq6d69erl8Z3mj3nz5mnz5s1q3ry5PvvsM1WvXl2//JKWtJo8ebJ27dqlrl276rvvvlPt2rW1YsUKl8aLvItPzH62Rm7rAQCAG0NuxgFeOUxEeHmZi8w44ErDhw/XrFmztHTpUg0fPjzD8fSlYoOCgrRw4UJt2bLFcX+dXVyZxZTT/UnyonPnzjp69Kj+97//6dSpU2rXrp1jg/abb75Zhw8f1gsvvKDExET169dPffv2LbBYJBIbRUr601jV447qwSPLNfDUWvU8+5MGnlqrB48sV/W4o071AAAAcsPsYdJ9PetmW+e+nnWvi5mhGzdu1NChQ9W7d2/Vq1dPJUuW1JEjR/L1GtHR0friiy+0ePFi7dixw/Gzfft2Xbx4UWvXrpUk9ezZU0lJSfr222+1aNEiDRo0yNFGjRo1lJqaqu3btzvKDhw4oIsXL+Y5rlq1amnnzp2Kj493lG3cuFEeHh6qUaOGo6xhw4aaOHGiNm3apLp162rRokWOY9WrV9f//vc/rV27Vnfeeadj00AAAADgelYY44D/GjhwoP7880/VrVs309kXe/fuVXR0tF599VW1atVKNWvWvKY99fKiSpUq8vLyctro3Gq1asuWLU4xR0REaMiQIfrkk080Y8YMvf/++45jQUFB6t+/vz744AN99tlnWrZsmS5cuFBgMbMUVRESGuSj6nFH1fvMDxmOBdoS1PvMD1pRso1Cg1pkcjYAAMDVNatXSg/3ra2FkYccM0WltJka9/Wsq+Y3lXZhdP+qVq2ali9fru7du8tkMunZZ5/N8RNXOfXxxx8rLCxM/fr1y/DUWZcuXTRnzhzdcccd8vf3V69evfTss89qz549TmvR1qxZU+3bt9eoUaP0zjvvyGKx6NFHH5Wvr+9Vn2RLTEzUjh07nMoCAwM1aNAgTZo0SUOHDtWjjz6qxMREjR07Vvfcc49KlCihw4cP6/3331ePHj1UunRp7du3T/v379e9996rxMREPf744+rbt68qVaqkEydOaMuWLerTp0++fW4AAABwL0H+XrJ4esiamvX9tMXTQ0H+XoUYVeYKYxzwXyEhITp9+nSGGRbpypcvLy8vL82cOVMPPPCA/vrrL73wwgsFFs++ffsylNWpU0cPPvignnzySfn4+KhmzZp6/fXXlZCQoBEjRkiSnnvuOTVq1Eh16tRRcnKyvv76a9WqVUuSNH36dJUqVUoNGzaUh4eHPv/8c5UsWVLFihUrsPdBYqMIqVWhmDpGb5Uk/XcYbJJkSOoYvVW1KjxU2KEBAIAbSJNaEWrbpLL2HrmoCzFJCg3yUe3KYdfFTI1006dP1/Dhw9W8eXOFh4frySefdOw3kV/mzp2r3r17Z5qA6NOnj+655x6dP39e4eHhGjRokLp06aLWrVs7NulO99FHH2nEiBFq3bq1SpYsqVdeeUW7du2Sj0/2y379/fffatiwoVNZu3bttG7dOq1Zs0bjxo1Tu3bt5Ofnpz59+mj69OmS0tbq3bt3rxYsWKDo6GiVKlVKo0eP1v3336/U1FRFR0fr3nvv1dmzZxUeHq4777xTU6ZMucZPCwAAAO6qeIif3p3QTjHxGZdNMux2xcfHq1TxEBUP8XNBdM4KYxyQmex+wR8REaH58+frqaee0ltvvaWbb75Zr7/+unr06FEgsQwYMCBD2fHjx/Xqq6/KZrPpgQceUFxcnBo3bqw1a9Y49vfz8vLSxIkTdeTIEfn6+qpVq1ZavHixpLQHqKZOnar9+/fLbDarSZMmWrVqlTw8Cm7BKJNRkAtvIVsxMTEKDg7W5cuXFRQUVODXu/znX/rrmUlXrVf3xSkKrpf9MhIoPFarVatWrVKXLl2yzOzi+kBfuRf6y33QV4UrKSlJhw8fVqVKla76i/PM2O12xcTEKCgoqEBvYouyEydOqFy5clq3bp3atWuX53YKo6+y+z4V9r2wuyjsz2XPpp268NrzV60X+uRzqtW8foHHg6vj/4vuhf5yH/SVe6G/8te1jgGyw/jAvbjTGIEZG0VISg7XYs5pPQAAABS87777TnFxcapXr55Onz6tJ554QhUrVlTr1q1dHRpuAB4BAUo1ecjTyHoJhlSThzwCAgoxKgAAACB7JDaKEK9/pg3lVz0AAAAUPKvVqqeeekqHDh1SYGCgmjdvroULF/J0IvKFOTRM75fvJV9bsiSpU9QvKp0crR9CG+iQXxlJUqLZW1NCw1wZJgAAAOCExEYRElS7lrzCwpQSHZ1lHa/wMAXVrlWIUQEAACA7nTp1UqdOnVwdBm5QQf5eSvQNUsw/m33GefpJydFKMnvrrE9aMuN62ewTAAAASEdiowgxmc2qfN9w7X11mgxl3EBckiqPHC6T2VzYoQEAAABwgfTNPi9cTtDGnzfKK9ZfipeaVQvRvYPaSEpLflwPm30CAAAA6dixpYgJa9ZUVR8bL7uf88DEKzxMNSc8rrBmTV0UGQAAAABXKB7ipyplghUeKJn/GSd4G1ZVLVtMVcsWI6kBAACA6w4zNoqg0Ka36OL5cwr/85C0bZPOhJTTne+/wUwNAAAAoIjz8PGRJKXGJ7g4EgAAACBrzNgoqjw8ZKlQQZJkNXmS1AAAAAAgj39mbNgTSWwAAADg+sWMjSLMK8BfVkmeKUmuDgUAAADAdcDTkdhIdCpPjoqSNSY2y/MsQYHyjogo0NgAAACAdCQ2ijCf4ADFS/JMTXZ1KAAAAACuA5aAf/bTSP734afkqChte3CsDKs1y/NMFosavTOT5AYAAAAKBUtRFWG+QQGSJEtqigzDcHE0AADgRmLYbLr851+K+vEnXf7zLxk2m6tDuqq2bdvqkUcecXUYgEt5+ftLkjyuSGxYY2KzTWpIkmG1ZjujAwAA3NiSo6IUd/BQpj+JR44qOSrK1SFmyRXjgIoVK2rGjBmFes0bDTM2ijDfYkGSJG97ipKtNvl48XUAAADXLmbrNu1f9JlSoqMdZV5hYap833CFNWua79fr3r27rFarvv322wzHfvrpJ7Vu3Vo7d+7UTTfdlC/XS0xMVJkyZeTh4aGTJ0/K29s7X9rNypEjR1SpUiVt375dDRo0KNBrAd5B/yQ2rMzqBgAAOeOq2Z2FNQ6YP3++hg0bppo1a2rPnj1Oxz7//HP169dPFSpU0JEjR3Lc5pYtW+T/zwMledW2bVs1aNCgyCZImLFRhKXP2PC2W5WQlP0TWAAAADkRvflXHZ852ympIUkp0dHa++o0RW/+Jd+vOWLECEVGRurEiRMZjs2bN0+NGzfOt6SGJC1btkx16tRRzZo1tXLlynxrF7ge+AQFSpI8SWwAAIAcctXszsIcB/j7++vcuXPavHmzU/mcOXNUvnz5XLcXEREhv3/2NkPekNgowrwC0hIbHjKUcDnOxdEAAIDrkWEYsiUl5egnNSFBRz6cm217hz6Yo9SEhBy1l9OlMrt166aIiAjNnz/fqTwuLk6ff/65RowYoejoaN19990qU6aM/Pz8VK9ePX366ad5+kzmzJmjwYMHa/DgwZozZ46j/P3331fp0qVlt9ud6vfs2VPDhw93vH7xxRdVvHhxBQYGauTIkZowYcI1zcRITk7Www8/rOLFi8vHx0ctW7bUli1bHMcvXryoQYMGKSIiQr6+vqpWrZrmzZsnSUpJSdHYsWNVqlQp+fj4qEKFCnrllVfyHAvcn19w2pODnjaWqwUAoCjLzTjAnpyzByLsycluOw7w9PTUwIEDNXfuv+OdEydO6Pvvv9fAgQOd6h48eFA9e/ZUiRIlFBAQoCZNmmjdunVOdf67FJXJZNKHH36o3r17y8/PT9WqVdOXX36Z6zivlP5Alre3typWrKg33njD6fjs2bNVrVo1+fj4qESJEurbt6/j2NKlS1WvXj35+voqLCxM7du3V3x8/DXFk99Ye6gIM3lZZDN5yGzYlXApVirnPBXMsNkUs3uPUi5elFdIiIJq15LJbHZRtAAAwBXsycn6pf+gfGsvJfqCfr37nhzVbfrZQpl9fK5az9PTU/fee6/mz5+vp59+WiaTSVLatHCbzaa7775bcXFxatSokZ588kkFBQXpm2++0T333KMqVarolltuyXH8Bw8e1ObNm7V8+XIZhqH//e9/Onr0qCpUqKC77rpLY8eO1YYNG9SuXTtJ0oULF/Ttt99q1apVkqSFCxfqpZde0uzZs9WiRQstXrxYb7zxhipVqpTjGP7riSee0LJly7RgwQJVqFBBU6dOVadOnXTgwAGFhobq2Wef1e7du7V69WqFh4frwIEDSkxMlCS99957+uqrr7RkyRKVL19ex48f1/Hjx/McC9yff7EgXZZkNuyyp6TIXMBLrQEAgOtTfo8DJOnPic/kqN71OA6QpOHDh6tt27Z688035efnp/nz5+uOO+5QiRIlnOrFxcWpS5cueumll+Tt7a2PPvpI3bt31759+7Kd3TFlyhRNnTpV06ZN08yZMzVo0CAdPXpUoaGhuYpTkrZt26Z+/fpp8uTJ6t+/vzZt2qSHHnpIYWFhGjp0qLZu3aqHH35YH3/8sZo3b64LFy7op59+kiSdOXNGgwYN0tSpU9W7d2/Fxsbqp59+uu4eeiGxUYSZTCZZzV4ypyYp8bLzVLDozb/o0AdzC21tbAAAgGsxfPhwTZs2TT/88IPatm0rKW36eZ8+fRQcHKzg4GA99thjjvpjx47VmjVrtGTJklwNaObOnavOnTsrJCREktSpUyfNmzdPkydPVkhIiDp37qxFixY5EhtLly5VeHi4brvtNknSzJkzNWLECA0bNkyS9Nxzz2nt2rWKi8vb7Nn4+Hi98847mj9/vjp37ixJ+uCDDxQZGak5c+bo8ccf17Fjx9SwYUM1btxYUtrTYZJkt9t14sQJVatWTS1btpTJZFKFChXyFAduHAHB/jIkmSSlxCfIl8QGAAC4jhXWOECSGjZsqMqVK2vp0qW65557NH/+fE2fPl2HDh1yqle/fn3Vr1/f8fqFF17QihUr9OWXX2rMmDFZtj906FDdfffdkqSXX35Zb731ln777TfdcccduYpTkqZPn6527drp2WeflSRVr15du3fv1rRp0zR06FAdO3ZM/v7+6tatmwIDA1WhQgU1bNhQdrtdZ8+eVWpqqu68807H+KBevXq5jqGgkdgo4qwWb/mkJikp5t/BdPTmX7T31WkZ6qavjV1zwuMkNwAAKCI8vL3V9LOFOap7eddu7Xn+pavWq/Xc0wquUztH186pmjVrqnnz5po7d67atm2rAwcO6KefftLzzz8vSbLZbHr55Ze1ZMkSnTx5UikpKUpOTs7VurY2m00LFizQm2++6SgbPHiwHnvsMT333HPy8PDQoEGDdN9992n27Nny9vbWwoULNWDAAHl4pK0Au2/fPj300ENO7d5yyy367rvvchzHlQ4ePCir1aoWLVo4yiwWi2655RbHxoYPPvig+vTpo99//10dO3ZUr1691Lx5c0nSwIEDdeedd6pGjRq644471K1bN3Xs2DFPseDG4O/nrWQPi3zsViVcjJFvaIirQwIAAC6Qm3FA/KHDOZqNUe+VF+Vf+eozla+3ccCVhg8frnnz5ql8+fKKj49Xly5d9PbbbzvViYuL0+TJk/XNN9/o9OnTSk1NVWJioo4dO5Zt21fuB+Lv76+goCCdO3cuT3Hu2bNHPXv2dCpr0aKFZsyYIZvNpg4dOqhChQqqXLmy7rjjDt1xxx3q3bu3fHx8VLduXbVr10716tVTp06d1LFjR/Xt29fxcNf1gj02ijibJW1aV3JsWmLDsNl06IOrrI394VwZNluBxwYAAFzPZDLJ7OOTo5+QBvXlFRaWbXte4WEKaVA/R+2lTyXPqREjRmjZsmWKjY3VvHnzVKVKFbVp00aSNG3aNL355pt68skntWHDBu3YsUOdOnVSSkpKjttfs2aNTp48qf79+8vT01Oenp4aMGCAjh49qvXr10uSunfvLsMw9M033+j48eP66aefNGhQ/k7hz63OnTvr6NGj+t///qdTp06pXbt2jqfW6tevr4MHD+qFF15QYmKi+vXr57S2Looei6eHrB4WSVLcxbRZ3ZagQJkslmzPM1kssvyz8TgAAHB/uRkH5DQR4eHt7ZbjgCsNGjRIv/zyiyZPnqx77rlHnp4Z5w089thjWrFihV5++WX99NNP2rFjh+rVq3fVa1r+c79lMpky7N+XXwIDA/X777/r008/ValSpfTcc8+pfv36unTpksxms9asWaPVq1erdu3amjlzpmrUqKHDhw8XSCx5RWKjiLN7pSU2rHFpm7/E7N7jtPxUZlLORytm954Cjw0AALgXk9msiiOGZVun8sjhBbZnV79+/eTh4aFFixbpo48+0vDhwx2Doo0bN6pnz54aPHiw6tevr8qVK+vvv//OVftz5szRgAEDtGPHDqefAQMGODYR9/Hx0Z133qmFCxfq008/VY0aNXTzzTc72qhRo4bTxt6SMrzOjSpVqsjLy0sbN250lFmtVm3ZskW1a/87KyYiIkJDhgzRJ598ohkzZuj99993HAsKClL//v31wQcf6LPPPtOyZct04cKFPMcE92f1TPvlRMI/y9V6R0So0TszVX/6NHmXKC5J8ilTWvWnT3P8NHpnprwjIrJsEwAAoKAU9DjgSqGhoerRo4d++OEHDR8+PNM6Gzdu1NChQ9W7d2/Vq1dPJUuW1JEjR/J8zbyoVauW0xghPa7q1avL/M94zNPTU+3bt9fUqVP1xx9/6MiRI46Z5CaTSS1atNCUKVO0fft2eXl5acWKFYX6Hq6GpaiKOMPbObGRcvFijs7LaT0AAFC0hDW7VeXGPqSziz5z3qsrPEyVRxbsXl0BAQHq37+/Jk6cqJiYGA0dOtRxrFq1alq6dKk2bdqkkJAQTZ8+XWfPnnX65X92oqKi9NVXX+nLL79U3bp1nY7de++96t27ty5cuKDQ0FANGjRI3bp1065duzR48GCnumPHjtV9992nxo0bq3nz5vrss8/0xx9/qHLlyleNYd++fRnK6tSpowcffFCPP/64QkNDVb58eU2dOlUJCQkaMWKEpLR9PBo1aqQ6deooOTlZX3/9tWrVqiVJmjVrlipWrKhGjRrJw8NDn3/+uUqWLKlixYrl6HPBjSnV4i0lSYkx/+7D5x0RIe+ICBnWVEmSyeShgCpX/94CAIAbX/rsTsNqzbJOQc7uLMhxQGbmz5+v2bNnKyyL2erVqlXT8uXL1b17d5lMJj377LMFNvMiKipKO3bscCorVaqUHn30UTVp0kQvvPCC+vfvr82bN+vtt9/W7NmzJUlff/21Dh06pNatWyskJESrVq2S3W5XjRo1tHXrVv3666/q1KmTihcvrl9//VVRUVGOMcT1gsRGUefjK0myxSdIkrxyuFZaTusBAICiJ6hxI5Vp01pxe/cp5eJFeYWEKKh2rQKbqXGlESNGaM6cOerSpYtKly7tKH/mmWd06NAhderUSX5+fho1apR69eqly5cv56jdjz76SP7+/o5Nwa/Url07+fr66pNPPtHDDz+s22+/XaGhodq3b58GDhzoVHfQoEE6dOiQHnvsMSUlJalfv34aOnSofvvtt6vGMGDAgAxlx48f16uvviq73a577rlHsbGxaty4sdasWeNYA9fLy0sTJ07UkSNH5Ovrq1atWmnx4sWS0gaBr7/+uvbv3y+z2awmTZpo1apVjj1BUDTZLWkzNpJj4zMcS01IGzfYrXlbvgEAANx40md3Wq94KCKd3W5XfHy8ipUqWaCzOwtqHJAZX19f+fr6Znl8+vTpGj58uJo3b67w8HA9+eSTiomJyfP1srNo0SItWrTIqeyFF17QM888oyVLlui5557TCy+8oFKlSun55593JH2KFSum5cuXa/LkyUpKSlK1atX06aefqk6dOkpISNCPP/6oN998UzExMapQoYLeeOMNde7cuUDeQ16R2CjiTP/8JbQlpA1agmrXkldYWLbLUXmFhymo9vWVoQMAANcXk9ms4Hp1r14xnzVr1kyGYWQoDw0N1cqVK7M99/vvv8/y2KOPPqpHH30002NeXl66eMVsVg8PD506dSrLtp599lk9++yzjtcdOnRQ1apVs6xfsWLFTN/Tld566y299dZbmR575pln9MwzGTdztNvtGjJkiMaOHUsiA07SZ3Wn/LMPXzp7aqrsSUlpf07J+olMAABQ9KTP7vwvu90ue0yMvIOCCvT6BTUOkKShQ4c6zQL5r0ceeUSPPPKI43XFihUdSzqlGz16tNPr/y5NlVnsly5dyjauq8Xdp08f9enTJ9NjLVu2zPT89Fkbq1evvu7HCNd3dChwZj8/SZKRlCgp7ZcQle/LfH24dAW5NjYAAMCNLCEhQdOnT9euXbu0d+9eTZo0SevWrdOQIUNcHRrgYEpPbPwzqzudLeHf19ktNQEAAAAUNBIbRZzZ3z/tD/8kNiQprFlT1ZzwuDx8fJzqeoWHqeaExwt0bWwAAIAbmclk0qpVq9S6dWs1atRIX331lZYtW6b27du7OjTAweSb9vBT6n8SG1e+tqewFBUAAABch6WoijhLemIjOcmpPKxZU4Vt2aqo9RskSbWenqiQRg2ZqQEAAHANfH19tW7dOleHAWTL7Je2XK094T8zNuL/3XPDbrXKMAyZTKZCjQ0AAACQmLFR5FkC0hIb5v8kNiTJFvfvwCWgWhWSGgAAAEAR4OmfNmMjfT+NdKlXJDZkGDJSUwszLAAAAMCBxEYR5x0YIEkyWzMmNlLj/t0skM0BAQAoWux2u6tDwA3gapue4/pkyWS5Wsl5jw0pbdYGAAC4cTAGQGHIr+8ZS1EVcd5BAbJK8rQmZziWGhvr+LPdyhq6AAAUBV5eXvLw8NCpU6cUEREhLy+vXC01Y7fblZKSoqSkJHl48AzN9ayg+8owDEVFRclkMsliseR7+yg4XoFpiQ1TSjYzNvTPw09+hRYWAAAoINc6BsgO4wP3UpD9ZRiGUlJSFBUVJQ8PD3l5eV1TeyQ2iji/YoGKk2SxZUxcWGOZsQEAQFHj4eGhSpUq6fTp0zp16lSuzzcMQ4mJifL19WXt/etcYfSVyWRS2bJlZWZJU7fiExQgmyRzivPDT/9NbBg8/AQAwA3hWscA2WF84F4Ko7/8/PxUvnz5a06ckNgo4vyCAyVJFnuq7Kmp8vBM+0oYhuG0FJXBNHMAAIoMLy8vlS9fXqmpqbLZbLk612q16scff1Tr1q15Sv86Vxh9ZbFYSGq4Id/AAMVJMqc6JzZs8f9ZioqHnwAAuGFcyxggO4wP3EtB95fZbJanp2e+JE1IbBRx/sUCHX+2xsXLu1iwJMmekuKUzLCn8DQWAABFSfryQbm9mTWbzUpNTZWPjw8Dl+scfYX/SoyO075f/tTlU2dkluRlTdaeTTsdx1NPnnGqz3K1AADcWPI6BsgO95zuxZ36i8RGEefrbVGKPOQlu6K2bFOZ29vIZDYrNSbWqR4bAwIAAAA3rtMHT6jUlyt12Viu9Dk2FiNVF1573lHHLpOuXDCAGRsAAABwFXZsKcIu/PKb/nhotLyUthP90bdnaet9Dyp68y9Oy1BJzNgAAAAAbmQxURfladizreMhw+k1MzYAAADgKszYKKK8jhzVgbkfZShPiY7W3lenqdyAfk7lPI0FAAAA4EqMEQAAAOAqzNgoggybXf6/bMm2zulvVju95mksAAAAAFcisQEAAABXIbFRBMXu2SNzQkK2dVJj/7PHBoMWAAAAAJI8vLwkSQYPPwEAAMBFSGwUQdZLl3J9jsHm4QAAAAAkWUKKSeLhJwAAALgOiY0iyBxcLNfnsHk4AAAAkDO9e/dWSEiI+vbt6+pQCoRXsWKSWK4WAAAArkNiowg67lNcMWY/GVkcNySlmJz3lbczYwMAAADIkXHjxumjjz5ydRgFxpKe2GDGBgAAAFyExEYRdCneqnURTSQpQ3Ij/XWUVzFJkoe3tyRmbAAAAAA51bZtWwUGBro6jFwJighRqikHw0Ozpzz9/SXx8BMAAABch8RGERQS6K2/AypoRck2ijX7OR2LNftpRck2spnMkiSv0BBJDFoAAABQNPz444/q3r27SpcuLZPJpJUrV2aoM2vWLFWsWFE+Pj669dZb9dtvvxV+oPmsVJWyOt2jl4Ife1qhTz6npCHjZP/nWLGHHlHQ8FGSJEtggDy8LJJ4+AkAAACu43n1KrjR1KoUKn8v6e+ACtrvX04VE06r/+n1kqS55boqydNXbS//KUnyCg1V0ukzTDMHAABAkRAfH6/69etr+PDhuvPOOzMc/+yzzzR+/Hi9++67uvXWWzVjxgx16tRJ+/btU/HixXN9veTkZCUnJztex8TESJKsVqushfhwkdVqlW9YgCo3qimLxaLQmCT9tihQodZYFQ/zl4clWDGSzH6+MsxpD0GlJiUVaoxIk/6Z89m7B/rLfdBX7oX+ch/0lXtxdX/l5rokNoogs4dJTatK63dLhslDh/3LKN7sI39bkoJtCUry9FWop02S5BUWKkky2BgQAAAARUDnzp3VuXPnLI9Pnz5d9913n4YNGyZJevfdd/XNN99o7ty5mjBhQq6v98orr2jKlCkZyteuXSs/P79MzihYkZGRkiTDkGIsQQq1xmrTt+vkFeynIEmxKVZdOH5cfpIO/f23/ly1qtBjRJr0voJ7oL/cB33lXugv90FfuRdX9VdCQkKO65LYKKIqhUtPDL5Zc77arejLSbrs6S9/W5LKelk1fEgTmV5YLLvSZmxIbAwIAAAApKSkaNu2bZo4caKjzMPDQ+3bt9fmzZvz1ObEiRM1fvx4x+uYmBiVK1dOHTt2VFBQ0DXHnFNWq1WRkZHq0KGDLJa0paY++eY3KUEqYbWpZFi4TkoqFlJMfiVKKEp/qWxYmKp06VJoMSJNZn2F6xf95T7oK/dCf7kP+sq9uLq/0mcv5wSJjSKsad2Sal6/rP48EKWtU35Q6eRoDbq1uCpVC9Gv/6yXa/tnWrydGRsAAAAo4s6fPy+bzaYSJUo4lZcoUUJ79+51vG7fvr127typ+Ph4lS1bVp9//rmaNWuWaZve3t7y9vbOUG6xWFwymLRYLLJfuqT4o8dUNWqfJMm2Y6tO7tgqSYrff0Dx+w9IkqJ/3qRK9w6Wd0REoccJ131HkDf0l/ugr9wL/eU+6Cv34sp70ZwisVHEmT1MalC9uDb5B0tx0qU//tDvq79xHD+7eo0kKelclKtCBAAAANzKunXrXB1CniVHndcfD/9PhtUqj6tVtttljYklsQEAAIBCd9V7VRQRwWlLTqX89YesFy9mOJxw+IiiN/9S2FEBAAAA143w8HCZzWadPXvWqfzs2bMqWbKki6LKX6mxsTLY3BMAAADXORIbkCR5hoVJkoxs6hz6cK4Mm61wAgIAAACuM15eXmrUqJHWr1/vKLPb7Vq/fn2WS00BAAAAyH8sRQVJUqhnWsLClE2dlPPRitm9R8H16hZOUAAAAEAhi4uL04EDBxyvDx8+rB07dig0NFTly5fX+PHjNWTIEDVu3Fi33HKLZsyYofj4eA0bNsyFUeefi7FJrg4BAAAAuCoSG5AkBfrlbGOWlEyWqQIAAABuFFu3btVtt93meD1+/HhJ0pAhQzR//nz1799fUVFReu6553TmzBk1aNBA3377bYYNxd1VfGKqq0MAAAAArorEBiRJAdb4HNXzCgkp4EgAAAAA12nbtq0MI7sFWqUxY8ZozJgxhRQRAAAAgP9ijw2kbQr+3aps99eQJK/wMAXVrlUoMQEAAAAAAAAAkBkSG0WcYbPp0AdzJWW/v4YkVR45XCazueCDAgAAAOAWLEGBrg4BAAAARRCJjSIuZvcepURHX72iyaSwZk0LPiAAAAAALmPyD1CqKfthYuo/j0R5BgfLOyKiMMICAAAAnLDHRhGX483ADUOG3S6TB7kwAAAA4EZlDg3V++V7ydeWnGUdL3uKBp2KlGy2QowMAAAA+BeJjSLOXKxYjuvarVaZvb0LLhgAAAAALhdjCVCMJSDL48HWOEmSLSWlsEICAAAAnPD4fRF3wqeEYsx+WW4cfmW5YbUWRkgAAAAAXCTI30sWz6ssRWVK23fPnpKisxfiCyMsAAAAwAmJjSLuYlyK1kU0kaQMyY301/b0/6aQ2AAAAABuZBHFfPXuhHYaP/DmLOukJzZMkmJiEgspMgAAAOBfLEVVxIUG+ejvgApaUbKN2kdtUZAtwXEs1tNP68KbqNvZjfIyUmW3MtUcAAAAKAxWq1XWQpwxnX4tq9WqkACLSoX5Zlk3PbEhSdakxEKNE859hesf/eU+6Cv3Qn+5D/rKvbi6v3JzXRIbRVztymEKC/bR36qg/f7lVC7xnPxtiYo3++q4b3EZJg/Zz/8qpaYyYwMAAAAoILNmzdKsWbNk+2dD7rVr18rPz6/Q44iMjJQknY/Nuo7N9O/E/99+3qj9+7JOgqDgpPcV3AP95T7oK/dCf7kP+sq9uKq/EhISrl7pHyQ2ijizh0mjetXTKwu2yDB56JhfyQx1fPx8pJgkZmwAAAAABWT06NEaPXq0YmJiFBwcrI4dOyooKKjQrm+1WhUZGakOHTrIYrHo4MnLWrl9Y+aVTSalmjzkadjV5OabVb1epUKLExn7Ctc3+st90Ffuhf5yH/SVe3F1f8XExOS4LokNqPlNpTVxSBO9v/JPRV9OcpQH+lnUvVVleS/zUXIMe2wAAAAAhcVisbhkMJl+XU/P7IeKqSazPA27zIadX1K4iKu+I8gb+st90Ffuhf5yH/SVe3HlvWhOsXk4JKUlN+Y801HtGpdzlMUmWLVozT6dvpQsSbKnMGMDAAAAwL/7bBipPPwEAACAwkdiAw6//nVa67cez1CebKR9TXb9faawQwIAAABwHbKlbyDORqAAAABwARIbkCTZ7IbeX/lnpsdS/9kcMHLTIdnsRmGGBQAAAMAFgvy9ZPHMeriYPmPDj8WNAQAA4ALchkKStPtQtNP+GldKfxorIS5Ruw9Fq17V8MIMDQAAAEAhKx7ip3cntFNM/L/L0S5eu0+/7jqjjrdWUInEYKWejFGQN8/KAQAAoPCR2IAk6UJM5kkN6d+nsTwNW7b1AAAAANw4iof4qXiIn+N1varh+nXXGcUmpMjH30dxkuwpLEUFAACAwsfjNZAkhQb5ZHnsysRGdvUAAAAA3JjOXUyQxWySJB04ftGxD9/pM5d04MQlnbuY4MrwAAAAUMQwYwOSpNqVwxQW7JPpclTpiY1gbw/VrhxW2KEBAAAAcKFzFxP0wKvrZU21S5KiLiVp36lYVZa08Os/9dePCbJ4eujdCe2cZngAAAAABYUZG5AkmT1MGtWrXqbHbB5piY2mNcNl9jAVZlgAAAAAXCwmPsWR1EiX/vCT2bBJkqypdqf9OAAAAICCRGIDDs1vKq2JQ5ooLNh5uSlPb29JUrkwlqECAAAA4LxcLQAAAFDYSGxco969eyskJER9+/Z1dSj5ovlNpTXnmY7q2qKiJKlWxRC1b15ZkmS3sjEgAAAAAMlGYgMAAAAuRGLjGo0bN04fffSRq8PIV2YPk5rVKy1JuhSXIrOXlyTJnsLUcgAAAADM2AAAAIBrkdi4Rm3btlVgYKCrw8h35Uumvacz0fGym9P2mGfGBgAAAAAp4x4bAAAAQGEq0omNH3/8Ud27d1fp0qVlMpm0cuXKDHVmzZqlihUrysfHR7feeqt+++23wg/UBYoFeCvA1yLDkPYcj5Ek2ZKZsQEAAABASjWlDSU97SQ2AAAAUPg8XR2AK8XHx6t+/foaPny47rzzzgzHP/vsM40fP17vvvuubr31Vs2YMUOdOnXSvn37VLx48VxfLzk5WcnJyY7XMTFpCQOr1SprIc6GSL9Wdtf85a8zSkpJlST9ui9aHSX9uvO4zm0/rqZ1SxZGmPhHTvoL1wf6yr3QX+6DvnIv9Jf7cHVf8R1xb+yxAQAAAFcq0omNzp07q3Pnzlkenz59uu677z4NGzZMkvTuu+/qm2++0dy5czVhwoRcX++VV17RlClTMpSvXbtWfn5+uW7vWkVGRmZafvi8tH73v6/Tp5nbU1I09ZPf1a62VCm8MCLElbLqL1x/6Cv3Qn+5D/rKvdBf7sNVfZWQkOCS6yL3gvy9ZPH0kDXVriBrnHxtyfKxpz2wFZiaoBJJ0fL09JBX1Ckle1vlHRHh4ogBAABwoyvSiY3spKSkaNu2bZo4caKjzMPDQ+3bt9fmzZvz1ObEiRM1fvx4x+uYmBiVK1dOHTt2VFBQ0DXHnFNWq1WRkZHq0KGDLBaL0zGb3dADr22QlPRvmcc/6+f+M818x0kfPTD4Npk9TIUWc1GWXX/h+kJfuRf6y33QV+6F/nIfru6r9NnLuP4VD/HTuxPa6eLx0zo/5Wkp9d/ZNtUSTqhawglJ0vHJX+mExaJG78wkuQEAAIACRWIjC+fPn5fNZlOJEiWcykuUKKG9e/c6Xrdv3147d+5UfHy8ypYtq88//1zNmjXLtE1vb295e3tnKLdYLC4ZTGZ23b0Hziv6cpJTWapjmrldkhR9OUn7j8eoXlWmbRQmV31PkHv0lXuhv9wHfeVe6C/34cp7UWTteluuNiTAIi9vm86nZh+TYbUq8cJFeRQrlt8h4h+uXkYOuUN/uQ/6yr3QX+6DvnIvru6v3FyXxMY1WrdunatDyFcXYpIylKVmsn5uZvUAAAAA5M2sWbM0a9Ys2Wxp99zX23K1kpRyKlqlc9LGdz/La++e/AsKmWLJP/dCf7kP+sq90F/ug75yL+6wXC2JjSyEh4fLbDbr7NmzTuVnz55VyZI37ubZoUE+GcpSTR6SnBMbmdUDAAAAkDejR4/W6NGjFRMTo+Dg4Otqudp0+375U5e//eaqbdWq20A1mtbL7xDxD1cvI4fcob/cB33lXugv90FfuRdX91dulqslsZEFLy8vNWrUSOvXr1evXr0kSXa7XevXr9eYMWNcG1wBql05TGHBPk7LUdn+mbFh/iexEV7MV7Urh7kkPgAAAKAouJ6Wq01nNptz1IbZbOYXF4WAJf/cC/3lPugr90J/uQ/6yr24w3K1HgUYx3UvLi5OO3bs0I4dOyRJhw8f1o4dO3Ts2DFJ0vjx4/XBBx9owYIF2rNnjx588EHFx8dr2LBhLoy6YJk9TBrVy/npKts/XxNfW7LKJ5zRyO612TgcAAAAAAAAAOASRXrGxtatW3Xbbbc5Xo8fP16SNGTIEM2fP1/9+/dXVFSUnnvuOZ05c0YNGjTQt99+m2FD8RtN85tKa+KQJnp/5Z8KO7lPHaN+lST52ZM18NRaeb21TdH3DVdYs6YujhQAAADA9ebshXiFXUxQ8ZDC3yMEAAAARUORTmy0bdtWhmFkW2fMmDE39NJTWWl+U2lViz2qv6f+oP9+QinR0dr76jTVnPA4yQ0AAAAATj5ZvVcXforWuxPakdwAAABAgSjSS1Eha4bNpiNz5kmSslp06tCHc2XYbFkcBQAAAHAj8QgIUKop+yFkqkzyT02Qb2KMYuJTCikyAAAAFDUkNpCpmN17lBIdnW2dlPPRitm9p5AiAgAAAOBK5tAwvV++l5aUvF2pWQwlPWWo35kNGnVspWwXsh9PAAAAAHlFYgOZSrpwMV/rAQAAAHBvQf5eSvQNUrynrzxlz7aup2GXPS6ukCIDAABAUUNiA5k6lZizr0ZO6wEAAABwb8VD/PTuhHYa3Lmmq0MBAABAEcdvpZGpmPByijH7Zdg4/Ep2mRQbxYwNAAAAoKgoHuKnEqH+rg4DAAAARRyJDWQqtJif1kU0kaQskxsmGTIvnafozb8UXmAAAAAAAAAAgCKNxAYyVbtymKLL1NCKEq1lyJRpHZPSkh6HPpwrw2Yr1PgAAAAAXN9Sz5xWclSUq8MAAADADYjEBjJl9jBpVK96SjL7yCObBalMklLORytm957CCw4AAACAy/j7WnJUL2bBB9r24FiSGwAAAMh3JDaQpeY3ldbdzUvlqG7SBfbaAAAAAIqC0CCfHNc1rFZZY2ILMBoAAAAURZ6uDgCS1WqV1Wot1Otd+d/s+IQWU3IO2jweZyi0EN9DUZKb/oJr0Vfuhf5yH/SVe6G/3Ier+4rviPuyBAXKZLHIoA8BAADgIiQ2XGDWrFmaNWuWbP/sS7F27Vr5+fkVehyRkZFXrXPwrF21zH4KtCVkutOGISnW0097Tkbr5KpV+R4j/pWT/sL1gb5yL/SX+6Cv3Av95T5c1VcJCQkuuS6unXdEhBq9M1OXd+/R/ulvujocAAAAFEEkNlxg9OjRGj16tGJiYhQcHKyOHTsqKCio0K5vtVoVGRmpDh06yGLJfn3cvw5G65Ntx9X7zA8yJKfkRvrOG+vCm2hw62aqWyWsoEIu0nLTX3At+sq90F/ug75yL/SX+3B1X8XExBT6NZF/vCMi5FeWJaYAAADgGiQ2rgMWi8Ulg8mcXPem6iUUXaaGVkhqH7VFQbZ/n6xLNln0W7Haulimum6qXkJmj8zmdCC/uOp7gtyjr9wL/eU+6Cv3Qn+5D1feiwIAAABAXrB5OLJl9jBpVK96+juggt6peKd+DKkv2z9fGx/DqtYXd2rE/s916ddfXRwpAAAAAAAAAKAoILGBq2p+U2lNHNJENxtn1eriTnnI7lwh5pL2vjpN0Zt/cU2AAAAAAAAAAIAig6WokCPN6pSQ5fLvSsmmzqEP5yr0liYymc2FFhcAAABwI7JarbJarYV6vSv/mxMXrCalmszyNGxZ1kk1mXXBapJ3Ib6XG11e+gquQ3+5D/rKvdBf7oO+ci+u7q/cXJfEBnIkZvcepURHZ1sn5Xy0YnbvUXC9uoUUFQAAAHBjmDVrlmbNmiWbLS1JsHbtWvn5+RV6HJGRkTmuez5W+q58T/nakiVJYdbL6nH2ZyWZPPVpmY6STEo0e+v2rX8ofN8fBRRx0ZWbvoLr0V/ug75yL/SX+6Cv3Iur+ishIeHqlf5BYgM5knLxYr7WAwAAAPCv0aNHa/To0YqJiVFwcLA6duyooKCgQru+1WpVZGSkOnTokOON3Q+evKyV2zcqxhIgSYr2CpYhycdIVaynvxI8fSVJLVq2UJUywQUVepGTl76C69Bf7oO+ci/0l/ugr9yLq/srJiYmx3VJbCBHvEJC8rUeAAAAgKxZLBaXDCZzc11PT+fhZKqHpy5ZAhVijVV4ymUd+yex4enpyS8yCoCrviPIG/rLfdBX7oX+ch/0lXtx5b1oTpHYQI4E1a4lr7CwbJej8goPU1DtWoUYFQAAAIDrQZA1Tr62ZMWafRVijVWlhJNK9kgbmFqPHVWyt1XeEREujhIAAAA3ChIbyBGT2azK9w3X3lenyZBkyqRO5ZHD2TgcAAAAKGKCrHEadWylPA27o6zZpV1qdmmXJOnCa9/oosWiRu/MJLkBAACAfOHh6gDgPsKaNZUGjFC8xd+pPN7iJw0YkXYcAAAAQJHia0t2SmpkxrBaZY2JLaSIAAAAcKMjsYEc2/THKb261apZ5XtrUemOumxOS3B8G9pEr261atMfp1wcIQAAAAAAAADgRkdiAzlisxt6f+WfkiTD5KFjfiV13K+EJCnCelmS9MEXf8lmN1wWIwAAAIDCE+TvJYsnQ0oAAAAUPu5CkSO7D0Ur+nKSU9k5SzFJUpX4EyqfcEbRF+O1+1DWm4sDAAAAuHEUD/HTuxPa6dFBjVwdCgAAAIoYNg9HjlyIcU5qVI87qqb/bAZYJvm8Bp5aqxizny7+6iVV7eqKEAEAAAAUsuIhfvIrEagLrg4EAAAARQozNpAjoUE+jj9Xjzuq3md+kK892alOoC1B5iVzFb35l8IODwAAAAAAAABQRJDYQI7UrhymsGAfmQy72kdtkSSZ/lMn/fWhD+fKsNkKNT4AAAAAAAAAQNFAYgM5YvYwaVSveiqXeE5BtoQMSY0rpZyPVszuPYUWGwAAAADXsQQFymSxZFvHZLHIEhRYSBEBAADgRsceG8ix5jeVltGilPT51eumXLxY8AEBAAAAcDnviAg1ememrDGxmrlku+IOHlaXqM3yCgtTracnSEpLfnhHRLg4UgAAANwoSGxcB6xWq6xWa6Fe78r/5kbNOuW1NweJDY/AwEJ9Tzeya+kvFC76yr3QX+6DvnIv9Jf7cHVf8R25sXhHRKT9VLiov04nSZKsly/Lv2IFmcxmF0cHAACAGw2JDReYNWuWZs2aJds/+1CsXbtWfn5+hR5HZGRk7k+y2xXi5yePhMyXozIk2f399PORw9Kxo9caIq6Qp/6CS9BX7oX+ch/0lXuhv9yHq/oqISHBJddFwSoe4qdYTz8ZJg8pNVUpFy/JOzzM1WEBAADgBkNiwwVGjx6t0aNHKyYmRsHBwerYsaOCgoIK7fpWq1WRkZHq0KGDLFdZCzczF8KL68Dr02Uo8w3Eazz4gEKb3pIfoULX3l8oPPSVe6G/3Ad95V7oL/fh6r6KiYkp9Gui4Jy7mKCY+BQZkgyThxJ8AuSfGKODuw7Jq4pZQf5eKh5S+A9zAQAA4MZEYuM6YLFYXDKYzOt1S7RqIU9Ps3a++a68E2Md5V6hoao8aoTCmjXNzzDxD1d9T5B79JV7ob/cB33lXugv9+HKe1HcGM5dTNADr66XNdXuKDsvX/krRgsW/qzdgadk8fTQuxPakdwAAABAvvBwdQBwT2HNmurskCe0qHRHpVq8JUk1n36SpAYAAABQxMTEpzglNSTpsmeAJCnYGidJsqbaFROfUuixAQAA4MZEYgN5ViIiQMf8SirWL1SSlHwuysURAQAAALgeXLb8k9hIjXNxJAAAALgRkdhAnkUUS5tGHmVK+2/i6bOuDAcAAADAdeLfGRvxLo4EAAAANyISG8iTTX+c0rSFWyX9m9j4dvU2bfrjlCvDAgAAAOBCQdY4lUiKlodhkySFWi+rRFK0SiRFy3rsqJKjmOUNAACAa8fm4ci1TX+c0isLtjhep08z94m/pFcWbNHEIU3U/KbSrgoPAAAAgAsEWeM06thKeRr/7rcRnJqgYSe+kSRdeO0bXbRY1OidmfKOiMi2reSoKFljYrM8bgkKvGobAAAAuHGR2ECu2OyG3l/5p1PZJc9ASVIxa9rA44Mv/tKtdUvJ7GHKVduGzaaY3XuUcvGivEJCFFS7lkxmc/4EDgAAAKBA+dqSnZIamTGsVlljYrNNSiRHRWnbg2NlWK1Z1jHlMEECAACAGxOJDeTK7kPRir6c5FR2KX1jQGucasccVFyCv3YdiNJN1YvnuN3ozb/o0AdzlRId7SjzCgtT5fuGK6xZ0/wJHgAAAMB1zxoTm21SQ8pZggQAAAA3LhIbyJULMUkZykolnZchySxDPc5tlCTFvPCboh+6L0dJiejNv2jvq9MylKdER2vvq9NUc8LjJDcAAABQpFitVlmv8sv9/L7elf/NDT9vD1k8c759Y2pqarbXSU1NzZd2blTX0lcofPSX+6Cv3Av95T7oK/fi6v7KzXVJbCBXQoN8nF5XjzuqXmd/zFDPFHMpR0kJw2bToQ/mZnvNQx/OVegtTViWCgAAADesWbNmadasWbLZ0jbdXrt2rfz8/Ao9jsjIyDyd1+dmyTgn6cTV6/7888+y7d2T5XHz+WiF5OCaV2vnRpfXvoJr0F/ug75yL/SX+6Cv3Iur+ishISHHdUlsIFdqVw5TWLCPoi8nyWTY1T4qbRPxrHbTuFpSImb3HqflpzKTcj5aMbv3KLhe3WsJHQAAALhujR49WqNHj1ZMTIyCg4PVsWNHBQUFFdr1rVarIiMj1aFDB1ksljy1cWLnHp1a981V69Wp31hl69fK8nj8ocPa9eXV22nZsqX8K1fKVYw3gvzoKxQe+st90Ffuhf5yH/SVe3F1f8XExOS4LokN5IrZw6RRverplQVbVC7xnIJs2WfRrpaUSLl4MUfXzWk9AAAA4EZgsVhcMpi8lusmpRg5rpfdNTw9czZM9fT0LNK/IHHVdwR5Q3+5D/rKvdBf7oO+ci+uvBfNqZwvhAr8o/lNpTVxSBOV9M7Z2rfZJSW8QnIyyTzn9QAAAAAAAAAANzYSG8iT5jeV1ujhrXNUN7ukRFDtWvIKC8v+/PAwBdXOeqo6AAAAANfzCAhQqin7IWaqyUMeAQGFFBEAAABuVCxFhTwLqVNbXmFhSo6OznKPjaslJUxmsyrfN1x7X52WZZ3KI4ezcTgAAABwnTOHhun98r3ka0v+p8TQoBNr5aVULSvZRjGeAUo0e2tKaPYPNlmCAmWyWGRYrVnWMVkssgQF5mP0AAAAcCckNpBnJrNZKR16SYvnyJDzBuLpq+umtO911aREWLOmqjnhcf395kzZE5Mc5V7hYao8crjCmjXN79ABAAAAFIAYS4BiLP/OyLjoFagSKRdlN5l11if7hEY674gINXpnpqwxsdr9wsuyXrwon9KlVeOx/znqWIIC5R0Rke/xAwAAwD2Q2ECe2eyGPthvVljJNmoftcVpI/FYTz+tC2+iCwc81dRuyOyR1ZyONGHNmipi+w6dXRMpSaox4XGF3dKEmRoAAACAG7tkSUtsFLPG5uo874gIeUdEyJ7y7+yPgCqV8z9AAAAAuCUSG8iz3YeiFX05SdEBFbTfv5xGHvtSYdYY/RBSX7+E1pNh8pAuJWr3oWjVqxp+1fZsCf8mRvwrViSpAQAAALi5S//M3ihmjcv1uYbNJlt82hjBdsXMbgAAAIDNw5FnF2L+HVwYJg+d807bJDzVbElLamRSLzup8f8mNuzJDFwAAAAAdxLk7yWLp/MQ86IlbR+M9BkbFk8PBfl75ag95/FBcjY1AQAAUNQwYwN5Fhrk4/T6kqfzoCWrelmxxcf/+2eeyAIAAADcSvEQP707oZ1i4lMkSXuOXNDahackSTWD7fq//7VRkL+Xiof45ai91Ph/Z3nYkpJkGIZMpuyXuAUAAEDRQGIDeVa7cpjCgn0UfTktCZE+zTz4imnm4cV8VbtyzjYJvPKJLFsSiQ0AAADA3RQP8VPxED8lR0UpxSNGnnab/p+9e49vqr7/B/7KtW3aJk1TCpSbFBAobfHGraJzU/E7dep06nROnA6mY5vf+Z1+Ye7rbk6cOvfzwmRcVHbBiZch3gbINuVOGSiUci+XlhbapmnTNm1zcvn90SYkaS4n95zk9Xw89phNzuWTfJLS83mf9/sNAI6WZgztNULWJ0NXm7jm37au8zc+weGAw2qFIisrnsMnIiIiIolgYCMFCIIAQRASej7P/4/GA18rwzN/2QOgvzEg4F0/9/4bJ8Nht2HgeiYom0fGhrW7O6HvSSqL5XxRfHGupIXzJR2cK2nhfElHsueKn5H01dfSgv889EM4BQHfGHjMabNh3/885t5GplLh0ldeChrcsHV6Z4I7+voY2CAiIiIiAAxsJMWSJUuwZMkS2O39q/0bNmyARiMuHTuWNm7cGJPjXF0GbD8GtAsDGRu2LuSqnZg5Xoa203vw0WlxxzGYzXAllu/duRN9xtaYjC9dxGq+KP44V9LC+ZIOzpW0cL6kI1lzZbFYQm9EkiSYO+EMEbhyCgI6ag9CM7IzYPaGV8YG+svVqrTamI6ViIiIiKSJgY0kWLBgARYsWACz2QydToc5c+ZAm8A/0AVBwMaNG3HttddCpVLF5Jjfsztw988+hgMyqJx2LPvRTOQUiStBBQAOwYbdr/7J/XP5xIkYet2cmIxN6uIxXxQfnCtp4XxJB+dKWjhf0pHsuTKbzQk/J6WWo8+/ACBw9oatq8vrZ0cfy9USERERUT8GNlKASqVKysVkLM+rUgH6Ag3MCg0K7N1o/9e/4awoh7ZsMmQKRcj9Bd879qwCF0N8JOtzQuHjXEkL50s6OFfSwvmSjmT+LUoE9GdvCObOkIENew8DG0RERETUj4ENipnJPfXIs/cAAOrffAv1b74FRV4eSr52A0bdflvQAIdnfw2gv34uERERERFlLt9rBHsvAxtERERE1E+e7AFQejBu34FZNR9BAYfX4/auLtS/8SZ2zb0fxu07Au5v6/bO2OBFCxERERFRZrN1+mRs9PLmJyIiIiLqx8AGRc1pt6Nu+asA4G7+7cvW2YVDTz8bMLhh970bi2nmREREREQZbVCPDd78REREREQDGNigqJlrD8JqNAYManiqW/EqnHb7oMd9MzbYGJCIiIiIKLMNKkXFawQiIiIiGsDABkXNajKJ37bVCHPtwUGPD7poYcYGEREREZEkqbT5kMWgObyts7P/eDotAF4jEBEREdF5bB5OUVPr9WFt7y8Q4i5FJZcDDgd7bBARERERSVTWkCG49JWXIJg7sW3THuR++EZEx7F19V8jqIuKIHSYWYqKiIiIiNyYsUFR05ZNhtpgEL29v0CIzWLxes7BxoBERERERJKVNWQI8saVImfCRNhkwS87ZSoVVNr8QY+7emxkFfVfa/DmJyIiIiJyYcYGRU2mUKB03v049PSzcCJwA3EAUBcZoC2bPOhxV8ZGVpEBVqMR9t6e+AyWiIiIiIgSRjtiGJ4ZfQvG6pVYeO80NP/7UzSt+wC6inJc8J25APpLV2UNGeK1n0MQ4Ojrv9kpq6gIAAMbRERERHQeMzYoJgyzZmLEj/4bPXJ10O1Kv3s/ZArFoMddPTbUhYUAeNFCRERERJQOtHlqmFV5OCXTIW9cKQqnXQYA6G1uRt64UuSNKx0U1AA8evDJZO5rBGZ1ExEREZELMzYoZkZddTl+9GErZrXtx5etx2Hv7nI/pzYYUDrvfhhmzfS7r617oBSVwXXRwsAGEREREZHUaXP7b3wyd1vR29zsfrzvXDM69h+AQpPjfswzc8PW2X8todBooMjp34Y3PxERERGRCwMbFDMKhRx5udnYJpuKu/7nRyhoOY0Dv/oNYLNh2PXXQZmXB6fd7jdjw1WKytWrw867sYiIiIiIJM8V2Mjr68Se7/8ITkFwP1fzsye8tpWpVLj0lZeQNWSIu7+GKj8PipxsAAxsEBEREdF5DGxQTBXkq9FpsaKjW0C+xQKZTAYngNN/Xg0gcOaGzaPHBgA4+voCBkGIiIiIiCi1NZssMHdbAQBZKgVyevu8ghr+OAUBgrmzP7AxcH2gyM2DPKs/sMGsbiIiIiJyYWCDYkqXl4X6c13o2LULXWteHfS81WjEoaefxaSFj3oFN3xLUQGAvc8KpUdqOhERERERpb5mkwUPPr0Jgs0R9r6WhgYAQNfx4wAAmVwGa7sJACB0dQXcj4iIiIgyCwMbFFO6XDVkTgds77+FYLkWdSteReH0ae6MDLtlILBRoAdkMsDphKOvF2Bgg4iIiIgykCAIEEJkOMT6fJ7/H422DktEQQ0AOPr8C14/dx09hq6jxwAAPafr0dXYhKwhRVGPUcpiOVcUf5wv6eBcSQvnSzo4V9KS7PkK57wMbFDMbNvXiP8casaonmZk9XQG3dbaaoS59iB0FeVw2u3uwIYyLxeK7GzYe3pYQ5eIiIiIMsaSJUuwZMkS2O12AMCGDRug0WgSPo6NGzdGfYzW4JcCUfn3xx/DPlC+NtPFYq4ocThf0sG5khbOl3RwrqQlWfNlGVgjFoOBDYqJbfsasXhVNQAg194jah+rqT+l3N5zfnuFRgN5dlZ/YKOHgQ0iIiIiygwLFizAggULYDabodPpMGfOHGi12oSdXxAEbNy4Eddeey1UKlVUxzp+pgNr926N0ci8zZ49G7mlY+NybKmI5VxR/HG+pINzJS2cL+ngXElLsufLbDaL3paBDYqa3eHEsrX73T93K8SVj1Lr9QAAobO/Vq5MoUDnocOQZ2UBYHNAIiIiIspcKpUqKReTsTivUhm/y0yFQsFFkQHJ+oxQZDhf0sG5khbOl3RwrqQlmX+LiiWpwIbD4cCnn36KzZs349SpU7BYLBgyZAguvvhiXHPNNRg1alSyh5iRauuMMHacD0LU5xTDrNAg326BLMA+6iIDtGWTYdy+A8dfWQYAcNrtqPnZz8/33WBgg4iIiIiC4PVB5nHabMkeAhERERGlAHmyByBGT08PnnzySYwaNQrXX389Pv74Y7S3t0OhUODYsWP4+c9/jrFjx+L666/Hjh07kj3cjNNm9g5AOGVyfDJkWv9/B9in9Lv3o21XNQ49/SyEjg7v/QfqCrd/sS/mYyUiIiIi6eP1gfT0KLJgk0V/+emwWmMwGiIiIiKSOklkbFx44YWYNWsWli9fHrC+16lTp7B69Wp885vfxOOPP4558+YlYaSZqVCbPeixI3lj8PdhX8I1LdXQ2s83fVEXFqJ0/gMonD4Nu+c9FPS4zZ/8Exfce487g4OIiIiICOD1gRSZVXlYNvoW5Nj7AAAFghlfP7cZMrUaFU/9Gj2NjTj6/Ashj+Po64v3UImIiIhIAiQR2NiwYQMmT54cdJsxY8Zg0aJF+MlPfoLTp08naGQEAGWlBhh02V7lqID+4MbR3FEY1dOMW859Bo29F0VXXQllXh46ag7AajQGPa6tqwvm2oPQVZTHc/hEREREJDG8Pkht2lw1VEo5BJvD63GzKg9mVR60QhdUCi0gV8BptcJ84ADsVkHUsZmxQURERESARAIboS5aPKlUKowbNy6OoyFfCrkM82+pwOJV1YOec8rkyHb0QSO3A3ag8d21aHx3LRR5eaKObTWZYj1cIiIiIpI4Xh+ktmK9BksXXg1z9/kgxKIlW9BrtWPhTeOAF58EbOcDGSdf+5PoY8uUbDpKRERERBLpseFr8+bNuOeeezBr1iycOXMGAPDnP/8ZW7ZsSfLIMldVZQkWzZ0Gg867LNVlzibcevZTQPC+A8ve1SXquGq9PmZjJCIiIqL0xOuD1FOs12D8yAL3/4YZcgEAaluPV1BDFKUS6qIiAIAiZ3AZXCIiIiLKPJILbLzzzju47rrrkJOTg71796JvoMZqR0cHnnrqqSSPLrNVVZZg5c/m4OrLRgEALp1YhOvb90R8PHlONrRl4u/GIyIiIqLMw+sDaSjWawAAbeYIemTYbFDk5AAAHL29ITYmIiIiokwgiVJUnp588kksXboU9957L/72t7+5H7/88svx5JNPJnFkkRMEAYIQ5l1LUZ7P8/9jrXxcITbtrkfu2VMh+2gEkzdhAmwOB+BwhN44jcV7vih2OFfSwvmSDs6VtHC+pCPZcxWr86bj9UE6Ktb3ByZM5l6IK0rrTZGVBQCwM7BBRERERJBgYOPw4cO48sorBz2u0+nQ3t6e+AFFYMmSJViyZAnsdjuA/uaHGo0m4ePYuHFjXI7bbO7/f/PZ5oj2d6hVkFsFNHd1oe6jj2I4MmmL13xR7HGupIXzJR2cK2nhfElHsubKYrHE5DjpcH2QCYa4MzZ6MSqC/WXq/t4a9t4IMj6IiIiIKO1ILrAxbNgwHDt2DBdccIHX41u2bEFpaWlyBhWmBQsWYMGCBTCbzdDpdJgzZw60Wm3Czi8IAjZu3Ihrr70WKlXsm++Zu61Y9/knaHPmhL2vUqtFye234vTK1zGssBAXXn99zMcnNfGeL4odzpW0cL6kg3MlLZwv6Uj2XJnN5pgcJx2uDzLB0ML+wIYpklJUOJ+xwVJURERERARIMLAxb948PPzww3j11Vchk8nQ2NiI7du34yc/+Qn+7//+L9nDi4hKpUrKxWS8zluoU0KTrUS9sxgKvR52k0n0vjazGQ5zJwDAabVyQcRDsj4nFD7OlbRwvqSDcyUtnC/pSObforGQjtcH6WjIQCmqts7IAhNytRoAS1ERERERUT/JBTYWLlwIh8OBq6++GhaLBVdeeSWysrLwk5/8BD/84Q+TPTwCIJPJMLRQgxONNpy+ZA5GbHozrP3tfVYAQG9zCzr210BbNhkyhSIeQyUiIiIiieP1gTS4moebuyLL2HBY+3uy9DSdRdfxOvfjKm0+soYMiX6ARERERCQpkgtsyGQyPP7443j00Udx7NgxdHV1oaysDHl5kbSgo3jYtq8RZ1q6AAB/PpWFC4deiVvObYYcTlH7N3+yCQDQd/Ysan72c6gNBpTOux+GWTPjNmYiIiIikiZeH6S+ZpMF5q4+KJVyWIQsQKkEbLawjtG+dy8AoOWf/0LLP//lflymUuHSV15icIOIiIgow0gusOGiVqtRVlaW7GGQj237GrF4VbXXY0fyL8B7AG459xlkIo5h92kkaTUacejpZzFp4aMMbhARERGRX7w+SE3NJgsefHoTBJsDAGBW5eEPI25Cjr0PubYe6AUzvmL8DxQib4Ly5RQECOZOBjaIiIiIMowkAhu33nqr6G3ffffdOI6EgrE7nFi2dr/f5w7nX4C/y2T4assO5NgjSz+vW/EqCqdPY1kqIiIiogzH6wPpMHdb3UEN92OqPJhV5zNqjuaNxs++WY5RQ/O9trM0NODo8y8kZJxEREREJC2SCGzodLpkD4FEqK0zwtgRuJnfkbwxOJo7Cv83vgOOrf+CravL/ZxSq4XNbA56fGurEebag9BVlMdszEREREQkPbw+SC9mVR5Uo8cgb2RBsodCRERERBIhicDGa6+9luwhkAht5sBBDRenTA7LzGtw5fe+DXPtQVhNJqj1evQZjTj6+xdD7m81mWIxVCIiIiKSMF4fEBERERFlNkkENkgaCrXZoreTKRRemRcd+2tE7avW6yMaGxERERERERERERGlB0kGNt5++22sWbMGp0+fhtVq9Xpuz549SRoVlZUaYNBlBy1HVVSQg7JSw6DHtWWToTYYYDUaA+6rLjJAWzY5JmMlIiIiovTB6wMiIiIioswiT/YAwvXiiy/iO9/5DoYOHYq9e/di+vTpMBgMqKurw1e/+tVkDy+jKeQyzL+lIug2D3xtChRy2aDHZQoFSufdH3Tf0u/ez8bhREREROSF1wdERERERJlHcoGNP/zhD1i2bBleeuklqNVqPPbYY9i4cSN+9KMfoaOjI9nDy3hVlSVYNHcaDDr/ZalWrKvBtn2Nfp8zzJqJSQsfhdrgndGhLjJg0sJHYZg1M+bjJSIiIiJp4/VB+lJp8yFTqYJuI1OpoNLmJ2hERERERJQqJFeK6vTp06iqqgIA5OTkoLOzEwDw7W9/GzNnzsTLL7+czOER+oMbDqcTv/3T7kHPGTt6sXhVNRbNnYaqypJBzxtmzUTh9Glo/PBjnFz5GlR6PS5b9gozNYiIiIjIL14fpDZtrhoqpRyCzRFwG6VCBpO5F80mC4r1GvfjWUOG4NJXXoJg7p/Tls82o3HtOmjLp2Ds/fcB6A9+ZA0ZEtfXQERERESpR3IZG8OGDUNbWxsAYPTo0dixYwcA4MSJE3A6nckcGg2wO5xY8V7wZuDL36uB3eF/vmQKBYZcORsAILS3w2m3x3yMRERERJQeeH2Q2or1GixdeDWeeGAGlAr/l582uxO/WrkTDz69Cc0mi9dzWUOGIG9cKfLGlUJ/8UUAAGtbm/sxBjWIiIiIMpPkMja+8pWvYN26dbj44ovxne98Bz/+8Y/x9ttvY/fu3bj11luTPTwCUFtnDNpAHABa23tQW2dExfgiv8+rdDoocnNh7+5GT2MTci8YE4+hEhEREZHE8fog9RXrNTB3W2GzB87aAADB5oC52+qVteFJM3o0AKD37Dk4rFbI1eqIxtPX0uLOAvGHWSBEREREqU9ygY1ly5bB4ej/g3jBggUwGAzYtm0bbrrpJnzve99L8ugIANrMwYMaYraTyWTQjByBzsNH0HOmkYENIiIiIvKL1weZoa+lBdYOM+TZ2XD09sK4YxdyRpwvbSs2GNHX0oL/PPRDOAUh4DYylQqXvvISgxtJwKATERERiSW5wIZcLodcfj6F+Zvf/Ca++c1vJnFE5KtQ679xeLjbZZeUoPPwEbRu3QqVNh/assnstUFEREREXnh9kP78BSOO/O73XtuIDUYI5s6gQQ0AcAoCBHMnF9ATjEEnIiIiCofkAhuvvfYa8vLycPvtt3s9/tZbb8FisWDu3LlJGhm5lJUaYNBlBy1HVVSQg7JSQ8Dnjdt3oG3nrv7/3rodxq3boTYYUDrvfhhmzYz5mImIiIhImnh9kP7EBiM6ag9CM7ITVpMJtu5uAIAyNxdqvd69naWhQdQ5LQ0Nks0OkGrWA4NOREREFA7JBTYWL16MP/7xj4MeLy4uxvz583nhkgIUchnm31KBxauqA24z7+ZyKOQyv88Zt+/AoaefHfS41WjEoaefxaSFjwYMbjjtdphrD8JqMkGt17uzPAI9TkRERETSxusDcjn6/AsxPZZMpUL5k7+EXKUKuJ2YIEEiAw3MeiAiIqJMIbnAxunTpzF27NhBj48ZMwanT59OwojIn6rKEiyaOw3L1u73ytwoKsjBvJvLUVVZ4nc/p92OuuWvBj123YpXUTh92qDAhHH7DtQtfxVWo9H9mNpgwJArZ6Plsy2DHmf2BxEREZH08fqA4sUpCKh5/Ak4bbaA24QKEogJNECpxORFjyF3zOiogw3MeiAiIqJMIbnARnFxMfbt24cLLrjA6/EvvvgCBkPg0kaUeFWVJZhRPhzvfXoMr31QiyH6bCz/6bUBMzUA9GdVeAQg/LG2GtFRcwAyudydgSGYzTj8zO8Gb2s04szf3/P7eKjsDyIiIiJKfbw+oHgKFtQAvEtgAf3ZFwDcGRqWhoaQgQbYbDj466eYSUFEREQUBskFNu666y786Ec/Qn5+Pq688koAwKeffoqHH36YTQJTkEIuw+ypI/DaB7UwmftCbm81mUQd9+BTv4Wj16OHhyxwsCSYQNkfRERERCQNvD6QBm2uGiqlHILNEXAblVIOba46gaOKDa8SWEolZAgdEPGHmRRERERE4kkusPHrX/8aJ0+exNVXXw2lsn/4DocD9957L5566qkkj478KSrIcV/EtJgsGGbIDbitZ2O/YLyCGgDgdEY0Nlf2R8HUyoj2JyIiIqLk4vWBNBTrNVi68GqYu60AgLc2HcG2fU24Ztoo3DC7FEB/8KNYr0nmMKNnsyGyKxMiIiIiCofkAhtqtRpvvvkmnnzySXz++efIyclBRUUFxowZk+yhUQByuQwlRbk4dbYTZ1q6ggY2tGWToTYYQpajiqXDz/wO43/wkLskFRuNExEREUkHrw+ko1ivcQcuJo4uxLZ9TbDaHBg/siC5A8tAloaGmDYtJyIiIko0yQU2XCZMmIAJEybAbrdj//790Gq10Iu8258Sr2RInjuwcemkoQG3kykUKJ13Pw49/WzCxmbr6nL32wDgtwF5uI3GPYMjKp0OACB0dDBQQkRERBQnvD6QlqGG/gDHOaMl5LYqbT5kKlXoXhVppK+lxd2nw5fNZoO8qyuq4x99/oWU6+khZp5lKpW7jwkRERFlNskFNv77v/8bFRUVeOCBB2C32/GlL30J27Ztg0ajwQcffICrrroq2UMkP0qK+rM0qmvPYexwHcpKDQGbiBtmzUTJTTeicd0HiRwiji15BbbOwRcI4TYaN27fMSg44imSQAkRERER+Zeu1weCIEBI4EK+61yJOmeRtr+Xxtm27pDnlBcUoPLF36Pz4CHUvfhyIoaXNDabDV2NTdj3ox8HXeDXK+TovuIK5A4fPmh/sZyCgJ42E+QFBZEON6Zc82zr7ETnoUM4/eoq93MXPr4QKp0Oyvx8yAsKEvrdiFaiv1sUOc6VtHC+pINzJS3Jnq9wziu5wMbbb7+Ne+65BwDw/vvvo66uDocOHcKf//xnPP7449i6dWuSR0i+tu1rxPodpwAAnx9pwedHWmDQZWP+LRWoqizxu0/h9GkJD2z4C2p4OrrkFSg0GujKpwTMuDBu3xEy2yTcQAkRERERBZYu1wdLlizBkiVLYLfbAQAbNmyARpP4fhMbN25MyHn6BtbfO7qseO/9j6ASkdCsaDUi3XNwtmzZAgDQh7iol9kd2LLxE9iLDF6Py7u6oFfIIbMHbtLuez77oYORDTaOsg4fhWdexq4vvoCtODUySyKVqO8WRY9zJS2cL+ngXElLsubLYgmdzesiucBGa2srhg0bBgD46KOPcMcdd+DCCy/E/fffjxdeeCHJoyNf2/Y1YvGq6kGPGzt6sXhVNRbNneY3uJGMXhuh2Du7cOCJX/rNuHDa7eioOYBjL78i+nh1K15F4fRpLEtFREREFIV0uT5YsGABFixYALPZDJ1Ohzlz5kCr1Sbs/IIgYOPGjbj22muhUqkScs6/792Irh4BF027AmOGhS4v1F13AgfWfZiAkSXP7NmzAUDU67xo1GjkjRkNAFDm5yNrSBEAoO/LXxGd3TJ79mzklo6NYsTxcabrbZzx+PmyCyeisEqaN4Ul47tFkeFcSQvnSzo4V9KS7Pkym82it5VcYGPo0KGora3F8OHD8Y9//AOvvNK/kGyxWKDgAnFKsTucWLZ2f9Btlr9XgxnlwweVpUpGrw2xfDMuQpWeCnicViPMtQehqyiPekxSb3gu9fETERFR8qTr9YFKpUrKxWQizzvUoEFXQweMHX0YP6ow5PY5hfq07rUhU6mQU6gP2FvD16kl52+q8uyXoSoZDvT0iDqGUqmMeL6D9QEBEFVzclt7u8/PJskvhiXrO50q4vl5ibVMn6tU5O/zY7PZoGg1wlrfAEWhPmU+PxQYv1vSksy/RcWSXGDjO9/5Du644w4MHz4cMpkM11xzDQBg586dmDRpUpJHR55q64wwdvQG3aa1vQe1dUZUjC8a9Jxh1kyMuutO1L/xZryGGJW6Fa/C6XDg8DO/i/gYVpMp6nH4C6xIqY+H1MdPREREycXrA+lpNllg7rYiL7v/wvVAnRGGghz389pcNYr1g8twZQ0ZgktfeQkdtQdx9PkUzcZRKiED4Ayj18XIO26DYeZM98Ku2MCGJ6cgQDB3Jmxhr6+lBf956IchG31H2pzcamwDACjz8mDr6kJfS+pk8lP44v15ofQW7POjR3+GGz8/RJlJcoGNX/ziFygvL0d9fT1uv/12ZGVlAQAUCgUWLlyY5NFFJl0bA7aYukVtt23fGUwao/P73LBbbsbZ9RshtLXFcmgxYW014vjSZVEdQ56fH3Iegs1X245dOPbc84PHNpBVMv4nj6Bw5vSoxhhPUh+/r2Q3WKLwcL6kg3MlLZwv6Uj2XMXqvOl4fZDOmk0WPPj0Jgi28z0g/v7pcfz90+Pun1VKOZYuvDpgcEMzMvyF/0SY8MjD0JVNBgC076/BsRfENTq31J9B/kQTLA0NEMw70deauEV8S0OD189i75oXzJ0hM2ecgoCO2oPu+QrnjnzrwPVf3oUT0L5nb9Ds+ERnAkRyPnlXF7rrTkCp9L8Ek0rZCvEg9vOSyOAcSQc/P0QUiOQCGwDwjW98Y9Bjc+fOTcJIIpMpjQEb28Vt98HWk+gxncTYwUkbAAD1RRXI/+enAACZ/03C4ozRcQDAFsHdVK4xOHI12HLyBHD6lKh9Bs2XwwH9mnchh//X4wRw+JWlMLU2A3J5ROOMK6mPPwg2xJIWzpd0cK6khfMlHVJoDBiK1K8PMom52+oV1PBHsDlg7rb6DWwA/YvAkZSkmvDIw9CMHOn1mKWhIabZH64Fb1uH+PrQbdt3oG37jpiNIRy+rz3Wdz17Hj+cY7sCG/kTL0T7nr3oa231u124mQC+QQmryQRb9/kb8pS5uVDrz7eo9w04RHK+juMnoH97LQ6seVfUPqFIqaQTcb6IiOJJkoENqcuUxoB2hxM7T/0rZDkqAPj8TDYevOfLg3ptuLRdcilOv/a6OyU5JJkMcDr9PyXuCHElAzDxoQe9shGcdgc6Dx6E0N4OVUEB8idPhkwhDzhf5poDOBRkQUAGQNFtwewLxkJbPiWOryYyUh+/P8lusETh4XxJB+dKWjhf0pHsuQqnMSCRJ1dJKtdiodVkwqHFzwQt/yRTqaArmxzXBcRUKo+l0oZuxu6P713PgRZlfTM9Ijl2IA5BgDAQGMq/cAKA/mx5f2OxNDSIvpMbQMighK9BQYragxGdL9Q1qNj3JtklnbhIHx4x8wWlEpMXPeYVUAP4XhIRicHARgpI18aAKgDzb6nA4lXVIbc1dvTiaL3Zb68NABh6xeUorprpbjDd09gUtPfGxEcfgaW+AU3vfwhbV5f7cUV+HuydXQH3C4dSq4UtggtydZEBpd/17h8RrM+E9rJLAQyeL0enuGwRR2dnSi4sSX38wbAhlrRwvqSDcyUtnC/pkEJjQMo89ec6A/baAPqDG56LfpcufTmiBddIsz9SXdaQIZBlZcHZ1weZQgHnQLUAMVxBCzEBo2j5Wyh338ymVEI5EKCxtrWFHZTwJaacja9ogiLhns/S0BByMTuZJXmSGVSRakBF1GfAZsPBXz816GH2jEhtUv1MEqUbBjYorqoqS3DTFaVYt7ku5LZt5uCZHTKFArqKcvfPuWNGDw4G+AQNRt1+mzsYotbr4XQ4cOCJX0b4aryNe3AeTqx8PWi9V3lWFiYtegxn1n2Ajj17UXTVlbjwRz+ATKFwb2PcvgOHnn520L6efSb88b2jI5CexiZR2yWa2PGL3Y6IiIiI0sfzq/cE7bXhyzfQIZZn9kesy1IlmufCuL23F86+PgAIK6gBxDfzxDPTI2TgxGbDvv99vL8srcOR1OBTJEGRcB19/oWUXsxOVlAl2VkqycKeEakrUz+TRKmIgQ2Ku5nlw0UFNgq12WEd1zBrJgqnT/MKXGjLJnsFDXyDIU67HWqDIWgwQoxRd92JosurIJPL/QYlXEbfcxf0F18Ey+l6dOzZ675jynM8dctfDXquk8tWQH1RBcw1B1BYWeHeX1s2WdRrqX/jTeSOGe2VIZIKxIxfXWSAdqABIxERERFlllC9NmIl3KDIqG/dhfq/vhHHEUXGc2Hc6ejvYyJTKuOacRGusIMmKTT2RAi2mN3X0hJRCTCpi3ej+kzEbIPosJk5UeqQXGAjUC1emUyGrKwsqNXqBI+IQikrNcCgyw7aa6OoIAdlpYawj+0buBCzfem8+4MGI0JSyJFVPARn3nsfKp0Wo+66Ew1vv+v3H7bGte8je8gQ5I4ZDQDoPlXv9by59mDIwITNbIb2s6049NlWd3kqw6yZYb2WuhWvonD6NK+gSrKJGX/pd+9PqTETERFR6uH1ASVa9tDiZA8hINdimiuYoczLg9DentxBUVja/rPHfeOeSyLKgkldpI3qM00qZRswwEJE0ZJcYKOgoAAyWeDWWyNHjsR9992Hn//855DL5QkcGQWikMtC9tp44GtTAjYOjzXDrJkYddedQXt0BGV34NgLL4va1FVOatyChwAAvU1NaP7nv5A1ZAjyJ05E+xf7wzq163iTFj4Kw6yZol+LtdUIc+3BsIJAiWCYNRMT//cnOPzb57we99eHhIiIiMgfXh8QebM0NEBo7wAAyBnYA9AfGLB1d0e0r6WhAcrc3BiPKLBUzAYKl++CtdVkCpk9JFOpIm5674t3yweWKtkG4QRYxPRCiuXnJ1YCZViFE7AJJ/gTTaCIQSaSKskFNl5//XU8/vjjuO+++zB9+nQAwK5du7Bq1Sr87Gc/Q0tLC5577jlkZWXhpz/9aZJHSy5VlSVYNHcalq3d7zdzY8W6GsjlMlRVlsDucKK2zog2cy8KtdkoKzXEPOiRUzI8pscL5dSf/gzIZIDTiaOuoMhArdhIeGZgiH0tVpMponPFW0FlpdfPRVdegQv/+4fM1CAiIiJReH0gLdpcNVRKOQRbZH8Hx5PYxbNoFrkTUcbK8871vubmuJ5LKg499duwe424HH3+BSDMa5NoAimxFMliZaB9xJbB6qitxanX/ywqu2T8wz90Vzfgwqk0RbogHl6JsZGYtPBRCF1dOPbiEmDgu2z48pU4YXfgoosuQpZOC8Hc6R5LvD5P4ZSEC1R6T2xGjJjgD5RKTF70GACEzOoKdN5UyuJJFAZy0ofkAhurVq3C7373O9xxxx3ux772ta+hoqICf/zjH7Fp0yaMHj0av/nNb3jhkmKqKkvgcDrx2z/tHvScsaMXi1dV49arxuHTvWe8gh8GXTbm31KBqsqSmI1FbEPqC+6/DyqdFidWvg5bgDIHYtg6uwY/GGFQA/DOwEhkE26n3R60p0kk+lpbvM9hszGoQURERKLx+kBaivUaLF14NQ7UGfH86j3JHo4Xz0bigai0+UGfDyWvdGzI4AnFXqRBDbdw9lcoogqkxEq4i5V9LS3oPnU66pJXJ1e8JnpbVV4u8saVDhq36ztmNZnQVXci4rEEOq7fsWjzIS8oiMm5YsW1gJ6qi6yJWBAP1pfH+K/PoAVQ99mWwU8OLPi71kGifQ9j9f0AQvfScX1OLQ0Nof+tsNlw8NdPRXXeVMjiSWSgIRMDOelMcoGNbdu2YenSpYMev/jii7F9+3YAwOzZs3H69OlED41CsDucWPFeTdBt3v338UGPuYIei+ZOi1lwQ2zj6pIbr4e59mBUQY14cWVgaMsmQ6HRwG6xBNxWqdWiz2hEx/6aiIMRxu07ULf8Va/3zLPnR6T6Wlq9fu5pbIz4WERERJR5eH0gPcV6DcxDrckehl9iGolHE9hQ6/Xu4ImloSH8ZtqU0mQKBZx2O5zJHIRSCavJJGpR1LVYCSD0neFxIHR0eP0s6g71CIhdyKx88fcxPa+YLLBgXL8fUnWRNZLG7i5isx4i5rPgH817GK/PZbLOk2oiDTTEO1uI5eykQXKBjVGjRmHlypV4+umnvR5fuXIlRo0aBQAwGo3Qx+DudIqt2jpj0AbioSx/rwYzyofHpCxVOI2rU7WEk+vOA5lCgfxJE9G+Z2/AbW1mM47+/sX+/UQEI3wzMwSzGYef+d2g7Xx7fkTCFdjQjB4Fy+l69DadhdPhgIw1sImIiEgEXh9QokW7WCkmeEISJJcnPUsDQFh3cLuIWeiLB2v7+cBGX0sLOmoPxiWoIea4TkFA66efQd3YiLMffgyntT/4qsjJgUqbD2Vubth3/3tmgR188ilY2zzWFsIoTS31RdZUCOB6vofhLogn6vuRrO9hskUSaAinTJdv9RKxa3yWhoaUzZZyYUktCQY2nnvuOdx+++34+OOPMW3aNADA7t27cejQIbz99tsAgOrqatx5553JHCb50WaOPKgBAK3tPaitM6JifFFMxmOYNROTFj46OAvBp3F1LEo4xZrKUAht2WT3z4qs/qaAitxc2EPUcg0VjPCXmYEQQYajS16BQqOBrnxK2NkgfS39pai0U8pgaTgDR18frG0mZBUZwjpOynA4YK45AHtHB4QOM1Q6LbIMhpiU7SIiIqLBeH0gTWJ6baiUcmhzU6/5tb+SVamefTHqW3chr3Qs1Hp9yo9VsqIoNZxMiW6O7qm3qQlAcjM1PJ352xpoAZz2V9rI08CCae6Y0SEXDbOGDIHT4fAOagCS/bxIXSQL4ql6s2smExUEChTkVYpbCj/6/Aspmy0FsKSWi+QCGzfddBMOHTqEP/7xjzhy5AgA4Ktf/SrWrl2LCy64AADw0EMPJXGEFEihNjvqY0QbHPFlmDUThdOnBe0bIaZsVaI5rVa07ap2Byasbe0AgPELHoSlvgH1b7wZ8hj+ghGtW7f5zcwI9UeXvbMLB574ZUSlqfpa+zM2socNQ9bQYvQ1ncXZf6xHwdTKoMGAePT7CEbM+dp27IJ+zbs45KcsWCzKdhEREdFgvD6QJlevDXO3FSZzL7p6BKz55Agamrtw7fRRqBg/BHk5Kpi7re7tU4nUsi7q//qGe4FDM3JksodDKSSS5uix0vzPf2P0XXfG7U71uN0BP7BgKnbR0FJ/JvZjSIBQd4NLccE/ogVxkQvh0QinKTlFKYweKamcLcWSWv0kF9gAgLFjxw5KNafUV1ZqgEGXHVU5qlgER3zJFAroKsqDPh+qbFUgKkMhnFar/+bhUbB1duHQ08+i5KYbUTh9Gvra+oMuKr0e51a+LuoYvsEIp8OBw89FV1M0ktJUrlJUVpMJ1tb+19Hw1jtoeOudgMGAcPp9xCIAIuZ8xu07cOy55xEotyUWZbuIiIjIP14fSJMrWPHYS5u9Mjc27qrHxl317p+VChl+et906P1cC2hz1SkR9BBTnkqmUkGlzU/gqLx59lMg8pKsElpOZ1w+kzKVCg5BQO+5czE/tiff/hGByr7E4ibJQGVxwi1FI/Z3lUMQRGU2ZIQom4X74xnEsJpMMWlKHu55Pc8fCZZBGozvSeJJ8rdQe3s7Vq5ciYMHDwIApkyZgvvvvx86nS7JI6NgFHIZ5t9SgcWrqiPav6ggB2WlySlPFKhsVTAX3H8fSm68Hm27qiMKiojRuO4DNK77wP2z1WgM+48m14J7LNWteBX6Sy9F5+HDgwIKvoGG3ub+UlSNa9cFHJsrgKMtmxzw/fQXOAgUkBj7wH1QabWigh3G7TtCnq9w+jTULX8VABCqA0zdildROH1aRpSlSnRWDRERZS5eH0iXudsatBwVANjsTvxq5U6/z6mUcixdeHXSgxv+ylP5inRBY8IjD3tlWdhsNmz/4ENoQ5XLCTKOaHqEJMqERx4GkBr1+Uk6JjzyMLKHDkXNz36ekM+45+czUAZHn7EtNufxUyIp5IK4QoELvjPXK6g6Zu49aN/7Odr/s7c/W8duR/aIEoy683YAgDI3F73nzonKbKDIJOv3mt/zigxQeQbXMqkMUtt/9riDP7bubq9+O54cghD6906Avh8uwf5O8A2aiM3wCbZdOgRaJBfY2L17N6677jrk5ORg+vTpAIDnn38ev/nNb7BhwwZccsklSR4hBVNVWYJFc6dh2dr9XpkbBl02vnTxCLz77+MB9513c3lMGodHylW2qqPmAA4/8zvYugJnYaiLDCi58XrIFAp3UOTYy68E3ScWzAcPx/X4Yllbjah+YD5sZrP7MUVeHgoumorOg4fCDr64AjiqwkI4BWvQbV2Bg2ABEN9yW4GyPRxWAcf+8MeQ51NoNKJfk7XVCHPtwaBZQukgnKwaIiKiaPD6ILMJNgfM3dakBzaA+JWn0owcibxxpe6fBUGAvSDyoF2wIIzVZPK7cCO2L8fwW27C2fc/DN5Ee2AhNZR0L5nFwE18uD43yQjc+WZwuHSfOBGbE0TQGB52O06ueDXo8wDQe6aRn8VMZbOJambv2XMiGWWQrCYTuo7XARC/qB8L9X99Q9yGSmXoYF+I73DA4GgUfYiCfa89z+cZOLHZbFC0GtFddwLKgcBXqgZBJBfY+PGPf4ybbroJy5cvd7+5NpsN3/3ud/Hf//3f+Oyzz5I8QgqlqrIEM8qHo7bOiF+u2IE+wY5ffHcmLijRYeKYQjz31/943bVVVJCDeTeXo6qyJImj7idTKFAwtRLjf/BQ0CyH0u/e73VneuH0aZBnvQrEObDRujmyu7biwTOoAQD2ri4Yt2yN6phCW+g7XaytRnTUHHBnUIgRKNvj2B/+OOh1+D3f/gOizwUAfRGkIksp+0FMlguDG0REFCu8PiCpSmb5qnCDMGLHOuLG6zHixutD1uUPe3E2zchUKujKJrM0GPqvc2J5XZPsPgUMDpAkiWxm7wrehauvpXXQQrmL2O9sosp1RSwGYwsUDIpXvyDPEpW+gRM9gAPrPnT/nKoZOJILbOzevdvrogUAlEolHnvsMVx22WVJHBmFQyGXoWJ8EYYX5eJkkxlt5j5cUNIf9Ch8vwbn2noAAJdPLcGj91yW1EwNfwKVplIXGVD63cF3pJtrDyak+bjNbIZSqw25GJ/uOmpqInq/Q2V7BCRzhnWeEytfhyIrS/TivpSyH5x2e8igkphyXFIK5BARUXLx+oCkKp7lq2It3LEGG3NfS0tYAR0plM0SbaAMSe6Y0e73KK1eXwRsXd1Q6bQxOx4DC+SP63dKugQT8yaMR9fRY0k5d7jfsb6WFuz70Y+hFwSvhfKwKJWpHdSQOCk3IpdcYEOr1eL06dOYNGmS1+P19fXIz09eIzaKTFFBDk42mdHS3h/IsDucaG0/X6JKKZenXFDDxVWaSszia6TNmCIx5Kor0eTRdyMjOSP7zESS7QEAuvJyNG/6t+hgis1sFp25kOzsh3ADDGKCeKHKcUkpkENERMnH6wOSskjLVzmzsxK+IB6rUlvhBkn8bSu2NFYqKf3RD1BYWe71Hvq+F1J8XdHqaWyE0Cnuxrzht9yErKIiqLT56D3XLL5EDGUuuRyTH1/oDibGKrAx+eePAw5n0rIILPXJzUwSq+0/e6DIyRH1b5Xhitkwbt7SX65QJgNsNpR+bz7yJ05gpl8cNX+2OdlDiIrkAht33nknHnjgATz33HOoqqoCAGzduhWPPvoo7rrrriSPjsJVVJADAGgdCGwY23tgd5y/+93U2et3v1QhUyhE9UoI1BgoHpS5uWE3Ok8n6iIDdBVT0PDW2xHtH262h7rIAF35FJTOux+Hnn4WToRuIO5yfPnKoJkLscp+iFQkAQaxQTzf7VwBFOOOnWj64KPB27OMVcbxDKrJ8/NFp0cTUebh9QFlIkdeHipf/D3Q038dJbUF8XCCJPHqXZJIToUc+ZMn+X0d6fD6onHy1deD92QZ4Cp15nqvuo7XMbBBoTkcUOv17s+NmLJ6oSjz8qC/+GLIZDJcuvRlCObOhP0Ozi0di+66E3D0pvZamUs431Gjq7S6x++DEytW4tI/LgnrnDKFQtTvlFTn2fMiniX2mtaui9uxE0FygY3nnnsOMpkM9957L2wDUVGVSoWHHnoITz/9dJJHR+EqKsgGcD6wca7N4vV8qgc2xNKWTYbaYAi6YK7Mz4OtM/oeHPVvvIlJCx/FZctfQeMHH+Hkq69HfUwpGXv/ff1N2kU0v/IrzGwPVz8Vw6yZGP+TR3D0+f8n+ryCsQ31b72D0d+8w+/z9W+9E3X2Q6QizRQRG8Tz3M5fACWQeAZyYiVYlgtLbInj7zOh12jQVlSMoVdcnsSREVEq4vUBZaqsIUVQqVQAktuvIy2JaQIrwoRHHoZ62DBs3l2NrCFFIbePxaKr1IhZgJzwyMPQlU1OfAAo0mtKSilt/9kDS0MDBLMZgAxj5t6Djv0HYNq5K6LjZQ0thrW11R2UTNTnUqZWI2/8OHTXnW9GP+XXv4BCo8G+//0pYLNh5DfvQMPf1iRkPIngtNvD7ulRcsvN0IwZhaZ1H6LrWHLKdUUrmmbhmUZygQ21Wo0XXngBixcvxvHjxwEA48aNg0ajSfLIKBJDfDI2zrV1A+jP5Ght70GbuS9pY4slmULhvqM/kPELHgKAQYt5kfTMcC3+ltx4PRrfez+jMjeOvrgk8rsXZDL0tbaK2lSl02LcQ9/zWtzXz5gGp1IJmdWKwlkz0bZ9R8jj1L/xJuzd3SicPs1rkdu4fQfq33hT1FhiXeosmkwRMUE8dZEB2rLJAAIHUAKxthrR+MFHKLnx+pQMCATLcgEGf79ZYmuwQJ8JucWCY889D6VSwfeLiLzw+kDatLlqqJRyCDYuHkZDSv06Us2ERx6GZuRIr8diVfZEM3IkskaPguOQuIU5z3m0mkzoqjuRdlkJF3z3O1BptTjz3vuwHK8TtY9m5MikfHYnP74Qtu5uSWVD0WCx/g51H6/D7gd/MKhfTrwp8/MhU6vP/5yXC2VuLgAgS69HX0sLHH3psYbmKdzv35l33o3TSBLDlZ3BoIY4kgtsuGg0GlRUVCR7GBQlVykqV4+NswMZG5PG6LGlvQfdPQL6BDuyVKm3gBkusQ3Hfft2ZI8bh50PzIfCYgl06EE87+IPFVBJN1GlZDqdaPnXv/vrOToDNwSXa3Jw2YplkKtV7jvw+4xGdDecgdxqBWQyDL3malGBDQBoXPcBGtd94F7kLpw+Law+H7EudRZNnwwxQTxXlouYAIo/J199HY3vvZ9yAYFQWS7+sMSWt2CfCVculRSydogoOXh9IE3Feg2WLrwa5m4rAKDuTAdeWvM5inTZ+P43puKp16thswcOeqiUcmhz1QGfzySZXtLIH1mIhrMylcpvJoCYBufx4jmPuWNGo2HN28HHEaPskoRQKnHq9T9LpgmwWq9PaFlpkhCbDQd//RRkKhUufeWlhGRbCUYjznqUbbZ1deOLRx7t/0HWf7XUE8eSRZQYDKSGRxKBjVtvvVX0tu++K+3IXKZx99jo6IHN7sChU20AAE22EkqFDDa7E+2dfRhamB533IlpOO7bt0MQBHTPnAbtPz8N61yuu/gDBVQCpdVGkiGSdoIENQDAMGMGZAo5Tv9tDZre/7C/9JXP/seWvBJ2eTHXIveou+4UnWXjmf3gPn2Y5Y58t+8Tee5AfTIcgoBRd92J+jVve9XH9A3iiQmgBDx3igUEIg3SuHCxvl8sms8TUWbg9UF6KdZrUKzv/3s/N7u/tJLZIuCyyUPxx0VXo6OzD4++tNndi+9/770Mwwz9d6lqc9XufSlziC29Vf7kLyEfKNcV6DiB+l4Ey4BJVD19MZk4DkFAzc9+nvJ390545GEoc3OT3gBYCvX3L/jud2BtM6Hx3bXJHgqF4BQECOZO5I0r9fquWk2mqBuLy1QqyNVq2Lu7RQyk/9/HHok0FU8lKn0BbJ1dkgm4kjdJBDZ0Ol2yh0BxYtD1Bzb6rHY88ORGtJn777bfsPM05AMRZ5O5N20CG4D4huOerBeMwfifPILTr60Sv+DtcWeJv4BK/sSJ6Dx8GH1GI4QOM1Q6LbIMBuRPnIj/PLgg4eWrpBBQUeTkwN7TA8Fkwq577x8c0PAgtLVFfJ7GDz4Uva0r+8El3Ibf/rZXarWizh1On4xh138Vpd/9jtdYY1FCK1UCAtEEaQAu1rtE2nw+UdgjhSh18Pogfem1WQAAq2CHpdeGYr0GSoXcHdQA+oMZ40cWJGmElAoSUXorVTJgxIzDs3xVT1MTTr32p+CL9yKzPEZ96y5RZXzEZsYEm69EmfTT/0358lJSymoJW4pnGE145GEAkd017/ld7TpeF9Ecukrjua53Tr7+Z/SICWwM6D3XHPY5M51m5ChMeHiBV1BK1O/RDJOqfbokEdh47bXXkj0EipMslQLZagV6rXZ3UMPFMRBx3r6/EZMuKEzG8FJK4czpKK6aiY6aAzj8zO+CLqr7u4vfX0Al0CJqqFJCsWp07nLB/fdBpdPi6O9fjNkx46Hoqitx7uP1aP/8C9H7yHOy4egJrzyWXeR7O+QrX0bh9Gnun8Nt+N26dRsOP/O7QduLCTAp8vPgdDjgtNvRtqs6ZLkzpSZn0AJwLNK6UyUgEIuF9ngu1ktlQT6S5vOJEm7QkIjii9cH6StbrYQmWwlLrw1t5l7k5qjQbPIuydrRaU3S6CiVJDPwkGrN2n3fi6KZM6LO8pCpVMgrHSvq/JMWPRb07zNXkCmWgY1IS/+o9Xrkjhkd1vwltCxZiCCRFIz61l3IHlrs9ZgyNxdqvT7iDCN/vXA6T55C3YsvRz1eT77nSCRXABAA9v3vTyP7zA2soxVddSWGXDEbtoGgiGA2h16oVyhwwXfmwt7Tk3a9fVwmPPIwlPl5OPjL37gfyy4Z7vffE9fvUavJFN77mIYmPPKw37KNqUASgQ1KX1s+P4Nea/BfCOt3nsa9N0yBQi4Lul0mkCkUKJhaifE/eEhUD4NIheoH4pv9IZjNOLHyda9tFfl5GH79V9H8yT9DNpIuufF6mGvFNdRLJuPW7WHv4+jpjSgbxZUdEkzLP/+Fji/2ie7LcXz5Snd2Q+vWbTj83O/DGpMne2cXDjzxS6gKC+EUQi8u9LUNXrQX02hcjEABgUQu5sdioT1ei/VSWpAPt/l8ooQbNCQiougUarNh6e1Cm7kXo4bmo6XN+2+i9q70a45K0hJOxoiQ5D4dgYgZPxB6UV+mUiW0gbKLaw66T50WXfLHFawINH82mw1btmzB7NmzkVOod78mz23DLUPmu8jvtNkgUyrdC/2+YtW4PtBY8krHep03HmXVCi+9BHnjSgM+H27JpkC9cJCTA6dCDlmQPkypzjNg4/psdh2vizqQljd2LAovu9TrsVABT9f5+1paQvf2kShlbi5UWh3k2dnu/qwyuQxdx+sAeGf6Bfo9WjRzBjpqD6Z01lesaUaOTMmgBiCRwMZ//dd/4Re/+AVmzgy+aNDZ2Yk//OEPyMvLw4IFCxI0OorUtn2N+O2fd4fcrrtHQG2dERXjixIwKmkQ24g82nME6wfie4e8YeYMv9vmjb1AVBAmVovc8RRpqawhV12JpnUfhLVPqKCGSzh9OQRjG+rfege5Y0b7zdTwK0QjdbElt3oa6gcfWqHA2AfuEz+WAPxdECR6MT/qz69cDiEOpdhSbUE+VLApWPN5J/obiEcbuI1kzKGChqlSEo0ok/D6IL0VarPR0NwF00BGt2/GBgMblApSpVRVpMSOP94lv0IJlvnieg2XLn150J3VnlxBhFCLloIgwH7oIHJLx0Ll0ZvFc9twMkVkKhWGfvlLYb0/rgXWeAgVcEgU3/feNX+BBO6FUwTTbbfgisumQalUJqz3TSxpRo6My5yoCgaX7BT7nY8kaCgV/l7P2Y/X4+zH6wHA3Qw+2PuUNWQINCOTX1YvUVK1BJWLJAIbt99+O2677TbodDp87Wtfw2WXXYaSkhJkZ2fDZDKhtrYWW7ZswUcffYQbbrgBzz4bvCQKJZ/d4cSytftFb+9bporENSKPVjj9QAJtKzYIE2xBU+oM06dBBqAxzOBGOMT25ah/400o8/PEHzhEI3WxhPaOQY8Zt+/AiZWvR3Vcf3fvByqxFc/F/Kg/vw4HDj/zO8gWymM2tngtyEeaCRMq2OTbfL5hzdteKb4OTQ5G3XgjHIKAjv01CSunxYbmRKmJ1wfpTZ+fDeD8NYArsKGQy2B3ONHBwAZRwiQzgCO2/Ekix+iZ7RFOICXZYrI4KZcDjthnR0Qzf468vEGBKALUBQVR7e8bNHSJWfAoTp+lUEIFaVzN4GP1vR1+y03IKiry+u71nmtOuVJf+VPKUHDRVChycqDS5sNus2PvwQOounaOV/ZaKpJEYOOBBx7APffcg7feegtvvvkmli1bho6O/kUymUyGsrIyXHfddaiursbkyYktT0GRqa0zwtghPljR3tkHu8PJclQ+ImlEngxigzCBgiDJ+kcvFjwX3uMZ2BDblwNATPujiOV7B06gTIJw+d69L6bEVt2KV6G/9FKYDxyA+lgdmt7/EFkFOtg6u6DSaZFlMES0aO76/B59cQnslvN3lsqzsjDi1lugNhTi+MuvhBxbrO78j8eCfKSZMKEyR0Z8/Wa0fLYl4HhVej3sfX1oXPOW13nHPnAfVFptXMuNie190r5vX0zGIZV+KETJxuuD9FaocwU2+gMYLe39maxjhmtRd6YD7Z0MbBBlglQtfyKFbB3fnhSBgiyiMlCUSkxe9BgAxK1MVixE2nfFJWl9VWJFoQAGbgxTRRnYcInHZ12mUqH8yV9C7hOMElOWLFWI7bM04sbrB71/XcfrUi6w0XmgFp0Hat0ZK/KCAghdZkkEDSUR2ACArKws3HPPPbjnnnsAAB0dHejp6YHBYEj5N5kGCzcDY8W6Gvz902OYf0sFqipL4jQqiiexQRjfIIjV1I6Tr74ev3HF+Q8WKZXaiidHby9at25D0eVVojIJxBh1152imqH7srYaUf3AfNjMZmgB1H+2ZdA2irw8lHztBoy6/bawFpUNs2bCWL0bLZv+5X7M0deH+jfehCI3V9TYYnXnv9gFebHbhVPWynNxXqXThZzvM39/L+jzgskEuZ/z+s53PMqNqXSD07j9aVjzTtTjCBQ4ChTAiSYIkm4BlHR7PSQOrw/SV6E2CwDcpahaTP2BjQmjCvoDG8zYIJKkcMs4pXL5k1QntsRROP1i+lpawmq6nmi+r8VqMqGr7oSoRWTf7CCxpZhS5nOqVEKZlwvbQKUEoaPDb9+IaEUbPCr90Q9QWFkecDyXLn1ZEiWwwvneSIk7YyVGgbFEkExgw5dOp4NO5GIDpZ5CbXbY+xg7erF4VTUWzZ3G4Eaa8wyCtHy2Oa7nGvmNW1H/xpsxP24mldoS68SK1873YokywKPIy8Oo229z/xxuM/RQ/VLsXV2of+NNNH3wIcYveCisBequw0f8H9NPmro/YgMNoYhtRi5mu3DKWrXtqh6cdRUDYvL1YlluzGm3o/6tdyLKtApnHK4FeeOuar+9eAIFcIZcOXtQlovYgIqUGsqLkW6vhyLH64P04bpWaGjpwrGGdpw19v8bWpDfH/Bobe9Bs8mCYr0maWMkovBJtYyT1IS72B5u74VUXsz1fS25Y0aHbITtrzl5oFJMvqLJhIk2KDLhkYehzM11BwFsHuWfDzzxS6/zhOobIVagz4CYbAunQo78yZNC9q/w7ZsTMsihVGL897+H43/4Y8jtEMNgiRQytzKBZAMbJG1lpQYYdNlhlaNyWf5eDWaUD2dZqgwhdnFWqdUGX6z2KWflCjwUTp+Gcxs+Cb4IG6KBtot2aiUadPmY/pWvoLCyQnyprQxhbWtz31EdrYKp599f4/YdUTcgD8TW2YVDTz+LkptuROH0aSHvAnfa7eg50xjVOUN95sXemS4mS8hfjxJ/xJa1qn/rnbgECsPlW9Ir3Lv5jdt34NjLr8DWFV3ZtlClxfwtyIthNRr9ZrmICaikWkP5aIl9PczoIJIWmaz/7/y6Mx348e8/dT/+5sb+mweMHb148OlNWLrwagY3iCSGi4HBhVMaKtB1QzyDC1Kbv2iDMZG+3kQEgVylxhLdNyLQexIsCGSz2bB5dzWyhhSFfQ6xwaWCyoqg21lNppQopRZt1gswuNScZ6BYMHfi5IroK2RIBQMblBQKuQzzb6nA4lXVYe/b2t6D2jojKsaL+4VI0iZ2cXbs/fcFXdye+JMfB6zFHyqTYvgNX0XTBx+FHOuQL38JdeYOaMunBFwwc5Xa6qg5gMPP/C7qhVOpcb3/Yoy6685BQSe5RgOHxYLes83o2F+D/IkTY1LWKpTGdR+gcd0HIe8CN/1nb3QN1+VyCD4BOs8F2Z7GpkHvSaAxickSGnv/fYM+q/4WgMUGo86sXSdqu3jzLOkVbnmnWPV/8R2Hr1iex1eggEq8GspHIhaBBrGvx+lw4MTK15nRQSQBzSYLzN1WtLZbQm4r2Bwwd1sZ2CCitCKFrAipSVYwJtLzhpPtEexzkmjBXq8gCHAcOhjz44aznas0V7L5+46H25Q9WKm5vpYWnFr1Z+n1iIkQAxuUNFWVJVg0dxqWrd0fduZGuD06SLrELM66Sj7JFsoHL2D6lITyJ1AmhWtfZV6eqMCGqqAAMHeE3E6mUKBgaiXG/+ChsBY25dlZcPRKu6a0Wq9H/sSJITNs1EUGjLr9Noy6/TavRf2mDz+GA0D38eOo+dnP3YGORPG8C9yzF4xrYbbr5MnoTuBw4PAzv4Nsoby/X4eIO/pdY5r42P+4F+pdfSEcgoCh/3Udzv1jvd99T6x8HTK53P39CBQEGDrnGnHD7+kR+0rjzmoyBb2b3195p7EP3IcTK1+P+Th8xarPTMBzBgioRNtQPlZZD5GWjvI9v9PhEPV6/AW9Pb83RZdXhf0aAo2JmSBEkWs2WfDg05sg2ByhNyYiSmNSy4qg2AonuJVKgQ0SL57f8UCfn3CDJ1LBwAYlVVVlCWaUD0dtnRFt5l60d/ZhxbqakPtF0qODpCtU4MG1EObbeDycRaZg+zrtdlFZI/mTJwOnT0X9ugIZ8fVbUqLMT6QUGg0Esxn/eXBByB4XrqbrANx33ft77YkMang6tuQVyH3mTZ6bi6wiQ0yOf3TJK+g+eQr1f1sjep/Dzz4fdraIZ6AGQMAgQP0bb4ouyZYqVDodjr7wsujt/QU7YsGVoeS5AG41tce9HJ2/gEo0DeVj1cci0lJY/s6vyMsTfd5AXL15IglusLcHUWyZu60MahAREYHBrXhIRN+TVJFJnx/JBTbq6+shk8kwcqCW2K5du7B69WqUlZVh/vz5SR4dRUIhl7nLStkdTvz902NBMziKCnJQVhqbxUOSDrFBC8/G4+EKtK/YrBGZQh72OT1fV5/RiPYv9sO0q9qrRFVY/UBSWPbwYSEXjv1l2MT77vZI2Dq7AHiXEXN0d6NHZIPwUOydXWEFNQBEFXQ4vnwlZKHac0soqKEeCDAl+7vi6mESaS+NaKh0OnTsr/H6fSm2DFxPY5PXz7HqyxFpKaxA57fHopSfT5aUWMnqVcIMEf94fUBEREREwaRLmbd0Cb7EiuQCG3fffTfmz5+Pb3/72zh79iyuvfZaTJkyBX/9619x9uxZPPHEE8keIkVBTO+NB742hY3DM1Q0QYtoickaESKsYej5uoqv+lLQhatQAZZoKPLzYO+Mfc8PuSYHDksPLKdOB91OqdXi0leWQK5WeT0upnwORUcwtiV7CDFV+t37IXSELguXiHG07aqO23c2EGV+Ho6+8LLX90ZVWIih114NZV5eyN4+9W+8idwxo91Nt2PVlyPcUlhOux0dNQdw7OVXgu4TC+H0FklWrxJmiATG6wMiIiIiCkXqmQwTHnkYurLJce/dIiWSC2zU1NRg+vTpAIA1a9agvLwcW7duxYYNG/Dggw/ywiUNhOq9sWJdDeRyGaoqS5IwOspk0ZS6CkewAE645avkOdlw9IjrSVNy4w0xKXU18s7bUVBRfr4vxvsfwgHAabMF3c9mNqPz8OFBr11s+Rwiz0Bjx/7QZQ3jRZGXh5Kv3QB7X1/Me3aI4S+jSGhrQ8Obb4k+Rt2KV6G/9FI0ffyPqPpyeG0XRimsRGe5+HsNgYLM9W+9E7P3RKxkZYhIBa8PMlf9ufN3XWpz1WwkTkRERJIjNugQaVADCLN3i4Qaj0susCEIArKysgAAn3zyCW666SYAwKRJk9DU1BRs15QlCEJCPzSuc6XyB3Xa5CEQhMl4bvXeQc8ZO3qxeFU1HrvnEswsH5aE0SWWFOYr02gmTYTrstnmcACO/nrQiZor7WWXYurFF6Pz4EGYdlXj3Ef/CLjt2IcexOnX/wShLcgd+XI5xv33j1A4YzrObdgIa7C790P0WVAVFmL4rV+HTCFH745dYQdKelpbofF5/+T58b9jYMica9B3rgXmL76I+7koPnInjEPZk7+GTCGHIAjImTABakNh8M9znNi7u2PWDydrRAn6zjTG5FjhsLYaUf3APNhENiT0/O4G+l0o9rvcXd+AM2veDmO0sdG8eQtsNhvyJ0+GqXo3Tr/2utfnR20oROHll+PsuvdFHa9lxw7kTJiAzoMHIbS3Q1VQgPzJk8MuW+i0O1C3fGXQbeqWv4r8iy8GgLDOl+y/MWJ13nS8PiBxnl+9x/3fKqUcSxdezeAGERFljHS9Cz/TJKpMltQzVvyRXGBjypQpWLp0KW644QZs3LgRv/71rwEAjY2NMBik0XdhyZIlWLJkCex2OwBgw4YN0GgS/wf4xo0bE35OsRxO4M2dwbdZ8tYetJ4CMqUqVSrPF3lL6FwNK4b6K19C7o5qKDwaadtzNeieMQ0729ugvqgC+f/8FAC8uii4whOdX5qNne1twPp/QD01+LY9UyYjp6Y24PPGiyrw8fp/AA4H9Gvehdxnu1D2HD4MwexTQsjhgF6jgdxiCetYANAzfhxyjh0Pud0xhRyyAi20YR6fUkfX8RP4+OOPAPn5RVzX5zkW/0w4stToKZsMOJ3I/Xxf8I1j2I+kt6kJMvR/xwK9jmDPRUMwd4o+rr/v7qDfhSG+y04ADk0OTn/wUdi/O2Khef1GNK/fCIdCAdnA32ieY+gztqFpIKghZmxnP/gYTRs3Qd5ndT9m12jQPXMarBeMCX0AhwOqc81QNjYhN0SAzmo04t9P/xbZh496/1sg8nzJ+hvD4jHWaKTD9QFFT7A5YO62MrBBREQZI136RlB6Bh0SQXKBjd/+9rf4+te/jmeffRZz587F1KlTAQDr1q1zp6CnugULFmDBggUwm83Q6XSYM2cOtNrELacJgoCNGzfi2muvhUqlCr1DEtQcN6J7c/DIRncfcMGkGSgfl94XrFKYL+qXzLlyfu97Qe/Sbbvk0kF3H2cZDBj9nbkonOn9uzPUtm07doU8lrnmAA6FuWClNhhwzX33+b27uK2oGMeeez7s413261/iiwU/Cpix4kT/XdjX3HcfOg8exKFPN4d1jqjJ5e6MH4qOzOFAubkLqvx8qHQ6qAv1yLt2Do5bemDasSvi45bc9nVoK8rd3ynjlq04HiqwEQPqYUNhPXsOMkd/kCTYQnq8AgBij6sqLPT67gqCgI3r12PmqNFwdnZ6/U4K9l2WARh1441oXCO+ZBYAKLRa2M3msPYJRj4Q1PAV7vssAyDzCGoAgMJigfafn2L8Tx4Z9LvXk7/fs6Hk7h2ccRbsfE67A6aaGuz5bDMuufIK6MvLw84miZY5RvOWDtcHRERERJHggjhlMskFNq666iq0trbCbDZDr9e7H58/f35Ssh5iQaVSJWXBOlnnFcNsCV6L33O7VH0NsZbK80XekjJXKsBw8UUBnx56xeUorpopqj9IqG3FHMvRKa58jafSefdDnZ0VcPxKpSKsmvul8+5HliYH4+Y/ELR585jv3Ad1dhYKKyugNhgS2qh84k9+jO5Tp8PqfUCBnX13rfcDIUqniTHy6zdD5VFCKaeoKKrjhSJTKuG02WBr985+kOfkQK5UDPTPSC1OwYrOvXvdzcbP/P09FK5dh2PW84v6rr4jI2/9OvruuhP1f1vjNTfK/HyMX/AgHBGUJhr6lavQuHZdTF5Lopx+fRWKq2b6/R1s3L4j7EBuuOfz7GGiBXDs081JaUQeq38r0/H6AMi8crWaLDlUSjkEW+QBf5vNlhHlW5M9VxQezpd0cK6khfMlHZwraUn2fIVzXskFNnp6euB0Ot0XLadOncLf//53TJ48Gdddd12SR0exUqjNjul2RBS8KXm424Z6Xu2xsCTGqLvuDLmY5tm83birGi3//gw2P3f7ejaQdu3nr+G62mBA69Ry913MMoUCpfPuDxoEicSIr9+Mls+2eJ97YIwA0i6oMeqbdyBnRAlUOh2OvvBS2D0ulHl5sHXFaPE+BiWhPn/4f7wWe7Vlk+MaAHMOZPA4enu9Hnf09MABIGfMKPScqoe2sgLmffvjMoZw2Tq7cOjpZ6G/7FJ0HKiFo6cHvvf927u6UP/Gm4N6j8gUCjjtdgydc03YTd+VWi3Gf/976Gk6CwDIGTMaPadOR/tyEiJQc3Gn3Y665a/G5XwdNQdQMLUyLRuRp8v1AcvVArddAvT6uZZttwD/Phx6/61btuJwBpURZ6laaeF8SQfnSlo4X9LBuZIWKZSrlVxg4+abb8att96KBx98EO3t7ZgxYwZUKhVaW1vx/PPP46GHHkr2ECkGykoNMOiyYezoDbhNUUEOykrTuwwVkVSFs/irMhRi1O23iTquK6CiqyjH2Pvuhbn2IPqMRggdZqh0WmQZDH4zUTyDIq4sk5wJE/r7gfhs5y8IEgnPAMuYb39rUIYLAOyeF59/s3IvnIDuI0fjcmwXZX6eV/aAb0AJAErnBc+W8WfiY/8DmVwOq8mEnsYmnNvwSUKzaHz5LvbGKwDmFqI0mbW5FQCgTMG70E27/xP2Ps6BBdzWrduRe8GY/jJiIn93aMsmQ5mX5w5sFE6bhpau7qD7yrLUcPqUh0oWq8k06DFz7cG4fd4P/fY5DL/xepz98OOg29WteBWF06f5zSZJVelyfcBytYEdP9OBfx/eGnK7y2dfjnEjdAkYUXKl8lzRYJwv6eBcSQvnSzo4V9KS7PkKp1yt5AIbe/bswe9//3sAwNtvv42hQ4di7969eOedd/DEE09I5sKFglPIZZh/SwUWr6oOuM28m8uhyJTO4UQSE87i77h5D0S0gBZOBoq/7QOlN/oLgghmM47/4Y9BMwmGf+0GZA0Z4jfA4m+sHftr4raAOfbee2Dr6opJgCYQmVqNKb/6OYSOjoClzcINFKmLDNCVT/E6zqjbb0Pbvv3Ys+ZtaGoPxvQ1KPJyYe+2iMrs8FzsjWUAzCV75Ej0NjSE3M7e0wMAcNjSK4277+xZHPnd/wMAyLODZ2PK1Go4rVa07diJth07IRv4Yztn+LCQv3cMs2ai9d+fxWzc0fDNbHPa7Wj/In5ZOPbublEZYoGySVJZul4fsFzteUqluMtWpVKZcmOPp1ScKwqM8yUdnCtp4XxJB+dKWpL5t6hYkgtsWCwW5A/Uut6wYQNuvfVWyOVyzJw5E6dOnUry6CiWqipLsGjuNCxbu98rcyNLrcBtXx6PGeXDkzg6Igol1OKvvzv8U4W/QIRh5gzUv/UOmt7/0CvAEenr8He3diyoi84HVTwDNP2loV6O2UK8YGyDTC7HkCuvCLqdbwmxpnUfBNy29Lv3DwqOyBQKaMunwHL6FCqv/ypOv7YqJq9h5B23QVdejgNP/FLU9r6LveG8rmBcn5+23f8RFdhw6T5eF9H5pMC3DJcvp9U748I5EKTsqK3FhAUPBf29M/K2r8O8/0BSs4CA/jJafUYjOvbXQFs2GW27quMaiAxXvH4/xQuvD4iIiIiIMo/kAhvjx4/H2rVr8fWvfx3r16/Hj3/8YwBAc3NzQlO1KTGqKkswo3w41nxyBG9vOgKrzYE+qx2r1x/G+h2nMP+WClRVliR7mEQUgOfir5iSUalMplBg9DfvwKjbbxPVhD2UcPuQiOUZHPAN0IjNopFnZ8HR2xdyO7GLn54lxHRlkwf3OxEZHCqcOd3duL593z40rHlH1Pn9KaisDHvx1nd7mUIBbdlkHPn9i2EdZ9RddyKnZLjX56c7zN4QgqkdQH/TbblaHfmCuFwesvyVVLRs+hc6Pt+H0nn347Llr8C093Mc/PVTXttkDx0a31JiItnMZhwd+NzEtK9MjMTr91O88Pog/Wlz1SEbiysVMpjMvWg2WVCsT71yfUREREQUW5ILbDzxxBO4++678eMf/xhf+cpXMGvWLAD9d2ddfPHFSR4dxcPOmiasXn9o0OPGjl4sXlWNRXOnMbhBlMLCLRmV6mL1esT0IVHk56HkhutR/7c1IY8nJjgQKItGnpcLw/TpKJhagSyDAU6HQ1QmQySLn/5KfYUTHHK9/9qyyWje9O+IFvRdWS3mMEtb+Xu94fRECDRHxu070PT+h+KOUVgIa9v5huzZw4ah8re/GRQ87D17blCjbk8lN92IwunTIJjNOPzM70SdWwp8e6JkDS1G37lmAICqoACKrKy4lBKLRsoFNQa+H1LC64P0V6zXYOnCq3GqyYynXq+GzT44wGGzO/GrlTuhUsqxdOHVDG4QERERpTnJBTa+8Y1vYPbs2WhqasLUqVPdj1999dX4+te/nsSRUTzYHU4sWxu83vTy92owo3w4+20QkaSI6UMyYcFDMMyaidwLxgxahFUZCjFszrWD7vwPRUxgwWm3hwy6RLP4GYvgUDRNvF1ZLeE0uQ/0esVmfYy84zaM/uadg+bIuH1HWK9h7Lz7ceT5F9zll9SFBQHfz9wxo0Vlx8gWylNmkT9WXD1RckaNcgc2FHm5cNrt7j4pntlk7V/sh2lXdcoFGZLBX0m4VMfrg8xQrNfA3G31G9TwJNgcMHdbGdggIiIiSnOSC2wAwLBhwzBs2DA0DNSiHjlyJKZPn57kUVE81NYZvfpr+NPa3oPaOiMqxhclaFRERLER6M5x38XnaLMcfIUKLIgJGqTC4me4d94r8/MxfsGD7vc1nOBIoNcrNmuloLJy0P5Oux11y18Vtb/nZ+LUqr+g9+zZkOcX+7nx7RfS8u/PYDObz28gwXJV1lYj6t96B50Hat2P9Tacwe55D6F0Xv/76Pk9KL7qS3Da7X4zX5o+/Nj7/Uhjo+66MyX7HonB6wMiIiIioswiucCGw+HAk08+id/97nfoGrirLj8/H//zP/+Dxx9/HHK5PMkjpFhqMwcPaoS7HRFRqhG7+Jzokl5igy7JJubOe0V+HkpuvAGjbr/N76J+NE3uxWR9BMr2EFvG6oL770PJjde7x64uMrgDG6oQgRWxnxvPPihj77vX6/OYP3EiOg8fhtVkgtXUjpOvvh7yeKnAXyku31JVngK9VyNv/TqqH5gfNLihLjJg7P334cTK1yWb+aIyFGLU7bclexgR4fUBEREREVHmkVxg4/HHH8fKlSvx9NNP4/LLLwcAbNmyBb/4xS/Q29uL3/zmN0keIcVSoTY7ptsREaWiVO1DEutMkXgJdOe92DFH0+Q+muwWsWWs1PoCr/3VhkL3f9t7LO7ySrHi7/Po+tlpt6PxvfeDL97LZLBMnohL7rgd+ilT0PDu39H0/oeDgk0FU6fCuGVrzMYdDlepKjHvm1ytwvjvfy/kHBtmzYRh5gyvz1FvUxPOfrw+lkOPOScAGYBx8x5Iue+2WLw+ICIiIiLKPJILbKxatQorVqzATTfd5H6ssrISI0aMwPe//31euKSZslIDDLrsoOWoNNlKNLf3YP+xVpSVGthrg4gohlI16BJMJGOO5nVGmt0itoyV53bG7Ttg2rXb/XPj2vfRunmbu7xSvIkJ5Iz78cPY2d4GbfkUyFUqjP7mHRh1+21+g03G2VU49vIrCe9tYW01wlx7UPSci51j389Rx/6a1AhsBCkn5sjVYOJDD6ZMFlYkeH1ARERERJR5JBfYaGtrw6RJkwY9PmnSJLS1tSVhRBRPCrkM82+pwOJV1QG3sfTa8P/e2AMAMOiyMf+WClRVliRqiERERBFlt4RbxipQo/Fg5ZXiIdQiv/ayS4GPPvLaJ1DgyPW+1b/1Ds78/T04ekOXllQZCqGdPDnqbA+xGTMu8ZrjhPAIashzc2GYMR0FUyug0Omw5eQJFM6Udi8KXh8QEREREWUeyQU2pk6dipdffhkvvvii1+Mvv/wypk6dmqRRUTxVVZZg0dxpWLZ2f8hG4saOXixeVY1Fc6cxuEFERAkVbtZHOGWsxDQaD6e8UrSCLfILghDWsWQKhTuro/6tdwaVrVIZCjFszrXIKRk+KNvDX3Bl6LXX+O2v4UtsxozvWGM9x6Eo8/MAALZOj6yWKBq6O7q70fLPf8Ew/TJoy6cAp09FPLZUwesDIiIiIqLMI7nAxjPPPIMbbrgBn3zyCWbNmgUA2L59O+rr6/GRz92BlD6qKktwWdkwfOdX62Hutobcfvl7NZhRPpxlqYiIKKWJLXEkptF4uOWVohXrMmWeAQ4xWRGBgisAcG7DJxE1dI+HUA3qg3E1jgcwqKG7+eBBHH7mdxGX8apb8SqmXnxxRPumGl4fZA5trhoqpRyCLXBgT6WUQ5urTuCoiIiIiCgZJBfY+NKXvoQjR45gyZIlOHToEADg1ltvxfe//32UlPAO/XR2+GSbqKAGALS296C2zoiK8UVxHhUREVF0xJQ4Els2KdzySqkonIBJoG0jbegeL645bvzgI5x89XXR+3k2jvd9nQVTKzH+Bw9FnA1ibTWi8+DBiPZNNbw+yBzFeg2WLrwa5m4rTOZedPUIWPruPlh6bbjr2okYPiQXeTkq9zVDsV6T5BETERERUbxILrABACUlJYOaADY0NGD+/PlYtmxZkkZF8dZmDl13O5rtiYiIkiXUYn4kjcYzWaQN3eNJplBArS8Ia59Q8xnodSry82DvDJ3JIbS3hzWeVMbrg8zhClY89tJmr8yNNzYe9tpOpZRj6cKrGdwgIiIiSlOSDGz4YzQasXLlSl64pLFCbXZctyciIkpV4TYap8iafcdbOIEnsfPp73U6HQ4ceOKXIfdVFRQA5g7RY5IaXh+kL3O3NWg5KgAQbA6Yu60MbBARERGlqbQJbFD6Kys1wKDLDtlAHAAMumyUlRoSMCoiIqL4C6fROJ0X6z4g0RIToHIJZz59X6fTbhcVCMufPDktmocTEREREVHmkSd7AERiKeQyzL+lQtS2VsGOnTVNcR4RERFR4rjKDqkN3oF7dZEBkxY+mpTyShQeV4AqGGV+ftTzKeY8/YETXgoQEREREZE0MWODJKWqsgSL5k7DsrX7g2ZudFoELF5VjUVzp6Gqkk0jiYgoPaRieSUKT7C+GCU33oBRt98Wk/kU02dEEISoz0NERERERJQMkgls3HrrrUGfb0+j5ocUXFVlCWaUD0fNsVY8/adqdPUEvihftnY/ZpQPh0IuS+AIiYiI4ifVyitR+BIVoEr3QBivD4iIiIiIMpdkAhs6nS7k8/fee2+CRkPJppDLIJfLggY1AMDY0Ys1nxzBXXMmJmhkRERERKElKkCVzoEwXh8QEREREWUuyQQ2XnvttWQPgVJMmzl0E3EAWL3+EEYV52H2RSPiPCIiIiIiShReH1Aouw+eg8ncC702G9pcNYr1mmQPiYiIiIhiRDKBDSJfhdps0ds+8+fdOH3OjDuvncSyVEREREREEqbNVUOllEOwOYJu99d/HHL/t0opx9KFVzO4QURERJQm5MkeAFGkykoNMOjEBTecAN7YcATf/vnH2LavMb4DIyIiIiKiuCnWa7B04dV45O5LRO8j2Bwwd1vjOCoiIiIiSiQGNkiyFHIZ5t9SEdY+nRYBi1dVM7hBRERERCRhxXoNRg3NT/YwiIiIiChJGNggSauqLMHd14XfGHzZ2v2wO5xxGBERERERERERERERxRMDGyR5d1wzUXRJKhdjRy/WfHIkTiMiIiIiIiIiIiIionhhYIMkL5KSVACwev0hlqQiIiIiIiIiIiIikhgGNigtVFWW4H+/fRnksvD2W/5eDUtSEREREREREREREUkIAxuUNmZfNAKPfvuysPZpbe9BbZ0xTiMiIiIiIiIiIiIiolhjYIPSyuypI7Bo7jTkaVSi92kz98ZxREREREREFA/aXDVUSnGXtEqFDCZzL441tKPZZInzyIiIiIgo3pTJHgBRrFVVlmBG+XC8tGYvNlXXh9y+UBte43EiIiIiIkq+Yr0GSxdeDXO3FSZzL7p6BJi7rXjt/QODys3a7E78auVOAIBKKcfShVejWK9JxrCJiIiIKAYY2KC0pJDL8MM7LsbnR1pg7AickVFUkIOyUkMCR0ZERERERLFSrNd4BSiONbSH7KEn2Bwwd1sZ2CAiIiKSMJaiorSlkMsw/5aKoNvMmTE6QaMhIiIiIqJUUX+ukyWpiIiIiCSMgQ1Ka1WVJVg0dxoMOv/lplavP4wHntyAbfsaEzwyIiIiIiJKludX78H3Fn+C6tqzDHAQERERSRADG5T2qipLsPJnc3D3dZP8Pm/s6MXiVdUMbhARERERZRBX340Hn97E4AYRERGRxDCwQRlj/Y6TQZ9ftnZ/yHq8RERERESUXgSbAwfqjAxuEBEREUkIAxuUEWrrjEGbiAP9mRsvrdnL4AYRERERUYZ5fvUeZm4QERERSQgDG5QR2szBgxoum6rr8e2ff8yyVEREREREGUawOWDutiZ7GEREREQkAgMblBEKtf6bh/vTaRHYc4OIiIiISIK0uWqolJFf5taf62TWBhEREZEEMLBBGaGs1ACDTnxwAwCWv1fDslRERERERBJSrNdg6cKr8cjdl0S0P0tSEREREUkDAxuUERRyGebfUhHWPq3tPaitM8ZpREREREREFA/Feg1GDc2PeH+WpCIiIiJKfQxsUMaoqizB3ddNDGsfsb05iIiIiIgodURbkoqIiIiIUhv/0qOMcsc1E8MqSRVObw4iIiIiIkoNrpJUTzwwA0oFL3uJiIiI0o0y2QMgSiRXSarFq6pDbpuXo8SxhnY0myzosgjQ5qlRpMtBWakBCrksAaMlIiIiIqJIFes1KNZr8MdFV+NAnRHPr96T7CERERERUYwwsEEZp6qyBIvmTsNLb32OLosQcLuuHhteff/AoMcNumzMv6UCVZUl8RwmERERERHFQLFeA5QCKqUcgs2R7OEQERERUQwwJ5cyUlVlCf7yy6/i7usmIU+jCmtfY0cvFq+qxrZ9jXEaHRERERERxZKrNNUjd1+S7KEQERERUQwwYyMFCIIAQQicORCP83n+fyb7xpdLUWLIwXOr94a977K1+3HJxKK4l6XifEkH50paOF/SwbmSFs6XdCR7rvgZoUQr1mtgHmpN9jCIiIiIKAYY2EiCJUuWYMmSJbDb7QCADRs2QKPRJHwcGzduTPg5U43DCby5M7J9jR29eO1vH6OkIPQ5znYAPVYgRw0M0wGRxEI4X9LBuZIWzpd0cK6khfMlHcmaK4vFkpTzUmbT5qpDlqRSKeXQ5qoTOCoiIiIiChcDG0mwYMECLFiwAGazGTqdDnPmzIFWq03Y+QVBwMaNG3HttddCpQqvDFO6qTluRPfmCCMbACaWXYQrLgrca2NHzVmsfL8Wxo5e92MGXTYe+FoZZpYPE3UOzpd0cK6khfMlHZwraeF8SUey58psNif8nESuklTmbitM5l509QhY88kRNDR34drpo1Exvgh5OSqYu63u7YmIiIgo9TCwkQJUKlVSLiaTdd5UYrbYotrfoNMEfA+37WvEM3/ZM+hxY0cvnvnLHiyaOy2sBuScL+ngXEkL50s6OFfSwvmSjmT+LUqUDK5gxWMvbfbK3Ni46zQ27jrt/lmllGPpwqsZ3CAiIiJKQWweThmtUJsd1f6//9sev03E7Q4nlq3dH3Tf5e/VwO5wRnV+IiIiIiIKn7nbGrQcFQAINoc7c4OIiIiIUgsDG5TRykoNMOgiD24YO3qxeFX1oOBGbZ3Rq/yUP63tPaitM0Z8biIiIiIiiq/6c51oNrEfDBEREVGqYWCDMppCLsP8WyqiPo5v9kVrR4+o/drMwYMfRERERESUPM+v3oMHn97E4AYRERFRimGPDcp4VZUlWDR3Gpat3e+VZZGXo8SM8uEoyMvCO/86FvQYre09WPb3fZh0QSHOGi34YMtxUeeOthQWERERERHFl2Bz4ECdEeahVmhz1ey5QURERJQCGNggQn9wY0b5cNTWGdFm7kWhNhtlpQYo5DJ8uqdB1DE+2nYSH207KfqcRQU5KCs1RDhiIiIiIiJKlOdX7wHAhuJEREREqYKBDaIBCrkMFeOLBj0er6yKeTeXQyGXxeXYREREREQUe66G4gxsEBERESUXe2wQhRBtg3FfOVkK3H3dRMwoHx6zYxIRERERERERERFlCgY2iEKIVYNxl54+O1avP4wHntyAbfsaY3ZcIiIiIiISR5urhkrJy2EiIiIiqeJfckQiVFWW4KYrSmN6TGNHLxavqmZwg4iIiIgowYr1GixdeDUeufuSZA+FiIiIiCLAHhtEIs0sH451m+tiftzl79VgRvlw9tsgIiIiIkqgYr0G5qHWsPfbsOMUduvOAQA0WUrk56qRl6OCXpsNba6a/TeIiIiIEoCBDSKRXL02jB29MT1ua3sPauuMfhuXExERERFR/LhKUgk2h+h9Pt5+MuBzKqUcSxdezeAGERERUZyxFBWRSLHuteFpR01TXI5LJDV2hxP7j7Xi0z0N2H+sFXaHM9lDIiIiojTmKkn1+x9/KSZlqQSbA+bu8LNAiIiIiCg8zNggCkNVZQkWzZ2GZWv3xzRzY93mOkwpNaCqsiRmxySSmm37Ggd9twy6bMy/pYLfDSIiIoqbYr0GxXpNRNkb4Wg2WYIGPVjGioiIiEg8BjaIwlRVWYIZ5cNRW2dEa3sPDp1qw0fbTkZ9XPbaoEy2bV8jFq+qHvS4saMXi1dVY9HcaQxuEBERUVy5sjdONZnx1OvVsNljF+BoNlnw4NObggZNWMaKiIiISDwGNogioJDL3D0xrrxkJHYeOBt1Bgd7bVCmsjucWLZ2f9BtGPgjIqJMIwgCBEFI6Pk8/z9T6fNUaNMoowpq2Gy2Qe9jW4clZCaIYHOgrcMCfZ4q+HacK0nhfEkH50paOF/SwbmSlmTPVzjnZWCDKEqu3hv+7jZ3mTa5GNUHm0Me64MtdSgrNXDxljJKbZ0xZGCQgT8iIkp3S5YswZIlS2C32wEAGzZsgEaT+Dv3N27cmPBzpprWzuj237plKw7nR3ZMf/sGwrmSFs6XdHCupIXzJR2cK2lJ1nxZLBbR2zKwQRQDgXpvFBXkYN7N5cjXqEUFNrbtb8I3H/8Qt355PO64ZiIDHJQR2szisp3EbkdERCRFCxYswIIFC2A2m6HT6TBnzhxotdqEnV8QBGzcuBHXXnstVKrgGQPp7viZDqzduzXi/S+ffTnGjdBFdEx/+/riXEkL50s6OFfSwvmSDs6VtCR7vsxms+htGdggihHP3htt5l4UarPd2Rd2hxMGXbaoclW9VjtWrz+M9zfX4Qe3X4Rpk4ckYPREyVOozY7pdkREROlApVIl5WIyWedNJUpldJfJTcYeFOo07l4ZzSYLmow9os8t9v3nXEkL50s6OFfSwvmSDs6VtCTzb1GxGNggiiHP3hu+j4cqV+Wr0yJg8apqPHbPJbEcIlHKKSs1hAz8FRXkoKzUkMBREREREUXm+dV73I3AAYRsGk5ERERE4ZMnewBEmaKqsgQ3XVEa9n4r1h2AwxmHARGlCFfgL5h5N5ezNBsRERFJhmBzwNxthbnbyqAGERERURwwsEGUQDPLh4e9T5u5D/88CNQcN8LOCAelKVefmtwc75TDooIcLJo7DVWVJUkaGREREVFkdh88h90HzyV7GERERERpiaWoiBJITMkdf062Ak8s34ncbCVmVgzH1AlDUKTLcffwIEoHVZUlOGey4NV1BwAAj9x1Ca68ZCQ/40RERJRQ2lw1VEp51JkWf/3HobC2Vynl0OaqozonUTppNllg7rYGfF6bq3b3siEioszDwAZRAkXSa8NTd68Nm6rrsam6HgAY6KC0Y/NYQBg1LJ+fZyIiIkq4Yr0GSxdeHXBBtf5cJ55fvSem53zk7kswpdTARVqiAc0mS8j+NK5eNvzeEBFlJgY2iBLMVXLnpbc+R5dFiOpYvoEOgy4b82+pYNkekqw+we7+754+WxJHQkRERJmsWK9J6GLpqKH5XJwl8iCmP42rlw2/O0REmYk9NoiSoKqyBH/55Vdx93WTkK1WxOy4xo5eLF5VjW37GmN2TKJEEoTzFy8MbBAREVGmqD/XiWMN7TjW0I5mkyXZwyEiIiJKeczYIEoShVyGu+ZMxB3XXIiX1ux1Z13EwrK1+zGjfDjL+CSR3eFEbZ0RbeZeFGqzWSZMJKtnxkYvAxtERESUGTxLW7G8DhEREVFoDGwQJZlCLsMP77gYnx9pCbupeCDGjl68+OYefPmy0ejo7OPCeoLtqDmLle/Xes0ny4SJw1JURERElOpi1Vw8EJbXISIiIgqNgQ2iFBBtU3F//rm7Af/c3eD+mQvriXGiFVjx2eBmkq4yYYvmTuMcBOG5QMDABhEREaUiz+bi8WgkDvSXpgL6gygMcBARERENxh4bRCnC1VTcoMuOy/HZfyP+7A4ndhwLvs3y92pgdzgTMyAJ8szYsLAUFREREaWoYr0G40cWYNTQ/Lgc//nVe/Dj33+KB5/exJ4bRERERH4wY4MohVRVlmBG+XDU1hmxo6YJG3edjvld68vfq8GM8uEAMKgHhL/HWL5KvIMn2tBtDb5Na3sPauuMqBhflJhBSYyVpaiIiIiI3FiWioiIiMg/BjaIUoxCLkPF+CJUjC/C/TeV42/rD+Lv/z6KWK3xtrb34KU392Jn7Vl0WQT343kaFWQAOj0eY/mq8Jg6+0Rt12aOTS+VdMRSVERERCQl8e63QZSpxHy3VEo5tLnqBI6KiIhSCQMbRClMIZfhjmsmQNN3FBdMmoH2LgFfHG0ZFJQI16bd9YMe83c8V/mq//32ZZh90YiIz5cp9PlZorYr1Man3Fg6YPNwIiIikhLPfhue4tV7gyhTeH63lq/dj9oTbdBrs/HEAzPc27AHDRFRZmNgg0gC5DKgfJwBKpUKX75sFOwOJ2qOteLpP1WjqyfyAIdYz/5lNyADZk9lcCOYyWMLkatG0HJURQU57rJfNBhLUREREZHUFOs1cV1c3X3wHEzmXui12dDmqqHPU8XtXESpxPXdUin728Pa7Q6MH1mQ3EEREVHKYGCDSIIUchmmXjgEP7zjIixeVR338zmcwG//tBvyuTKWpQpCIZdh5nhgU23gbebdXM6+JUFYBZaiIiIiIvL0138ccv+3SinHyz/5UhJHQ5R4rmuEXl4fEBGRB3myB0BEkauqLMGiudOQp0nMXVvL36uB3eFMyLmkamwR8Ng9l8Cg8y43VVSQg0VzpzEwFILV5pGx0csLFyIiIpImV3+AYBQRXI0LNgdqT7Shiy3bKIO4rhGsNgfsdvazISKifszYIJK4qsoSzCgfjjWfHMG6zcej6r0RSmt7D2rrjKgYXxS3c6SDmeXDMOkCA+5/ciMAQJOtxIrHr2WmhggsRUVERETpIFDvDU8mcy9+tXJn2Md+4c0voJABX/5KD0qGsCwVpT+vrG6rHXk5vEeXiIgY2CBKCwq5DHfNmYg7rrkQtXVGfH60BWs+ORKXc7WZeXuYGJ0eAaaePhvgdAJgYCMUlqIiIiKidBGq90azyQKVUg7BFv4d6HYnUHuiDUqlks2TKe153vzU22dDXg4DekRExMAGUVpRyGWoGF8U1+DD3iPNmH3RCGYfhNDR1ef+b6cTMHdboddmB9mDAO+LFgsDG0RERJTGXFkdB+qMeH71nrD3f+HNL6BUyPDT+6ZjzHAtAxwprKsXOH6mA0ql/yUYba6a8xeEYGNWNxERDcbABlEaKozjAvqm6nps+fwMZl80AlMnDEGRLgdlpQYGOnx0+JQdaO/qY2AjBLvd4dXDxSrYYbc7oIikADURERGRBBTrNTAPDVyuKhSb3YlfrdwJhRy4/2vlGF6U6/6bk4vlqaGlvQdvVQN/27U14DYqpRxLF17N+QqgzyOru9fKwAYREfVjYIMoDZWVGmDQZcPYEZ/MjT7BgU3V9dhUXQ8AyMtR4aYrS3HHNRMjCnDYHU7U1hnRZu5FoTY7JQMl4Y7R7JGxAXhncJB/Vj9lGFhDl4iIiCg0uwNY/l6N12O+wQ4GOpLD3G2F3Rl8G8HmgLnbyvkJQGAfPiIi8oOBDaI0pJDLMP+WCixeVZ2Q83X1CFi9/jDe31yHH9x+EaoqS9zPhQoIbNvXiGVr93sFYaINlMSavzEadNmYf0uF12v1NDhjI/I78TKFZxkqpUIGm90JS6/AGrpEREREEfANdjArgKTI6XR63QDV22cPsjUREWUS3gZLlKaqKkuwaO40GHT+yx8VFeTg1qvGDXo+XxP5InKnRcDiVdXYtq8RQH9A4IEnN+Cnr2zFc3/9D376ylY88OQGr+cXr6oelFniCpR8++cfu7dNlkBjNHb0er1WX74ZGu2dzNgIxdU4XKmQIyer/3PIO7KIiIgo3Wlz1VAp439p7soKIJISwSerm9cHRETkwowNojRWVVmCGeXDUVtnRGt7D8zdVmjz1F59Me69YYpXRoXd6cT/Ld0W1XmXv1cDh9OJ3/5p96DnXAGB//32ZVixrsbP3ue5AiWL5k4LmBkRT3aHE8vW7g+6zfL3ajCjfPigzBJXYEOtlMNqc7AUlQjWgaaAWSo5crKV6LRYeeFCREREac/VRNzcbYXJ3IvjZzrw138cisu56s91siQVSYpvuVpeHxARkQsDG0RpTiGXoWJ8kejn7Q5n1P05Wtt78Mo7+4Ju88q7X8DcLYg6XqDgQbzV1hlDvg+t7T2orTMOeo87BkpPjRyaj7ozHQxsiOAqRaVSKaDJ6v/nqaeXFy5ERESU/or1GnewYcxwLdZ8cmTQneqx8PzqPSxJRZLiWa4WYPNwIiI6j6WoiMiLqz9HtEKluYsNagDngweJ1mYWF9zxt525uz+QMXpYPgCgnYGNkFwXLWqVAjmuwAbvyCIiIqIM48rgeOTuS+JyfMHmwD9316O69iyONbSj2WSJy3mIYsE3sNHDHhtERDSAGRtENIirP8dLb32OLov4AEQ87ahpCpp5Eg+FWv/9ScRs58rYGDNMO/AzAxuhuHpsZKnkDGwQERFRRivWa4DS/obf8cjc8Cx15S+Do9lkCXqjEstZUaIMytjg9QEREQ1gYIOI/HL151jzyRG8+6+j6LUm986YdZvrMKXUkNBeG2WlhpBluYoK+vuVeLLZHejq6Q8Inc/YYKPGUPpcpaiUzNggIiIicmVunGoy46nXq2Gzxz7AAfRncJxqMrsDGSZzb8jzsZyVeNpcNRQywO4MvI1KKYc2V524QUkIe2wQEVEgDGwQUUAKuQx3zZmIO665EGs+OYJ1m48nNYNj2dr9Ce214SrLtXhVdcBt5t1cPmg8rotCuQwYWZwHAGjv7IPT6YRMltg+IVIiuJuHM7BBREREBJzvvfHHRfENcPzmtV2wO4KsvPsQbA4cqDMCpWBwI4QhBTm4fRpw6YzLcfBkO159/wAAYFbFcNxxzYUAmAETzKBSVOyxQUREAxjYIKKQPAMctXVGtLb34IujLdiyrxF9CczkMHb04qU1e/HDOy5OWHCjqrIEC74xFUve/sLr8aKCHMy7udxvBokrsKHNzYI+v79MlVWwo9dqdy/Y02B9A6Wo1Co5NNkMbBARERG5eAY42jos2LplK8qmXoZmUy9ee/9AWEEJfyLZn43IxcvLBsaN0OH0uW6vx8ePLEjOgCREELwDeSxFRURELlxhIyLRFHKZu8/Fly8bhasuG4X/W7otoWPYVF2PXQfO4ge3X5SwslSuPhkuVRXD8di90wIGV9yBjTw1stUKqFUKWAU7Orr6GNgIwuqvFFUvL1yIiIiIXIr1GujzVDicD1w2qRgqlQqzKobD3G2FydyL42c6vPpnxJtgc8DcbWVgQ6ROj74lwXqY0HlWm2+PDTYPJyKifvJkD4CIpKtiXBEMOnENtmOp0yJg8apqbNvXmJDztbb3eP1s6bUFzRhxNQ7X5WZBJpNBl6sCAPzrP/XYf6w16jvq0pUgDC5FZeEdWURERERBFes1GD+yANPKhuGyyUOTPRwKwszARtisAntsEBGRfwxsEFHEXD0okmX5ezXuIIHd4cT+Y634dE9DzIMHrR39gY1hhv470Y6faQ94HocTOHzKBABwwoktX5yBqbMPALB6/WH89JWteODJDQkLykiJZymqHJaiIiIiIgqbNlcNlZKX+amq03I+mNHJwIYorowN+cCNZeyxQURELqyJQkRRqaoswd3XTcTq9YejOo5cBtx05Tis/fS46H1a23vwxvpDUCjkWL/jJIwdve7nDLpszL+lwm+5KrvDido6I9rMvSjUZqOs1BA0A8OVsTG8KBdnjRZ0WgQ899f/DDrPjpqzeHMn0G09BQCoOW5EzXHjoOMZO3qxeFU1Fs2dlrByWlLgumhRq1iKioiIiCgSxXoNli68GgfqjHh+9Z5kDyctNZssQbMtgjUC98rYsFjhcDjdC/bkn6tcrTZXjfbOPvbYICIiNwY2iChqd1wzEet3nPIKLITr0Xsuw+yLRkCTrQwrSPLmJ0f8Pu4bPHAFM3bUNOHfexq8LiqCBUEAoGUgsLH3cEvA89x61Ti8+2/xQRmgP+NkRvnwhDVCT3Wuixa1SoEslQIAcK7Ngv3HWkMGn4iIiIioX7FeA5QCKqUcgs0RegcSrdlkwYNPbwr6vgZrqO55DeJwOGHpFZCnUcdlrOnCVYpKNxDYYEY3ERG5MLBBRFFzlaRavKo67H3zNWr84Pap7qBCLIIknpat3Q+H04kV79UEPGaoDIoWkyXkecLJNHFpbe9BbZ3R3ZA907kuWlpMFix5uwEA0GTsxk9f2Roy+ERERERE57kyN1xNxbt6BJxrs8Slsfjug+dQf64TeTkq6LXZQTMWQokmGyIRzN3WkMGiYA3VfV9bR7eVgY0QXDc/6fKyAHSih83DiYhoAAMbRBQTVZUlWDR3Gpat3e8VQCgqyMGVF5Xg071nvB7P16jwtStKccc1E73uxI8mSOKPsaMXv/3TblHbujIoAHiVqmpq7Q65b6QtPdrMsQngpAPXRcuOmrODnmP5LiIiIqLwFOs1Xovrxxra4xLY8D2mUiHDT++bDr02G4D4YISYbAjPYyc7yBEJzx4bAGDusmLEkCQNRiKsA58HbW5/AMhmd0CwOdhLhoiIGNggotipqizBjPLhfvtX3HvDFNF9LVxBkpfe+hxdFiFh429t78GaT44M6tcRT4UDF3wE9Amh08pZvouIiIgotdnsTvxq5U73z65gxJjh2qCBCDHZEJ7HDlbyKRU5HE50DQQ2igpy0NreA3N3X5JHlfo8e2y49FltUCmZ6UJElOkY2CCimFLIZX5LKwV6PBBXkOSZP+/Gtn2NsRxiUKvXx/4utkCKCnJQVmpI2PlSXYspdDCJ5buIiIiIpMUVjIh1ICJYyadU1N0ruLO8Rw7JGwhsBC67Rf2stv7AhiZbBaVCDpvdAUufjSW8iIgIzN0jopSlkMtw4+Vjkz2MuJl3czkzDzxY+sRl57B8FxEREZH0uAIRmapz4LXnZClRqOvP2s7k90MsVCcwqAABAABJREFUYaAPn1opR05W/725vWwgTkREYMYGEaW4slIDDLrshJWGSoSighzMu7mcvSJ8iA3xsHwXERERUfx8678mYdwInbtHBgDUn+vE86v3RH1sk7kXxxra/T5Xf64z6uOnss6BErvaXLW7rBIDG6H1DZSiUqsUyMlSoNMC9FrZQJyIiBjYIKIUF+tm4olWVJCDB742Bcca2vHOv45haKEG3/qvScjXqGF3OJmx4UGtUoTchuW7iIiIiCKjzVVDpZQH7WOhUsrxlctGxa28029e2wW7qx5TDNSf65RME3FXECOfgY2wuD6vKpUc2QMZGz3M2CAiIjCwQUQS4Gomvmztfslkbtw1ZyIqxhW5m6S7xn2uzeK+282gy8b8WyqYuTEgVLNIgOW7iIiIiCJVrNdg6cKrgy6mxztIEMugBgA8v3pPQpuIiw0OeTa6dvGXsdHB5uEhuZqHq5UKdykqBjaIiAhgYIOIJMLVTLy2zog2cy8K8rJQc8KID7bUocsirjdDIt185Tjk5qgAANv2NWLFuppB2xg7erF4VTUWzZ3G4AbOX7Tcde1EbNh1yiuIxfJdRERERNEr1mskkd0QDsHmwIE6I1CKuL82z+DQ9v1NWPPJEfdzv5o/y52N4W8cZkt/QEmrUUObm9X/GDM2QrJ6lqJSs8cGERGdx8AGEUmGQi5Dxfgi989TLxyCb1470R3saGjpwpqNhxHjG8EiMu+pjfjB7RdhRvlwLFu7P+i2y9+rwYzy4RmfiWAdaAx40cQhuHPORPz5o1q8869jGDdCh9/995cy/v0hIiIiShYxmQrJlMjMDVdwaNeBs16PK5VyjB9ZEHC/Lldgg6WowmId+MypVXJkZ/WXru1hjw0iIgIDG0Qkcb7BjjHD8vHbP+1O4oj6dVoELF5VjbuvmxiyfFZrew9q64xeryMTWW3n78ZSyGW4dPJQvPOvY7D02RjUICIiIkoiz0wFk7kXx8904K//OJTsYXlJZOYG0P83vKeG5i5UjAv897y5uz/LnD02wuOZseHusdHLjA0iImJgg4jSzOypIyCfKwvYj8Ogy4ZVsLtr3EYiJ0spuq7r+5vrRG33+dEWtJl7UajNdvflyDSui5asgSbiQwv7L0hbTBY4HE7IM/A9ISIiIkoVnmWsxgzXYs0nR1IugyORmRuuwEa+RoVOi4AzzV2Dtmk2WdDWYUFrJ3C2oxsAcNbYhf3HWgAA3T0CDp9qg0IhBxD/HidS5LpGaDVZ3P/d2NqFYw3t7m34vhERZSYGNogo7Xj242ht74G52wptnhpFuhyUlRqws6YJi1dVR3z8a6ePxjqRAQuxARTP+ryZ2lS8b6AUlUrZf2Fn0GZDIZfBZneizdyLooKcZA6PiIiIiAb4a0SeKpkcgs2BU03muDdJP9tmAQCUlujwxbFWHDlt8lpsF2x2PP7KNo/gTxsAYFN1AzZVN7i3+8mLm93/nchG6FLhuqHslXfPl/ddv+MU1u845f6Z7xsRUWZiYIOI0pJviSpPVZUlWDR3WsCsjnyNChddOAS1J9r8NrDO16hFBzYAIE+jCqvBeSY2FXc6nRBs3hkbCoUcRQU5ONdmwbk2CwMbRERERCnEXyNyvTY76YENAHjq9WrY7IGzSVwL4UDwclCBAiDNJguaWvszML441goAOHiyDT/+/afubZSK/ht0wiHYHDB3W7lA78GVpREM3zcioszEwEYKEAQBghB5WZxIzuf5/5TaOF/xMW3yEFwy8cs4OBC8cGV1GLTZmDy2EAq5DHaHEwdPtMHU2Qd9fpbX4wZddsjeGS43Vl2Av31yNOwxvrhmL7JUMkwpNQBA0LFKnWCzwzlw3SeDw/15HzIQ2Ghq7cSFo7SxPSe/W5LBuZIWzpd0JHuu+BkhongJFtQA+hfCt+9vwusf1IYMgPzmoSqolAqvx497ZGYEHkN4QQ3yz5pi5c6IiCh1MLCRBEuWLMGSJUtgt/ffebBhwwZoNIm/s2Djxo0JPydFjvMVXwoA3Z1AdxNw+vDg5zvh/fhFI4BNHaGPm5sFaPqO4pIxwJ5Tobf31N1jwy9W7MJAjzz4a+uRpQCmjAQuGg1IOb7h+dr+uWkjBsoMw9p/Ixy27PgC3U1fxOXc/G5JB+dKWjhf0pGsubJYLEk5LxHFjzZXDZVSnnK9N/xZ8V5NyG0EmwM//cO2kIESih+bBD5LRESUHAxsJMGCBQuwYMECmM1m6HQ6zJkzB1ptbO9EDkYQBGzcuBHXXnstVCpVws5LkeF8pa5La87iD+/uD1pmasHtl2Bm+TDoPm/EnlOfR3SeYH3K++z9AZOjLSo8dGsFZpYPcz8XLOPE3+P+xOIYYpg6+/DnbZsgkwE33vBVyGT9xzKrj+DIuWPokelhzx8W00wVfrekg3MlLZwv6Uj2XJnN5oSfk4jiy9V740CdEc+v3hOTY3735nLIACwXEYiIBwY1kqe/XC3ffyIi8o+BjRSgUqmScjGZrPNSZDhfqeeKi0ehaupIrPnkCNZtPu4V4HD143D1yBiiz43rWDotAp75yx4smjsNM8qH+x2TQZeNL108Ap/uPeNVRitQs/Jt+xoH9SEJ5xh2hxO1dUa0mXtRqM1GWakhYDDC4eyvbaxSKqBWq93n/2hrf5pL7UkTak+aQo45EvxuSQfnSlo4X9KRzL9FiSj9FOs1MA8N3LciHCqlHLMqhgMAXv+wlovcGcbucIIFvYiIKBAGNoiIoqCQy3DXnIm445oLse/IOfxr8058+YoZqLxwqNciflmpIay+HJH6/Rt7IJPJ0OMnzcPY0Yt3/33c7+O+zcq37WvE4lXVER8jUFAkUDDC1RQwSyUPev5gYyYiIiKi9PHI3ZdgSqnB3RA61pkglPrENA4nIqLMJU/2AIiI0oFCLkP5OAPGFQPl4wZnJijkMsy/pSLu4+i12v0GNcRYtnY/7A4n7A4nlq3dH9Exlr9Xgy1fnMHiVdWDgjiuYMS2fY2D9nM1BVSrFGGdf/l7NbA7eB8XERERUSpx9dqIlEop9wpqAP2ZIFNKDVEdl6TFKjBDh4iIAmPGBhFRglRVluDu6yZi9Xo/3clTgLGjF3/beBgtJkvEmSWt7T148c3Pg26z/L0azCgf7hX86R0IxtjtTnywuU70+Vvbe1BbZ0TF+KKIxktEREREsefqtWHu9l+SymTu/1tPr832+7w2V+0V1PA9brpmbqiUcmhz1ckeRsoQm7HB942IKDMxsEFElEB3XDMR63ecintJqkj9bUP0QZdQGSO+wYht+xqx5O0vAADtXX1YsS68xpBt5tR8L4mIiIgyWbFe4zc4EYvjxqqHR6L95FuXwuE8n2388bYTOHjShK/NHouvTBsdMKCTqay2/sBGTpYST33/cgDAi2/uxYlGM+69fjIunlgMIHAgjIiI0hsDG0RECeQqSRWsf0QmcAUjQvXSEKMwwJ1+RERERESpIi9HicljC1Gs16DZZIG524rSETocPGlCQ0sXAMDcbYW528qF+gGuZvHZagXGjywAAIwamo8TjWYo5HL3Y0RElJkY2CAiSrCqyhIsmjttUHNtuQzIlHYRhdrsqHp5uBQV5KCs1BCjURERERGRFLh6eLgWvqWgq8eG7y3+BAu+MRV/eHsfBPv5se893IK9hz91/6xSyrF04dUZH9zoGyhFpVYp3I8NKcgBALR29CRlTERElDoY2CAiSoKqyhLMKB+O2joj2sy9KNRmY+IFhTh8sg2t7T344mgLNu2uT/Yw40IGYP/xFnx+tCXqklzzbi4f1KidiGLL7nB6/a4qKzXwe0dEREnl6rVxqsmMp16vhs0ujQCHze7ECyH60QH9mQrmbmvGBzaEgebhatX5hvFDBt6TFpMlKWMiIqLUwcAGEVGSKOSyQU2vXT9/+bJRmD5l2KCsjqKCHMyZMTplG5CL4QTwxoYjUR1Dq1Hjodsqka9R49M9DVxsJYqTbfsaB/0eMuiyMf+WClRVliRxZERElOlcPTz+uKi/SbnJ3IuuHsH9vLnbitfePwB7pqREpyFXxoZK6ZGxoe/P2GhpZ8YGEVGmY2CDiChF+cvqcJVdSuUG5LH23ZvKoc1Vw9xtxY6aRtTUtWGIPhuvvLsP5u7zjSO52EoUW4F64Bg7erF4VTUWzZ3G7xsRESVdsCblsyqG40CdEc+v3pPgUUWv/lyn38czqf+GMNA8PMtPKaoWEwMbRESZjoENIqIU5i+rA0DIBuQ5WUpMKTVg98Fz8Rxe3BUV5ODGK0qhkMuwbV8jTjb1X+AdP2MetC0XW4liR0wPnOXv1WBG+fCMzpRimS4iotRWrNcApUhIPw6FHIhlRaxAwZhk9t9wNT0PJNZBl76BUlQqpUcpqoHAhrnbil6rDdlqLmsREWUq/gtARCRBgRqQ52tU+NoVpbjjmonuYMBLb32OLosQ5Gipy9VDI9Cd4/6IWWy1O5yoOW7E8Wag5rgRlRcO5WIkkYfaOmPIrLDW9h7U1hn9Bl8zAct0ERFJg6sfR6AF+fpznWFldCgVMvz0vunQa7O9HjeZe/GrlTujGqsYnv03EhloaDZZ8ODTm4IGiAK9N5GOQ/DTPDw3R4WcLAV6+uxobe/ByOL8sI9LRETpgYENIiKJClSqynOB3rXNmk+OYN3m45IKcNx0RSmqKktE3TnuKdRiq+9i5L8O7ZTEYqTrzvDW9h6Yu63Q5qlRpMvhHeIUF21mcaXuxG6Xblimi4hIWoKVq9LmqkNmdHgu2AdapD/W0B6r4Ya0Yccp7MprwppNR4P2EHGNO0+j8upT4ck08G+5bzDCxfV6zd3WkFkvNrvTb3BHpZTjNw9VBRyD53k8Wd2BjfMZGzKZDEUFGtSf62Rgg4hSSqKz2oiBDSIiSQtUqsp3m7vmTMQd11zoDoIU5GXh93/bE/SObG2uGt+7tRLP/nl3rIctyszy4QDE3Tnua0dN06D3xe5wYs0nR7B6/aFB26f6YqS/O8NdpBCUIekpDLC4Eel26YRluoiI0kuojA4g9RajPt5+UtR2gQIN4XCVvoqGYHPgp3/YBluQWl3+SmxZBwIprowN16KhK9Cx+fMzMHX2ubfPy1EFDT4RUfS4eO+fmKy2ZJYSTFcMbBARZQjfIEioPh0LvjEVVZUlkAN49i+7EeRmsEHuvm4iuiwC1m2ui2isRQU57kbpkdwRvm5zHZxOJ4YW5iJPo8L+Y63YcaAJ3T22oPul4mJkqDJcqR6UIWkqKzXAoMsOGlT0/J5mEpbpIiJKP8EyOsQSk/khRa7SV9EKFtTwPI93YGMgY0Op8LtouGHnaWzYeXrQsbh4SBQfXLwPTExWm7/fcxQdBjaIiDJUoD4dRQU5mHdzuXuRfPZFIwAZ8Ns/hc7c8N03T6PC6vWHwx6bq7cGEPkd4e9vORH2Pq3tPfhgc527YXkkxDQTFttwOJwyXKkYlCHpUshlIYOfnt/TTMIyXURE5I8r8+NUkxlPvV4ddCHfVSKqq0cIq79HsmzYcQrZ6sBlpGLJ827wc0YLAKCnT8CBOqPooBEXD4nig4v3lGoY2CAiymBi+nQAwOypIyCfK/PbKPe6mWNQUpTnd987rpmI9TtOiS4l5RsYAcTdOR5LK9bV4I0NhzCzYjimThji7mMBIOT7FKqZsKsclm+/k0DlpMIpw+UKyhTkZ0UdUCECzgc/X/jbXlj6zmc7+fueZhKW6SIiokBcmR9/XHS+tJXNZsPWLVtx+ezLoVT2L8G4SrUksi9HNMSWvoqWydyLx17aPGjhdPPnjdj8eWNCxkBERNLBwAYRUYYT06cDEB8E8T12qLu+77r2Qowozg94PDHHiLXuXhs2VddjU3U9ACBbrYBcJvNa3PUNRmz54ozfrBZXqahbrxqHDbtO+23g7trm0W9dCr022/3+tnb0hDXuFetqAo4vVNCFyJ+qyhLUnjDivc/6y8qVlxrw5EOXZ3RAjGW6iIgoFM/SVoIg4HA+MG6EDiqVKskjS21dPULalfIiIqL4YWCDiIhEExsE8SS25FUkx0iUXqt90GOevS0cDiee/UvwUl3v/vt4yPM8+9f/eP2szY384tdzfAD8BobYn4PE6Oo5H4yz9NkyOqgBsEwXERFRvOzY35TsIRARkYQwsEFERHEXSbZHsGO0tvdgxbqamDQyjNZLa/aiK0RT8kiZuwdnd4RLTI+OVOzP4Sqb1dreA5O5B3XngJrjRlReODSlxpkJPLOMzhq74XQ6IZNl9hy4gq3/72970cMyXUREFKF0bTgeqW0MbBARURgY2CAiooSIJNsj2DGy1IqElqcKJF5BjVgRk+HS2t6D2jpj1PMTK/7KZgHAp4d3snxWEnhlbPTaYO62QpeXlcQRBZbIPjJVlSXYc7gZ63ecAgBMmzwUj98/g4E3IiISzdVw/ECdURJNxCn1eDZb98fVz4WIKB0xsEFERJJUVVmCu6+biNXrDyd7KGmhzRx9ia9YLCpv29cYNGDlKp/1v9++DLMvGhHtkEmE7h7vzKEmY3dKBjaS0UfG870RbA4GNYiIKGzFeg3MQ5OfhZxu6s91uv873Rb3XcEMk7kXT71eDZs9cMaPSinH0oVXp9XrJ0pFYjLwVEo5tLnqBI4q/TGwQUREknXHNROxfseppPTdSDd7jzRj9kUjQi7MBgpexGJR2e5wiiqdBaC/p4kMmD2VwY1467L0L7bkZCnR02fD2dZuTBpTmORReQsUEIt3HxnPbJazbd0xPz4REWWGWJSkkssAhzOGg5I4zwyYYIv7nhkPNpsNrZ3A8TMdUCr7l8tSLSjSbLLgwac3if6sCDYHzN3WlHoNJF1SW7xPZEaTKwPP3G3Fr1bsgKmzDwDw9S+Nw5WXjIz5+agfAxtERCRZYpr4+srLUcLh6G+CTOdtqq7H1i8acctV4zCltAgdnX2Dsi78BS8KtVmYUmrA5s8bBx0z3EXl2jqj6CCVwwn89k+7gW+DmRtx1jmweD9uhA41dUZsrzkLgy4nrmWewiEmIBavPjKeGRvNph7Y7Q4oFPKYnoOIiNKf54JYIILNDpVSEfB5k7kXv1q5Mx7DSznfvbncvXB6rq0bf/1H8AzuQIv7gYIEa/dudf93qmU8mLutMevJwjJWFC7P31W/eW0nWtv7r92umFqCW78yAUDqfG7EBAFj/f0u1mtQrNegT7C7HxNsDowfWRCT49NgDGwQEZGkuZr4+i645+UoMaN8OCrGFaHLIkCbp0bRwGLszpqmlOjPkWp6rXb8bcMRAEfcj7myLgD4fc/azH1+gxqelq3dL2pROZJyWM/8eTdqTxoxq7wkZRba04lgc6DP2v+H+fEz7QD6A1zb9jWmTL8TMQGxePWR8czYcDicaGnvwTBDbkzPQUREmcG1IBapYw3tsRtMClMp5ZhVMRzFeg2aTZaIj9NssuBAnTFkkCARGQ/xDjB4luVyEWx2PP7KtoQu+saC1DJs0pHrd1Vv3/nFe1NXX8ot3osJAsbj+213OGHpPX8TZaORWd3xxMAGERFJXlVlCWaUDxfd36GqsgSP3XMJlqzZA89rCJkMcDKF34sr6yJfo4rqGGs+OYK75kwMul2hNjvsYzsBvL/5BN7ffCJlFtrTSVfP+S9Ij8fFCxD/Mk9iiQ2IxaKPjK8uS39gQyGXwe5w4qyxm4ENIiJKCjElYpQKGRZ8YyosvTYsf68mgaOLjUfuvgRTSg3uoEY4JZnqz3W6F73D3TcaoYIWYgIMSoUMP71vOvTabL9BilD8NaZXKmSw2YNf+KRSGatmkwWnmsx+e4qkcoZNurLbHV43+Jxq6oTT6YRMxpvMLL0+/QlbGdiIJwY2iIgoLSjksrDuxp5ZPgytp4ALJs2A2WJDoTYbEy8oxOGTbWht78EXR1uws/ase+EyHqQUSOmM8n1Yvf4QuixWzCwfHjDoVFZqgEGXHXHPFM/G4rq8rKiamFM/c1foZqbxKvMkltiAWCSBs2CcTie6By5cRg/Lx4lGMz7bewYKuZyfOSIiSjgx5aw8F/Zf/7A2IQv7sTRqaL57wTrckkzPr94DlVKO3zxUhbNGS8KCGqECKAo5EKT3NwDAZnfGvMxYqKBGKgknECXYHDhQZwRKweBGHHkGNWQAOi1WfH6kBfkevTUyNXvGd/2guc0Cm90BJcvVxgUDG0RElLHkMqB8nAEq1flsBFdw5MuXjfJqlN3Y2o3V6w/F5LxFBTmYd3M5HE5nf5+ICEgpKOKybnMd1m2uQ6E2C/816wKUFOV5BR4Uchm+e3N5xO+JyzN/3g3Pt4aZHJGrOd4acpt4lXkSS0xATC4DOrr7Ynrenj4bHANdWhsH7sTauOs0Nu46zc8cERElhdhyVoGCIPXnOv3e3e9LqZAPumteDKVCBhlkECLYNxYNiQWbA4uWbIU9zC7rn+5pwO6D59w/O+wOyBVyaLKUyM9VIy9HBb3HDRSucYopdRXBW5FxIg1iMXMjfk42md3/7fo2PbFsu9c2mToHrh582lw1LL0CbHYndh88h6KCHPc2mRr0iQcGNoiIiALwzQIZVZyHZ/+yG8GuheQy4KYrx2Hz52e8Flq1uWpcdcnIQRkL8rmyQf1BgolFUCTZ2sx9WL3+fJNHba4KV10yCnkaNdbvOBn18X2nxzOTg43GwyO2dnU8yjyJpZDLMP+WiqB9c1zN5uVzZTELNnjejeXqQ+KSKmW6iIiIAommp8dP75uGrh5BVBDkkbsvwaih+QC8F/zF7Put/5qEcSN00GuzY7YQGG5QA8D/Z+++w5o63z6AfxMSIBD2RhQVtyJuxVWtu45at7WKo9pW7a5trbVqf9122Pa1y9nl3nXUvfeeiHsPFISwCcl5/8CkhKwTCITI93NdXDUnT855Tp6TNOfc57lvrNp52ab2xQnglDUFU3g5k7KURutJdD/Z+jmCs4yBvY/xW4n56eIKBo4/nXfIoE15DfqUBAY2iIiIRGrdoAIggcWAwoQX8i+eD+9RV1TNj8L1Qe48zMDGA9eKHBRRKuTIyFY71WwOVYYaa3ZfKfHtfPXnEdy4r8LATrWYJkgkF5FTpu2d5slWLeuH472hTfDln5aDffZMm2Up1UdJbI+IiKikianTIZdJERnmrf+3tba6mhgFqUKs/z8UAJrUDilzBYnFyE/z5EQ/xi34dsExfY2PyDBvo7EsXEPkkSob6VlqqDJykZWTp5/VoqOb3VIawRJnDco4g4yskkvXXNrsPcNHzA2LzhL0cQYMbBAREdmgdUwFkwEF3UwK3d3ZttT8KNx2QMcaRQqK6NruP33HaWdzlCQBwMJNF7Byx2X0bheFulUD8Sg1G6qMXCg95EjPVMNb6YpAH4W+3kp5r9Pho3Sz2ibAJ//9cTQxfbVn2qyzV5JKdXtEREQlzZY6HQBsalt4uZigSHFTT5F96Gp8FA5wFKcIe2ncsW4tKENFl/4EBTYA+wYaMnOerPemrGNgg4iIyEbmAgr2uvBdnKAIYD744uUhR882VdH36RpYvu0iVmy/iOxCKXTKg+xcDRZtugDggtk2EhjeZ6dUyNGrbVUM6Fiz1AMcBWu9lHaQJTM7z2qbXLUGB8/cdXjKJbHpsOyVNutBStlP00VERGQrW1JUFTWdla0BFCobCgc4ABS5CHtpFfku3Gc/E7OMeazZLiNL3KwrRxITQC0JWSLOn8h+GNggIiIqAluCD45gLfgyuHNNDOhYA0u2XMCa3ZcN6gWUVT1aVcb+M/dE1yMpjsLJA9Kz1FiwMQErd1xCp2aRRmnBCrJnIGLfqTtGASp7Fqa21tf0xyctLeqF4syVJJPHSVqmukzUkxCbDsteabPEjqmj03QRERGVRcWp8UGOpQsWiMxYalbBGRWFi6/b+9jQ9dkU1juwnZibnxxNF0A9e/khvl14vNS2m5VT9t+bJwkDG0RERE8oa8EXF6lEH+DQXdy+nZiOhZsTzL7GGnc3F2TnlMwskGZ1QvBi7/o4dyUJa/dcwb7Td0tkO5Zk5WiwZvcVrNl9xWgWh0YrmAwUWZrtYS6woFvXgo3njfpgr2LopoImhfuq24/qlfxw8WYK0mE+AKarJ+Eo1Sv5WW0T6KuwW9osbxGpr+y5PSIiIvqPo+7Gpv/Yoza6qYCDixQY2bOevjZHmoi6ZsVRWrNHniRiU1Hp6pz4KeUl3CPTgv08cMerdG8ycoagz5OEgQ0iIqJyrnAApHK4N35ceqJIszheH9AQs9ecsfusCk83oHYVf31f61QNwKhPNpXK7A1zdLM4Vmy/hKZ1QnD8wgOT75m52R4Hz9w1ORvjqYYVsOPYLSSrcixuf/pfRwBJfuoxa3QBlIcpWVBl5OL+owz8s/uq2b7+s/sKxvdvoN+ftIxcq++1rp5ErUgfq/0pCaoMy+8XAIx+tp7d0niJOWmx5/aIiIjoP4XTWT1SZeOz+YeRZ4+r7eRQGm3+DTOl6dsFxyCVAM+2jUKgr8Ko4LmOqVRWQOmlsypcrN1R/RBbPFxXmPv/3nmqhHtkXkq69XMEe+KMjdLFwAYREREZ0KWxspSmSioBtAXyNRUsni6VSvD574ft2qcWUYapf1ykEozpHW337RRFdq4Gu0/csdrOcLaHDOlZxj96k1KzsWLHZVHb1QrAl38cgXaIAD9vd7PppEzNzLBGl14qIliZvy1t4eRcpuXXk3BMYENXy0J3B2fB/fVwl6H3U1F2nVGSnpl/UtmqfhjOX39ksL2CnwciIiIqGYXTWf06MT/QcfN+Gr5dcMyBPaOSFFM9EGcuJ0Ej8vepWFoBWLlT3O/wwkqjSLmYYu32SqtlLYBiyw1wusLcjlLa22Zgo3QxsEFERERGCqep0t3p7610RaCPAjUr+yPhWrLJi+kt64djYlxTmy+mmyKVAG8NboiUW8Z5Ue25ndJmKqhRVNP/PmrwuGA6qYNn7hYr+HPnQTqA/Av1oto/zCjytorr0ePARligJ74c3wZLtlzA4s0J0GgFZGbnYcHGBGw8cN1u9UkyHo9hrcr+mDC0KY7G38f/5uanUvjujafg62U9VRURERHZz5NQt0MqASQSSZEu2rtI7ZMeqqw7efGho7tgpHCR8pIIcKgycq2mXtOl1VKF5FqcvWEucPFIlY07DzMwf+1Z5GmsH4MDO9XA4s0XxO2Ag6SKnLGhS5tV3HHLUVtPyyyXSeFdYFYQFR0DG0RERGSWpTodlup36GZ9nLn0EF/8ebjIxcknvNAEzesGY72JwEbB7RQOvtxLynSaouj29l+KrIsAipcGSXdOrdFqEeDjbjWAtGDjeYQHiAuC2Fvy4775e7vj4Jm7FuuT2KPQua6wulIhh4tUgmZ1QxHir8D95Cys2X0ZDWsEF6twPBEREZU8mYsEI3rUFZX6qPCMZXt76/lGqPu4NpfuorPY2SdvPd8IoQEemPTzPtYdcaCCAY5x/WLg87gmW3qWGqqMXGTl5CEjS42cXA3cXV3goZDDw00GL09XiymvHqmycfl2qqg+6I4XU4XZAUCdp7HbceLvBDfyZOeKq/+oS5tV3BkvuY8DG+P7xyAqwhfHzyfijw3xiAz1whuDGwEovZRh5QEDG0RERFQiXKQSxNQIwqv9G1icNdCmQbhRfYqCqXzUasvBCXPBlwEda2DJlgtYsf2i6B+0T5LsXPud1P6+Lh592kWJSpP17cLjaFfLbpsWLenxjA0/Lzf8tuq0xba6QufFCTroiiZ6KvLvttp36g4epeXfEbZ060Us3XoRAT7udpshQkREROKIKSxe8M56AJi/7pzVFD+fvtIScpkLAPvX9JDLpKhbNUB/sVP3XzH7UvC1rDtSNuRpBHy/+ITD+1C4MDuQf+yLmY0hhthaKLcS05HuoAn2uvPA2Ogw7D9912JbXdqs4gQddOcINSP9UTnMG25yF/yxIR73kzNRNdwHUt70ZFcMbBAREVGJMpcyqmDwQlfc2lydiKIomE7LUr0QEmfn8dsY3LkGFm6yPN1cKwDb4oEmZ+6hTcOKpdQ74NHjYuvqPK3oQueWZh1ZozuWlB5y7Dt1x2Twzp4zRIiIiEicwhf4TSl8x/Qv73dAcmom9u7Zi1atW0Emk1lsD9he02NI11qIquBjsgC1uTu4bd0XU3VHrt9VWQ1w6GYYZGTniU5DVFaM6FEbf25IYABHJHuOrdh1fb/4JFwkQPunsxAeJLf+AjtKSs0CAFQM8bIa2CguQRD0hdU93eVIfJSJrGw1ZC4SZOdqcOjcXQT6/vf55MyN4mNgg4iIiEpcwZRRpoIXllJeFVfheiHJqmz4Kt0gSIBHqdlQZeRC6SHH6UsPcfDcPYPgh0QCCM5zXleiklKzcf1euuj2c/45h5YxEaWWiklXPFzs9tbuuVKsAJrupMXDTYZvCtU5KcweM0SIiIhIPFvrbQT7ecBPKUeCFxBVwQdyufWLr7Zuo0ntEFSL8BXdvqjbMfVaXRDGnIIXWGOjw0QFQ8qKOlX88evEDjh7JYlF48swjQCcu5oMmUxWqhfzdecIvkpxabOOxN/HI1U2/LzdbQ485ORq9MGe7Nw8vP7tDoPZVp/OM7wRyl7F3sszBjaIiIioVJRk8MIe2+/QtJLRzBFdkfQDZ+5i86EbyMqxX9FvZ7Tv1B3RbZNSs3Hm0kPE1AgqwR79R3fSEhrgKar9vtN3MXTKBozv38Dm2RSCIOhrbNx+kF4qM0SIiIiIisqW4EjBYIizBDiC/TygCjEfuKGy4fvFJ0v9Yr7ud7qPUlyx7r///a9On6191aWhcpFKkJObJ6rYe3FTX5V3DGwQERERPWYq+BFdLRDR1QIxslc9h9bskAAoC5NHbCmc+b95B9G3fTUM6FgTLlJJkVKOmQs2FVwHACQ+ygSQX8xbTKFzAEjLVBcpVVTBu7FyRB4LusCLWCWRno2IiIjsT2wdDG9PcRdWy4rCsz3Kes0OMeNAjmfvi/mJjzLNzkbK02j1zxXl82drX/VpqBTy/Kn/dmRpP4Hym9aKgQ0iIiIiEQrX7LAW4JgwpDH8vN2x//QdrN17tVgprQJ83DGyVz1M//NI0VdiJ2KDGkD+Rf8FGxOwYvslNK0TgnNXkw0CDpaKa2u0gsnaKIUDPEoPOSQAMrPzZ9P837KTUHrYlrvX1lRRaZn5JxUSyX8nMNb4m8inbc6+U3eMatKwEDkREVHZVJSaHs6k4GyPos7ikLlIIIEE6hIMilgbh0eqbKSm52DmslNlNjhDtkl8lImXv9hqNZgllQCP0kq+erluxoZSYd86ImL200UKjOxZD2GBnkZ1fJz5+8caBjaIiIiIbGCtKHnBouhA/oyPOlUD8OUfRQ9K6C5oy6QS/Lj0hMOLoPdsXQXr9l4VHeTIztVg9wnjNFbmimvvO3XH7H4W3qSpNra+Pw9TsvD3v/FoWCPY6syIfafu4Oflp/L7IgBz/jlrdRZLoK9CP7PEGjGFyC3VqyEiIqLSV5w6GM7EXM2OR6ps/UVdIP/CbsGLq7q75XWvEVtw3RoXieGd+GLGoX71IKdJsfWkunk/DcB/x03h40Wn4AV53YwF3WtUGbm4nZguaoaOVgC+XXDcvjthgsGMDTtSZeRa3U+NNv9mLVOe5FoeDGwQERERFYGpouTmLjK3jqkAaZzE6C58Lw85GtQIMprJoFM4SKIrwm5yJoMNhc69PORIMxGMuX5PhQUbE6y+PjY6vNjBmoJmLjuBrJw8pGeqcS8pA2v3XrXLem2xdOtFLN160eLMCHNBB2sBntHP1hMVeNBoBfy26rTFNt8sOApXmYvBxQPO5iAiIqLSVNRAjj0urMpcJPhgeDN4echw9OBeBPkqbO6DtYLqnN1RssQGtXQX5AGImplREm7eT7M446FgiqjLt1MA5M8Q0QVvyoInuZYHAxtERERExSC2KLouKGEqCKKrp/AwJQuqjFx4K10R6KMwGSQxF1ApWOh8x7FbJk/UdAEMc/1oXi8MGw9ct1ifQjf7wEUqgTROgh+XnDC4yF4Uqgw1Ziwq+buoxCg8i6Tg2MxeY/ouKJ3CMzcUbi54rl01NK8XJqpmxrkrSVZrg+SqtchVG57UmZv5QkRERFQWiamHoQtgmEuro1arkSA+06cRsbM7TP2mfqTKxp2HGZi/9qy+7hrZnzpPi/2n7yIrx3oh7pLy7YJjBseiOk8DucwFAMzWnUm4kYIEkcEbUwGQkkgdZS1A46wY2CAiIiIqJeaCIGKDI9ZeU7DQubVAibl+jOkdbXJWgk7B2Qct64fDQyHH5F/22dR3Z/DrylO4eleFtXuuiE5tpRWADk0qYufxW8jTCMjKya8xsmb3FUgAg1kynu4ytIgOQ0z1IP3Y2FpgvLDfVp22qVYIERERkSM4S10Sa8GP2OiwIhVWr18tEKcuPbRLH3U3STmazEVaIrNbZptJr1Sa8jQCPp5zsETWbWr2SsF6GQBw+XaqXbbzJKakYmCDiIiI6AlTlECJTsv64ZgY19QobVbhtFg60VGBCPBxtzrTwFGe71LLKG2XGMmqHCzaZD0tV2Fbj9w0WmZq2xnZedh6+Ca2Hs5v7+/thgpBSpu3V1BSajaWbLmAwZ1rFms9RERERCXtSahLUpTC6nKZFL2firJbYGPSiGYA4PCaIR8Mb4r0LLVdaqeUd5bqZRTHk5iSioENIiIiIjJgKW1WYWJmeThKoK8CAzrW0Bd6X779InJyNY7ulknJqhwkq3KKvZ4FG88jMtSLKamIiIiISpGY2h3Af8XOraXikkoAicTybAy5TIrIMG+zBd3vPMzAvH/OWlyHzEWCcf1i4KN0M1nAW2yhdz9vd0SGeVvdr7KgpGaXmFNWZtU8iRjYICIiIiIjtsz60M3y+HHpCZtnRpSkgmmzBneuidpV/J/ItFmFzVp9himpiIiIiBxA7EwUMam4AIhO12Vuu7p0WWLWYe55a8EKuUyqX88v73fA2StJZXrmxgfDm8LP2x2PVNm4fDsVf/97vkS3V5aCGkfi7+ORKttkEKsspH+zFQMbRERERFRsulkeizbGY9m2i3DkjVpSCTBhaBOnS5tlLw9TsrB29xX0aFMVAMzWWyEiIiIixxAbACnuhebipvyytR5KsJ8HVCHm25YFft7uqBbhq/93SQc2yhJL+6orku7lIUO6k5wuMbBBRERERHbhIpVgQMfq8Mi5iKsZFbD92G2H9GPCC03QOqaC0fKSTJvVoWlFfb2MsmD2mjNYtCXBqGi5ToCPO0b1rFP6HSMiIiIip/Ik1EPR0c0uIWMFi6RLAUTVSUSgX34B87I6m4OBDSIiIiKyK6kEGNuvPk5dTrLb7IgJQxrDz9tdX/MjNSMHs1efEVXgvCBzxdGLI8DHHWP7NcCJCw/K1GwQS2nBklKz8dVfx1AnHKh0OQn1a4QwdRURERERPZF0sxF0NUnIMi2AT+cf0T+Wy6T45f0OZe69Y2CDiIiIiOzOXrMjLAUrYqPDRRU4L0yXNuvMpYf44o/DSM8qXl2QMb2j4SqTltki6pacuwN8NOsgAnzcMaZ3NIuOExEREVGxiKnLYU/dYivDV+kKqYsUHm4yeHm6QqmQG9SRMDfjoKT7KnORIE9TsjU23nq+EQCUaF0TdZ4WqoxcBjaIiIiIqHwwNzsiwMcdXVpEIjxQCV+lGwQJ8Cg1G6qMXCg95EjPVBvUgjAXrLClwLmp18bUCMKrAxoUORhROOjSsn443hvaBNP/OgJ71wh8vktNhPp7QpWRi/uPMvDP7qt2XX9SajY+//0wJsY1ZXDDDtauXYu3334bWq0W7733Hl588UVHd4mIiIioVBSuy5GXl4e9e/aiTkwTXL+XbteaFnKZFP06VC/yBfeCfX2kysZn8w8jT2OfIMdbzzeCUiHXp3cqKRVDvEo9mFRWMLBBRERERCVGNzuiKDMrSoMu+PLj0hMWUze5u7qgd7so1K0aiNS0HLP70bpBBUACfPnHETNrso2XhyvG948xCjZIIMGa3Vfsso2CZq0+g+b1wsrM+DijvLw8vPXWW9i+fTt8fHzQuHFjPPfccwgIYMF2IiIiKh8K1uVQq9VI8AKa1ApGkJ9nkQMbLlJgZM96CAv01M/GsEfth4J9/XViB5y9klTs2Q9ymRR1qwZYLLpuD7qaIboAjT367kwY2CAiIiKiElWcmRWlQRd8WbLlAtbsvmwQ4PDykKNnm6oY0LGm6Iv9rWMqQBonMZqpEuirwKiedeGjdMP+03fwzx7zsy7cXV3Qp301s9ttUS+sRAIbD1OycO5KUpker7Lu0KFDqFu3LipUyC9g361bN2zatAmDBw92cM+IiIiInMOQrrUQ4p8fbNCllSqNAtbBfh5QhdgWjBjStRaiKviYTX1VEjMpTNUMKUrfnR0DG0RERERU7rlIJRjcuSYGdKxhl9kl1maqRFcLRL2oQKPgh9hASp2qAQjwcS+RYuXJqrJTAN0Rdu3ahenTp+Po0aO4e/cuVq5cid69exu0mTlzJqZPn4579+4hJiYGP/74I5o1awYAuHPnjj6oAQAVKlTA7du3S3MXiIiIiMokMSmT5DIpnm5S0WH1HGxJ62Str7qZFNfvqqymuZK5SCCBBGorbVgE/T8MbBARERERPWbP2SXW1lWcNF32Ks5uin+Bu83Ko4yMDMTExGDkyJHo06eP0fOLFy/GW2+9hV9++QXNmzfHjBkz0KVLFyQkJCA4ONjm7eXk5CAnJ0f/WKVSAchP26BWF6+wvS102yrNbVLRcKycC8fLeXCsnAvHy3kUHCs/pRz/985TFlM0eXu6wk8pd9jYFuzjo7QcZGQZ90OpkMPXy01UX/2UcvhVD8DMCdb3G4DVNkG+CgCmj30PN2mJ1drIy8srlTGxZRsMbBAREREROUhxAinmirMXR6BvfsH28qxbt27o1q2b2ee//fZbjB49GiNGjAAA/PLLL1i3bh3mzp2L999/H+Hh4QYzNG7fvq2fzWHK559/jmnTphkt37RpEzw8Sv9OvM2bN5f6NqloOFbOhePlPDhWzoXj5TyepLHKAHDf0Z0wo28jIDkD2HIO0Ar2W+/ePXuR4GW/9ZmTmZkpui0DG0RERERETqrgrI+HKVk4efEBth65WeT1jX62HguHW5Cbm4ujR49i4sSJ+mVSqRQdO3bE/v37AQDNmjXDmTNncPv2bfj4+GDDhg2YPHmy2XVOnDgRb731lv6xSqVCxYoV0blzZ3h7e5fczhSiVquxefNmdOrUCXK5vNS2S7bjWDkXjpfz4Fg5F46X8+BYOUbflCycu5qM7xefLPa65DIpunV5Sj9bpCTpZi+LwcAGEREREZETKzjro32TimhWN9Rk4fK2DcKx8/htk7M7An0VGP1sPbSsH15q/XZGDx8+hEajQUhIiMHykJAQnD9/HgAgk8nwzTffoH379tBqtXj33XcREGB+Foybmxvc3NyMlsvlcoec/Dtqu2Q7jpVz4Xg5D46Vc+F4OQ+OVekKD5JDJpMVKzWVI2p62HKMMLBBRERERPQEsVS7Y1j3uvrZHY9UWbhyKR4d2jZH/RohnKlhR7169UKvXr0c3Q0iIiIiKsd0xcvN1e14pMq/4cmvQI29vLw87N2zF61at4K/j0eZLlLOwAYRERER0RPGXO2OgsvVajXWp8WjXpS4guUEBAYGwsXFBffvG2ZVvn//PkJDQx3UKyIiIiIi04L9bAtOqNVqJHgBURV8yvwMG6mjO0BEREREROQMXF1d0bhxY2zdulW/TKvVYuvWrYiNjXVgz4iIiIiIyhfO2CAiIiIiInosPT0dly5d0j++evUqTpw4AX9/f1SqVAlvvfUW4uLi0KRJEzRr1gwzZsxARkYGRowY4cBeExERERGVLwxsEBERERERPXbkyBG0b99e//itt94CAMTFxWH+/PkYOHAgHjx4gI8++gj37t1DgwYN8O+//xoVFCciIiIiopLDwAYREREREdFj7dq1gyAIFtuMHz8e48ePL6UeERERERFRYayxQUREREREREREREREToOBDSIiIiIiIiIiIiIichoMbBARERERERERERERkdNgYIOIiIiIiIiIiIiIiJwGAxtEREREREREREREROQ0GNggIiIiIiIiIiIiIiKnwcAGERERERERERERERE5DQY2iIiIiIiIiIiIiIjIacgc3QEiIiIiIiIypFaroVarS3V7Bf9LZRfHyrlwvJwHx8q5cLycB8fKuTh6vGzZLgMbREREREREDjZz5kzMnDkTGo0GALBp0yZ4eHiUej82b95c6tukouFYOReOl/PgWDkXjpfz4Fg5F0eNV2Zmpui2DGw4kCAIAACVSlWq21Wr1cjMzIRKpYJcLi/VbZPtOF7Og2PlXDhezoNj5Vw4Xs7D0WOl+w2s+01c3o0bNw7jxo1DamoqfH19ERsbCy8vr1Lbvlqtxvbt29G+fXt+dss4jpVz4Xg5D46Vc+F4OQ+OlXNx9HilpaUBEHeOwMCGA+kGqmLFig7uCRERERGRY6SlpcHHx8fR3SgzdOcIVapUcXBPiIiIiIgcQ8w5gkTgLVIOo9VqcefOHXh5eUEikZTadlUqFSpWrIibN2/C29u71LZLRcPxch4cK+fC8XIeHCvnwvFyHo4eK0EQkJaWhvDwcEil0lLfflnFcwSyhmPlXDhezoNj5Vw4Xs6DY+VcHD1etpwjcMaGA0mlUkRERDhs+97e3vxCcSIcL+fBsXIuHC/nwbFyLhwv5+HIseJMDWM8RyCxOFbOhePlPDhWzoXj5Tw4Vs7FGc4ReGsUERERERERERERERE5DQY2iIiIiIiIiIiIiIjIaTCwUQ65ublhypQpcHNzc3RXSASOl/PgWDkXjpfz4Fg5F46X8+BYUUE8HpwHx8q5cLycB8fKuXC8nAfHyrk403ixeDgRERERERERERERETkNztggIiIiIiIiIiIiIiKnwcAGERERERERERERERE5DQY2iIiIiIiIiIiIiIjIaTCwQUREREREREREREREToOBjXJo5syZqFy5Mtzd3dG8eXMcOnTI0V0q96ZOnQqJRGLwV6tWLf3z2dnZGDduHAICAqBUKtG3b1/cv3/fgT0uP3bt2oWePXsiPDwcEokEq1atMnheEAR89NFHCAsLg0KhQMeOHXHx4kWDNsnJyRgyZAi8vb3h6+uLUaNGIT09vRT3ovywNl7Dhw83+qx17drVoA3Hq3R8/vnnaNq0Kby8vBAcHIzevXsjISHBoI2Y774bN26ge/fu8PDwQHBwMCZMmIC8vLzS3JUnnpixateundFn6+WXXzZow7EqHT///DPq168Pb29veHt7IzY2Fhs2bNA/z88VmcLzg7KJ5whlF88RnAvPEZwHzxGcB88RnMuTeo7AwEY5s3jxYrz11luYMmUKjh07hpiYGHTp0gWJiYmO7lq5V7duXdy9e1f/t2fPHv1zb775Jv755x8sXboUO3fuxJ07d9CnTx8H9rb8yMjIQExMDGbOnGny+a+++go//PADfvnlFxw8eBCenp7o0qULsrOz9W2GDBmCs2fPYvPmzVi7di127dqFMWPGlNYulCvWxgsAunbtavBZW7hwocHzHK/SsXPnTowbNw4HDhzA5s2boVar0blzZ2RkZOjbWPvu02g06N69O3Jzc7Fv3z78/vvvmD9/Pj766CNH7NITS8xYAcDo0aMNPltfffWV/jmOVemJiIjAF198gaNHj+LIkSN4+umn8eyzz+Ls2bMA+LkiYzw/KNt4jlA28RzBufAcwXnwHMF58BzBuTyx5wgClSvNmjUTxo0bp3+s0WiE8PBw4fPPP3dgr2jKlClCTEyMyedSUlIEuVwuLF26VL8sPj5eACDs37+/lHpIgiAIAISVK1fqH2u1WiE0NFSYPn26fllKSorg5uYmLFy4UBAEQTh37pwAQDh8+LC+zYYNGwSJRCLcvn271PpeHhUeL0EQhLi4OOHZZ581+xqOl+MkJiYKAISdO3cKgiDuu2/9+vWCVCoV7t27p2/z888/C97e3kJOTk7p7kA5UnisBEEQnnrqKeH11183+xqOlWP5+fkJs2fP5ueKTOL5QdnFcwTnwHME58JzBOfCcwTnwXME5/MknCNwxkY5kpubi6NHj6Jjx476ZVKpFB07dsT+/fsd2DMCgIsXLyI8PBxVq1bFkCFDcOPGDQDA0aNHoVarDcatVq1aqFSpEsfNwa5evYp79+4ZjI2Pjw+aN2+uH5v9+/fD19cXTZo00bfp2LEjpFIpDh48WOp9JmDHjh0IDg5GzZo18corryApKUn/HMfLcVJTUwEA/v7+AMR99+3fvx/R0dEICQnRt+nSpQtUKpX+zhOyv8JjpfP3338jMDAQ9erVw8SJE5GZmal/jmPlGBqNBosWLUJGRgZiY2P5uSIjPD8o+3iO4Hx4juCceI5QNvEcwXnwHMF5PEnnCDKHbZlK3cOHD6HRaAwOQgAICQnB+fPnHdQrAoDmzZtj/vz5qFmzJu7evYtp06ahTZs2OHPmDO7duwdXV1f4+voavCYkJAT37t1zTIcJAPTvv6nPlO65e/fuITg42OB5mUwGf39/jp8DdO3aFX369EGVKlVw+fJlfPDBB+jWrRv2798PFxcXjpeDaLVavPHGG2jVqhXq1asHAKK+++7du2fy86d7juzP1FgBwPPPP4/IyEiEh4fj1KlTeO+995CQkIAVK1YA4FiVttOnTyM2NhbZ2dlQKpVYuXIl6tSpgxMnTvBzRQZ4flC28RzBOfEcwfnwHKFs4jmC8+A5gnN4Es8RGNggKgO6deum/3f9+vXRvHlzREZGYsmSJVAoFA7sGdGTZdCgQfp/R0dHo379+oiKisKOHTvQoUMHB/asfBs3bhzOnDljkDecyiZzY1Uwx3R0dDTCwsLQoUMHXL58GVFRUaXdzXKvZs2aOHHiBFJTU7Fs2TLExcVh586dju4WEdmI5whEpYPnCGUTzxGcB88RnMOTeI7AVFTlSGBgIFxcXIyq2t+/fx+hoaEO6hWZ4uvrixo1auDSpUsIDQ1Fbm4uUlJSDNpw3BxP9/5b+kyFhoYaFd/My8tDcnIyx68MqFq1KgIDA3Hp0iUAHC9HGD9+PNauXYvt27cjIiJCv1zMd19oaKjJz5/uObIvc2NlSvPmzQHA4LPFsSo9rq6uqFatGho3bozPP/8cMTEx+P777/m5IiM8P3AuPEdwDjxHcH48R3A8niM4D54jOI8n8RyBgY1yxNXVFY0bN8bWrVv1y7RaLbZu3YrY2FgH9owKS09Px+XLlxEWFobGjRtDLpcbjFtCQgJu3LjBcXOwKlWqIDQ01GBsVCoVDh48qB+b2NhYpKSk4OjRo/o227Ztg1ar1f9PnRzn1q1bSEpKQlhYGACOV2kSBAHjx4/HypUrsW3bNlSpUsXgeTHffbGxsTh9+rTBiebmzZvh7e2NOnXqlM6OlAPWxsqUEydOAIDBZ4tj5TharRY5OTn8XJERnh84F54jOAeeIzg/niM4Ds8RnAfPEZzfE3GO4LCy5eQQixYtEtzc3IT58+cL586dE8aMGSP4+voaVLWn0vf2228LO3bsEK5evSrs3btX6NixoxAYGCgkJiYKgiAIL7/8slCpUiVh27ZtwpEjR4TY2FghNjbWwb0uH9LS0oTjx48Lx48fFwAI3377rXD8+HHh+vXrgiAIwhdffCH4+voKq1evFk6dOiU8++yzQpUqVYSsrCz9Orp27So0bNhQOHjwoLBnzx6hevXqwuDBgx21S080S+OVlpYmvPPOO8L+/fuFq1evClu2bBEaNWokVK9eXcjOztavg+NVOl555RXBx8dH2LFjh3D37l39X2Zmpr6Nte++vLw8oV69ekLnzp2FEydOCP/++68QFBQkTJw40RG79MSyNlaXLl0SPv74Y+HIkSPC1atXhdWrVwtVq1YV2rZtq18Hx6r0vP/++8LOnTuFq1evCqdOnRLef/99QSKRCJs2bRIEgZ8rMsbzg7KL5whlF88RnAvPEZwHzxGcB88RnMuTeo7AwEY59OOPPwqVKlUSXF1dhWbNmgkHDhxwdJfKvYEDBwphYWGCq6urUKFCBWHgwIHCpUuX9M9nZWUJY8eOFfz8/AQPDw/hueeeE+7evevAHpcf27dvFwAY/cXFxQmCIAharVaYPHmyEBISIri5uQkdOnQQEhISDNaRlJQkDB48WFAqlYK3t7cwYsQIIS0tzQF78+SzNF6ZmZlC586dhaCgIEEulwuRkZHC6NGjjS7ccLxKh6lxAiDMmzdP30bMd9+1a9eEbt26CQqFQggMDBTefvttQa1Wl/LePNmsjdWNGzeEtm3bCv7+/oKbm5tQrVo1YcKECUJqaqrBejhWpWPkyJFCZGSk4OrqKgQFBQkdOnTQn7AIAj9XZBrPD8omniOUXTxHcC48R3AePEdwHjxHcC5P6jmCRBAEwf7zQIiIiIiIiIiIiIiIiOyPNTaIiIiIiIiIiIiIiMhpMLBBREREREREREREREROg4ENIiIiIiIiIiIiIiJyGgxsEBERERERERERERGR02Bgg4iIiIiIiIiIiIiInAYDG0RERERERERERERE5DQY2CAiIiIiIiIiIiIiIqfBwAYRERERERERERERETkNBjaIiIhsJJFIsGrVKkd3g4iIiIiIygieIxARlS4GNoiIyKkMHz4cEonE6K9r166O7hoRERERETkAzxGIiMofmaM7QEREZKuuXbti3rx5Bsvc3Nwc1BsiIiIiInI0niMQEZUvnLFBREROx83NDaGhoQZ/fn5+APKngP/888/o1q0bFAoFqlatimXLlhm8/vTp03j66aehUCgQEBCAMWPGID093aDN3LlzUbduXbi5uSEsLAzjx483eP7hw4d47rnn4OHhgerVq2PNmjUlu9NERERERGQWzxGIiMoXBjaIiOiJM3nyZPTt2xcnT57EkCFDMGjQIMTHxwMAMjIy0KVLF/j5+eHw4cNYunQptmzZYnBS8vPPP2PcuHEYM2YMTp8+jTVr1qBatWoG25g2bRoGDBiAU6dO4ZlnnsGQIUOQnJxcqvtJRERERETi8ByBiOjJIhEEQXB0J4iIiMQaPnw4/vrrL7i7uxss/+CDD/DBBx9AIpHg5Zdfxs8//6x/rkWLFmjUqBF++uknzJo1C++99x5u3rwJT09PAMD69evRs2dP3LlzByEhIahQoQJGjBiBTz75xGQfJBIJPvzwQ/zvf/8DkH8ipFQqsWHDBubxJSIiIiIqZTxHICIqf1hjg4iInE779u0NTkoAwN/fX//v2NhYg+diY2Nx4sQJAEB8fDxiYmL0JywA0KpVK2i1WiQkJEAikeDOnTvo0KGDxT7Ur19f/29PT094e3sjMTGxqLtERERERETFwHMEIqLyhYENIiJyOp6enkbTvu1FoVCIaieXyw0eSyQSaLXakugSERERERFZwXMEIqLyhTU2iIjoiXPgwAGjx7Vr1wYA1K5dGydPnkRGRob++b1790IqlaJmzZrw8vJC5cqVsXXr1lLtMxERERERlRyeIxARPVk4Y4OIiJxOTk4O7t27Z7BMJpMhMDAQALB06VI0adIErVu3xt9//41Dhw5hzpw5AIAhQ4ZgypQpiIuLw9SpU/HgwQO8+uqrGDp0KEJCQgAAU6dOxcsvv4zg4GB069YNaWlp2Lt3L1599dXS3VEiIiIiIhKF5whEROULAxtEROR0/v33X4SFhRksq1mzJs6fPw8AmDZtGhYtWoSxY8ciLCwMCxcuRJ06dQAAHh4e2LhxI15//XU0bdoUHh4e6Nu3L7799lv9uuLi4pCdnY3vvvsO77zzDgIDA9GvX7/S20EiIiIiIrIJzxGIiMoXiSAIgqM7QUREZC8SiQQrV65E7969Hd0VIiIiIiIqA3iOQET05GGNDSIiIiIiIiIiIiIichoMbBARERERERERERERkdNgKioiIiIiIiIiIiIiInIanLFBREREREREREREREROg4ENIiIiIiIiIiIiIiJyGgxsEBERERERERERERGR02Bgg4iIiIiIiIiIiIiInAYDG0RERERERERERERE5DQY2CAiIiIiIiIiIiIiIqfBwAYRERERERERERERETkNBjaIiIiIiIiIiIiIiMhpMLBBREREREREREREREROg4ENIiIiIiIiIiIiIiJyGgxsEBERERERERERERGR02Bgg4iIiIiIiIiIiIiInAYDG0RERERERERERERE5DQY2CAiIiIiIiIiIiIiIqfBwAYR0RNkx44dkEgk2LFjh93WOXXqVEgkErutr6RJJBJMnTrVLuu6du0aJBIJ5s+fr19m6v2oXLkyhg8fbpdt6gwfPhyVK1e26zqJiIiIiBxJ7O9rc+z5W1+nXbt2aNeunV3XSUREJY+BDSIiM+bPnw+JRIIjR44YLE9NTUWzZs3g7u6Of//910G9Kx8qV64MiUQCiUQCqVQKX19fREdHY8yYMTh48KDdtrNgwQLMmDHDbusT686dO5g6dSpOnDhR6ts2R3ey+fXXXzu6K0RERETkQL169YKHhwfS0tLMthkyZAhcXV2RlJRUij2z3blz5zB16lRcu3bN0V0pESkpKXB3d4dEIkF8fLzJNsOHD9efW0kkEnh7eyMmJgbffPMNcnJySrnHRETFx8AGEZENVCoVOnfujFOnTmHlypXo2rWro7v0xGvQoAH+/PNP/PHHH/j888/Rvn17/PPPP2jRogXeeusto/ZZWVn48MMPbdqGucBGZGQksrKyMHTo0KJ236I7d+5g2rRpJgMbs2bNQkJCQolsl4iIiIjImiFDhiArKwsrV640+XxmZiZWr16Nrl27IiAgoMjb+fDDD5GVlVXk14tx7tw5TJs2zWRgY9OmTdi0aVOJbr+kLV26FBKJBKGhofj777/NtnNzc8Off/6JP//8E5999hn8/f3xzjvvIC4urhR7S0RkHzJHd4CIyFmkpaWhS5cuOHHiBFasWIFu3bo5ukvlQoUKFfDCCy8YLPvyyy/x/PPP47vvvkP16tXxyiuv6J9zd3e327YlEold12cLuVzukO0SEREREQH5Mza8vLywYMECDBs2zOj51atXIyMjA0OGDCnWdmQyGWQyx12ecnV1ddi27eWvv/7CM888g8jISCxYsACffPKJyXYymczg3Grs2LFo3rw5Fi9ejG+//Rbh4eGl1WUiomLjjA0iIhHS09PRtWtXHDt2DMuXL0f37t0Nnh8+fDiUSiVu376N3r17Q6lUIigoCO+88w40Go1B24yMDLz99tuoWLEi3NzcULNmTXz99dcQBEHfpk+fPmjUqJHB63r27AmJRII1a9bolx08eBASiQQbNmyw2P+DBw+ia9eu8PHxgYeHB5566ins3bvXqN2ePXvQtGlTuLu7IyoqCr/++qvJ9WVlZeG1115DYGAgvLy80KtXL9y+fdtkztvbt29j5MiRCAkJgZubG+rWrYu5c+da7K81CoUCf/75J/z9/fHpp58avHeF+5CWloY33ngDlStXhpubG4KDg9GpUyccO3YMQH5O3XXr1uH69ev6adm62hamcgCLkZycjHfeeQfR0dFQKpXw9vZGt27dcPLkSX2bHTt2oGnTpgCAESNG6Let25apGhtijh3dezB+/HisWrUK9erV07/v9kydlpiYiFGjRiEkJATu7u6IiYnB77//btRu0aJFaNy4Mby8vODt7Y3o6Gh8//33+ufVajWmTZuG6tWrw93dHQEBAWjdujU2b95ssJ7z58+jX79+8Pf3h7u7O5o0aWLwWbBlXURERERknUKhQJ8+fbB161YkJiYaPb9gwQL9uYCY37/mmKqxkZOTgzfffBNBQUH6bdy6dcvotdevX8fYsWNRs2ZNKBQKBAQEoH///gYzM+bPn4/+/fsDANq3b6//3a2rS2iqxoaY37oFU7j+9ttviIqKgpubG5o2bYrDhw9b3W9d6uM9e/bgtddeQ1BQEHx9ffHSSy8hNzcXKSkpGDZsGPz8/ODn54d3333X6Hc/ANy4cQO7d+/GoEGDMGjQIFy9ehX79u2zun0AkEql+n1/UtN0EdGTizM2iIisyMjIQLdu3XD48GEsW7YMPXr0MNlOo9GgS5cuaN68Ob7++mts2bIF33zzDaKiovQzCgRBQK9evbB9+3aMGjUKDRo0wMaNGzFhwgTcvn0b3333HQCgTZs2WL16NVQqFby9vSEIAvbu3QupVIrdu3ejV69eAIDdu3dDKpWiVatWZvu/bds2dOvWDY0bN8aUKVMglUoxb948PP3009i9ezeaNWsGADh9+jQ6d+6MoKAgTJ06FXl5eZgyZQpCQkKM1jl8+HAsWbIEQ4cORYsWLbBz506jYA8A3L9/Hy1atNBfaA8KCsKGDRswatQoqFQqvPHGGzaNRUFKpRLPPfcc5syZg3PnzqFu3bom27388stYtmwZxo8fjzp16iApKQl79uxBfHw8GjVqhEmTJiE1NRW3bt3Sv/9KpbLI/QKAK1euYNWqVejfvz+qVKmC+/fv49dff8VTTz2Fc+fOITw8HLVr18bHH3+Mjz76CGPGjEGbNm0AAC1btjS5TrHHjs6ePXuwYsUKjB07Fl5eXvjhhx/Qt29f3Lhxo1ipAoD8wFa7du1w6dIljB8/HlWqVMHSpUsxfPhwpKSk4PXXXwcAbN68GYMHD0aHDh3w5ZdfAgDi4+Oxd+9efZupU6fi888/x4svvohmzZpBpVLhyJEjOHbsGDp16gQAOHv2LFq1aoUKFSrg/fffh6enJ5YsWYLevXtj+fLleO6550Svi4iIiIjEGzJkCH7//XcsWbIE48eP1y9PTk7Gxo0bMXjwYCgUCpw9e9bq719bvPjii/jrr7/w/PPPo2XLlti2bZvJ843Dhw9j3759GDRoECIiInDt2jX8/PPPaNeuHc6dOwcPDw+0bdsWr732Gn744Qd88MEHqF27NgDo/1uY2N+6OgsWLEBaWhpeeuklSCQSfPXVV+jTpw+uXLkiahb2q6++itDQUEybNg0HDhzAb7/9Bl9fX+zbtw+VKlXCZ599hvXr12P69OmoV6+e0eyZhQsXwtPTEz169IBCoUBUVBT+/vtvs+cVhV2+fBkAin2OQERU6gQiIjJp3rx5AgAhMjJSkMvlwqpVq8y2jYuLEwAIH3/8scHyhg0bCo0bN9Y/XrVqlQBA+OSTTwza9evXT5BIJMKlS5cEQRCEw4cPCwCE9evXC4IgCKdOnRIACP379xeaN2+uf12vXr2Ehg0b6h9v375dACBs375dEARB0Gq1QvXq1YUuXboIWq1W3y4zM1OoUqWK0KlTJ/2y3r17C+7u7sL169f1y86dOye4uLgIBf93cfToUQGA8MYbbxjsw/DhwwUAwpQpU/TLRo0aJYSFhQkPHz40aDto0CDBx8dHyMzMNPFu/icyMlLo3r272ee/++47AYCwevVq/bLCffDx8RHGjRtncTvdu3cXIiMjjZZfvXpVACDMmzdPv2zKlClC4f99RkZGCnFxcfrH2dnZgkajMVqXm5ubwTGiG+eC69eJi4sz6JPYY0cQ8t8DV1dXg2UnT54UAAg//vijqbfAaJ+nT59uts2MGTMEAMJff/2lX5abmyvExsYKSqVSUKlUgiAIwuuvvy54e3sLeXl5ZtcVExNjcYwFQRA6dOggREdHC9nZ2fplWq1WaNmypVC9enWb1kVERERE4uXl5QlhYWFCbGyswfJffvlFACBs3LhREATxv3/F/L4+ceKEAEAYO3aswfqef/55o9/6ps4n9u/fLwAQ/vjjD/2ypUuXGpwnFfTUU08JTz31lP6x2N+6un0JCAgQkpOT9W1Xr14tABD++ecfo20VpDvfLHyuFhsbK0gkEuHll1/WL8vLyxMiIiIM+qkTHR0tDBkyRP/4gw8+EAIDAwW1Wm3QLi4uTvD09BQePHggPHjwQLh06ZLw2WefCRKJRKhfv77FvhIRlUVMRUVEZMX9+/fh7u6OihUrWm378ssvGzxu06YNrly5on+8fv16uLi44LXXXjNo9/bbb0MQBH1KqYYNG0KpVGLXrl0A8mdmREREYNiwYTh27BgyMzMhCAL27Nmjv9PflBMnTuDixYt4/vnnkZSUhIcPH+Lhw4fIyMhAhw4dsGvXLmi1Wmg0GmzcuBG9e/dGpUqV9K+vXbs2unTpYrBOXTqjsWPHGix/9dVXDR4LgoDly5ejZ8+eEARBv+2HDx+iS5cuSE1N1aeDKirdzIq0tDSzbXx9fXHw4EHcuXOnWNuyhZubG6TS/P/FajQaJCUlQalUombNmkXeZ7HHjk7Hjh0RFRWlf1y/fn14e3sbHI9FtX79eoSGhmLw4MH6ZXK5HK+99hrS09Oxc+dOAPnvfUZGhsVUUL6+vjh79iwuXrxo8vnk5GRs27YNAwYMQFpamv4YSkpKQpcuXXDx4kXcvn1b1LqIiIiIyDYuLi4YNGgQ9u/fb5CqaMGCBQgJCUGHDh0A2Pf37/r16wHA6HevqdneCoVC/2+1Wo2kpCRUq1YNvr6+xfrdLea3rs7AgQPh5+enf6w7PxP7u3vUqFEGqbiaN28OQRAwatQo/TIXFxc0adLEaJ2nTp3C6dOnDfo6ePBgPHz4EBs3bjTaVkZGBoKCghAUFIRq1arhgw8+QGxsrNkC8UREZRkDG0REVvz6669wdXVF165dkZCQYLadu7s7goKCDJb5+fnh0aNH+sfXr19HeHg4vLy8DNrppkFfv34dQP4P19jYWOzevRtAfmCjTZs2aN26NTQaDQ4cOIBz584hOTnZYmBDd4E3Li5O/wNW9zd79mzk5OQgNTUVDx48QFZWFqpXr260jpo1axo8vn79OqRSKapUqWKwvFq1agaPHzx4gJSUFPz2229G2x4xYgQAmMzVa4v09HQAMHo/C/rqq69w5swZVKxYEc2aNcPUqVPtcnHfEq1Wqy9s7ubmhsDAQAQFBeHUqVNITU0t0jrFHjs6BQNUOoWPx6K6fv06qlevrj95NdeXsWPHokaNGujWrRsiIiIwcuRIozofH3/8MVJSUlCjRg1ER0djwoQJOHXqlP75S5cuQRAETJ482eg4mjJlCoD/jiNr6yIiIiIi2+mKgy9YsAAAcOvWLX1NBxcXFwD2/f2rO98oeJMOYHxeAuSnjfroo4/0Neh0201JSSnW724xv3V1Cv/u1gU5xP7uLvx6Hx8fADC6sc7Hx8donX/99Rc8PT1RtWpVXLp0CZcuXYK7uzsqV66Mv//+22hb7u7u2Lx5MzZv3oxdu3bh5s2b2Lt3L6pWrSqqr0REZQlrbBARWVGnTh2sX78eHTp0QKdOnbB3716Tszd0P+rtpXXr1vj000+RnZ2N3bt3Y9KkSfD19UW9evWwe/dufe0LS4ENrVYLAJg+fToaNGhgso1SqUROTo5d+15w2y+88ALi4uJMtqlfv36xtnHmzBkAxkGVggYMGIA2bdpg5cqV2LRpE6ZPn44vv/wSK1asQLdu3Yq1fXM+++wzTJ48GSNHjsT//vc/+Pv7QyqV4o033tC/LyXN3PEomCg4WFKCg4Nx4sQJbNy4ERs2bMCGDRswb948DBs2TF98sW3btrh8+TJWr16NTZs2Yfbs2fjuu+/wyy+/4MUXX9S/X++8847R7CEd3fhbWxcRERER2a5x48aoVasWFi5ciA8++AALFy6EIAj6gAfguN+/r776KubNm4c33ngDsbGx8PHxgUQiwaBBg5zmd7e515taXnCdgiBg4cKFyMjIQJ06dYzaJiYmIj093aB+oIuLCzp27CiqX0REZR0DG0REIjRr1gyrVq1C9+7d0alTJ+zevdtodoYYkZGR2LJlC9LS0gzuvD9//rz+eZ02bdogNzcXCxcuxO3bt/UBjLZt2+oDGzVq1DBZ3FtHd5eTt7e3xR+wQUFBUCgUJlP4FJ6lEhkZCa1Wi6tXrxrM8Lh06ZLROr28vKDRaErkx3N6ejpWrlyJihUrmi38pxMWFoaxY8di7NixSExMRKNGjfDpp5/qAxsFp37bw7Jly9C+fXvMmTPHYHlKSgoCAwP1j23Zri3HTkmLjIzEqVOnoNVqDe5kM9UXV1dX9OzZEz179oRWq8XYsWPx66+/YvLkyfqAhL+/P0aMGIERI0YgPT0dbdu2xdSpU/Hiiy/q7x6Ty+WijiNL6yIiIiKiohkyZAgmT56MU6dOYcGCBahevTqaNm2qf17s718xdOcbly9fNpilYWr2/LJlyxAXF4dvvvlGvyw7OxspKSkG7Wz93S32t64j7dy5E7du3cLHH39sdD706NEjjBkzBqtWrcILL7zgoB4SEZUspqIiIhKpQ4cOWLhwIS5duoSuXbtCpVLZvI5nnnkGGo0G//d//2ew/LvvvoNEIjGYQdC8eXPI5XJ8+eWX8Pf3R926dQHkBzwOHDiAnTt3WpytAeTfXRUVFYWvv/5an7apoAcPHgDIv3OnS5cuWLVqFW7cuKF/Pj4+3ig3q+6u+Z9++slg+Y8//mjw2MXFBX379sXy5cv1MytMbbsosrKyMHToUCQnJ2PSpElmT1Q0Go3RFPTg4GCEh4cbzFLx9PQs8lR1U1xcXIzu0Fq6dKm+FkTB7QIwOvEyxZZjp6Q988wzuHfvHhYvXqxflpeXhx9//BFKpRJPPfUUACApKcngdVKpVD9LR/f+F26jVCpRrVo1/fPBwcFo164dfv31V9y9e9eoLwWPI2vrIiIiIqKi0c3O+Oijj3DixAmD2RqA+N+/Yuh+1/7www8Gy2fMmGHU1tR2f/zxR2g0GoNltv7uFvNb19F0aagmTJiAfv36GfyNHj0a1atXN5mOiojoScEZG0RENnjuuecwa9YsjBw5Er169cK///4Ld3d30a/v2bMn2rdvj0mTJuHatWuIiYnBpk2bsHr1arzxxhsGeWQ9PDzQuHFjHDhwAD179tRfvG/bti0yMjKQkZFhNbAhlUoxe/ZsdOvWDXXr1sWIESNQoUIF3L59G9u3b4e3tzf++ecfAMC0adPw77//ok2bNhg7dqz+x3vdunUN6hQ0btwYffv2xYwZM5CUlIQWLVpg586duHDhAgDDu6G++OILbN++Hc2bN8fo0aNRp04dJCcn49ixY9iyZQuSk5Otvme3b9/GX3/9BSB/lsa5c+ewdOlS3Lt3D2+//TZeeukls69NS0tDREQE+vXrh5iYGCiVSmzZsgWHDx82uKurcePGWLx4Md566y00bdoUSqUSPXv2tNo3c3r06IGPP/4YI0aMQMuWLXH69Gn8/fffRrlro6Ki4Ovri19++QVeXl7w9PRE8+bNjeqXALYdO/awdetWZGdnGy3v3bs3xowZg19//RXDhw/H0aNHUblyZSxbtgx79+7FjBkz9DNKXnzxRSQnJ+Ppp59GREQErl+/jh9//BENGjTQ31VWp04dtGvXDo0bN4a/vz+OHDmCZcuWYfz48fptzpw5E61bt0Z0dDRGjx6NqlWr4v79+9i/fz9u3bqFkydPil4XEREREdmuSpUqaNmyJVavXg0ARoENsb9/xWjQoAEGDx6Mn376CampqWjZsiW2bt1qNENct90///wTPj4+qFOnDvbv348tW7YgICDAaJ0uLi748ssvkZqaCjc3Nzz99NMIDg42WqfY37qOlJOTg+XLl6NTp05mz0d79eqF77//HomJiSb3k4jI6QlERGTSvHnzBADC4cOHjZ77+uuvBQBCjx49BLVaLcTFxQmenp5G7aZMmSIU/qpNS0sT3nzzTSE8PFyQy+VC9erVhenTpwtardbo9RMmTBAACF9++aXB8mrVqgkAhMuXLxss3759uwBA2L59u8Hy48ePC3369BECAgIENzc3ITIyUhgwYICwdetWg3Y7d+4UGjduLLi6ugpVq1YVfvnlF5P7kJGRIYwbN07w9/cXlEql0Lt3byEhIUEAIHzxxRcGbe/fvy+MGzdOqFixoiCXy4XQ0FChQ4cOwm+//Wa0v4VFRkYKAAQAgkQiEby9vYW6desKo0ePFg4ePGjyNQCEKVOmCIIgCDk5OcKECROEmJgYwcvLS/D09BRiYmKEn376yeA16enpwvPPPy/4+voKAITIyEhBEATh6tWrAgBh3rx5+ram3o/IyEghLi5O/zg7O1t4++23hbCwMEGhUAitWrUS9u/fLzz11FPCU089ZfDa1atXC3Xq1BFkMpnBtuLi4vT90BF77AAQxo0bZ/L9LNhPU3T7bO7vzz//FAQhf1xHjBghBAYGCq6urkJ0dLTB+yQIgrBs2TKhc+fOQnBwsODq6ipUqlRJeOmll4S7d+/q23zyySdCs2bNBF9fX0GhUAi1atUSPv30UyE3N9dgXZcvXxaGDRsmhIaGCnK5XKhQoYLQo0cPYdmyZTavi4iIiIhsN3PmTAGA0KxZM6PnxP7+Ffv7OisrS3jttdeEgIAAwdPTU+jZs6dw8+ZNg9/6giAIjx490v8mVSqVQpcuXYTz58+b/N07a9YsoWrVqoKLi4vBOZOp3+hifuvq9mX69OlG70fhfppi7nxT9348ePDAYHnBc87ly5cLAIQ5c+aYXf+OHTsEAML3339v9HoioieBRBBKsYooERE9sU6cOIGGDRvir7/+MrqDi4iIiIiIiIiIyF5YY4OIiGyWlZVltGzGjBmQSqVo27atA3pERERERERERETlBWtsEBGRzb766iscPXoU7du3h0wmw4YNG7BhwwaMGTMGFStWdHT3iIiIiIiIiIjoCcZUVEREZLPNmzdj2rRpOHfuHNLT01GpUiUMHToUkyZNgkzGmDkREREREREREZUcBjaIiIiIiIiIiIiIiMhpsMYGERERERERERERERE5DeYLcSCtVos7d+7Ay8sLEonE0d0hIiIiIio1giAgLS0N4eHhkEp5v5UOzxGIiIiIqLyy5RyBgQ0HunPnDovsEhEREVG5dvPmTURERDi6G2UGzxGIiIiIqLwTc47AwIYDeXl5AcgfKG9v71LbrlqtxqZNm9C5c2fI5fJS2y4VDcfLeXCsnAvHy3lwrJwLx8t5OHqsVCoVKlasqP9NTPl4jkDWcKycC8fLeXCsnAvHy3lwrJyLo8fLlnMEBjYcSDe13Nvbu9RPWjw8PODt7c0vFCfA8XIeHCvnwvFyHhwr58Lxch5lZayYbskQzxHIGo6Vc+F4OQ+OlXPheDkPjpVzKSvjJeYcgclsiYiIiIiIiIiIiIjIaTCwQUREREREREREREREToOBDSIiIiIiIiIiIiIichqssUFERERENtFoNFCr1SafU6vVkMlkyM7OhkajKeWekS1KY6xcXV0hlfJeqpJg6XNYFPzsOg9nGiu5XA4XFxdHd4OIiIieQAxsEBEREZEogiDg3r17SElJsdgmNDQUN2/eZFHoMq40xkoqlaJKlSpwdXUtkfWXR2I+h0VdLz+7zsHZxsrX1xehoaFO0VciIiJyHgxsEBEREZEououpwcHB8PDwMHmRSqvVIj09HUqlknfql3ElPVZarRZ37tzB3bt3UalSJV7UtBMxn8Oi4GfXeTjLWAmCgMzMTCQmJgIAwsLCHNwjIiIiepIwsEFEREREVmk0Gv3F1ICAALPttFotcnNz4e7uXqYvuFHpjFVQUBDu3LmDvLw8yOXyEtlGeSL2c1gU/Ow6D2caK4VCAQBITExEcHAw01IRERGR3ZTtX0FEREREVCbocvl7eHg4uCfkTHQpqMp6HQBnwc8hOSPd8WrPmjBEREREDGwQERERkWhMJ0S24PFSMvi+kjPh8UpEREQlgYENIiIiIiIiIiIiInI6marbuHhsNjJVtx3dFSplDGwQERERERERERERkdN5lHgaqocJSEk84+iuUCljYIOIiIiISsWDR1m4dCvF7N/DlCxHd1G0ypUrY8aMGY7uBlGRaLVanE28gD3XD+Ns4gVotVpHd8mqdu3a4Y033tA/FvMZlEgkWLVqVbG3ba/1EBERkf2lJp4DAKQ8OOfgnlBpkzm6A0RERET05FPnafDWjJ1ISc8x28bXyw1zP+wEuczFbtu1ltt9ypQpmDp1qs3rPXz4MDw9PYvYq3zt2rVDgwYNDC7Ofv/993j33Xfx+++/Y9CgQWjXrh127twJIL8Qd2BgIBo1aoQRI0agT58+Ftc/fPhwpKSk8IIsGTh46zjmH1uCpKwU/bIAhS/iGvRHLe+qdt9ez549oVar8e+//xo9t3v3brRt2xYnT55E/fr1bVqvPT6DhU2dOhWrVq3CiRMnDJbfvXsXfn5+dt2WvX3++ef48MMP8cUXX2DChAkGz82fPx8jRowAkP+dGB4ejk6dOuHLL79EcHCwI7pLRERkF+qcNGSl3wUAZKXdgTonHXI3pYN7RaWFMzaIiIiIqMTJXKQI8lPAXJxBIgGCfBWQudj35+ndu3f1fzNmzIC3t7fBsnfeeUffVhAE5OXliVpvUFAQPDw87NrXKVOm4IMPPsDq1asxaNAg/fLRo0fj7t27uHz5MpYvX446depg0KBBGDNmjF23T0++g7eO45u9vxkENQAgKSsF3+6fhWP37Z/CYdSoUdi8eTNu3bpl9Ny8efPQpEkTm4MaQMl8Bs0JDQ2Fm5tbqWyrqObOnYt3330Xc+fONfm87rvv1q1bmDVrFjZs2IChQ4eWci+JiIjsS5WUYPExPdkY2ChnHjzKwuXbqXiYBly+nerUKSCIiIjIsQRBQHZOnuFfbh6yczX5/y2wPCdXgwEdakAQzK0LGNChBnJyNcbrLPQnmFuJCaGhofo/Hx8fSCQS/ePz58/Dy8sLGzZsQOPGjeHm5oY9e/bg8uXLePbZZxESEgKlUommTZtiy5YtBustnAZHIpFg9uzZeO655+Dh4YHq1atjzZo1ot/HV199FT/88AM2b96Mrl27Gjzv4eGB0NBQREREoEWLFvjyyy/x66+/YtasWUb9ssXOnTvRoUMHKBQKhIWF4f333zcI7CxbtgzR0dFQKBQICAhAx44dkZGRAQDYsWMHmjVrBk9PT/j6+qJVq1a4fv16kftCRSMIArLzckT9ZaqzMO/YEovrWxT/DzLVWaLWJ/Zz2KNHDwQFBWH+/PkGy9PT07F06VKMGjUKSUlJGDx4MCpUqAAPDw9ER0dj4cKFFtdb+DN48eJFtG3bFu7u7qhTpw42b95s9Jr33nsPNWrUgIeHB6pWrYrJkydDrVYDyJ/VMG3aNJw8eRISiQQSiUTf58KpqE6fPo2nn35a/9kYM2YM0tPT9c8PHz4cvXv3xtdff42wsDAEBARg3Lhx+m2ZMnXqVDRo0ABz585FpUqVoFQqMXbsWGg0Gnz11VcIDQ1FcHAwPv30U6PX7ty5E1lZWfj444+hUqmwb98+oza6777w8HB069YNr732GrZs2YKsLJ7/ERGR80pJjAegu3NKwnRU5QxTUZUjhVNArDq+16hNSaSAICIioidTTq4G/T9YZ7f1fTr/kKh2Sz/rDnc3+/2Mff/99/H111+jatWq8PPzw82bN/HMM8/g008/hZubG/744w/07NkTCQkJqFSpktn1TJs2DV999RWmT5+OH3/8EUOGDMH169fh7+9v9jV5eXl44YUXsG3bNuzcuVP0netxcXF4++23sWLFCnTs2NHmfb59+zZ69OiBwYMH488//8SFCxcwevRouLu7Y+rUqbh79y4GDx6Mr776Cs899xzS0tKwe/du/ayW3r17Y/To0Vi4cCFyc3Nx6NAhq2m/yP5yNLkYtvwNu60vJUeFkavesd4QwB99Z8BdZn0Wg0wmw7BhwzB//nxMmjRJf5wsXboUGo0GgwcPRnp6Oho3boz33nsP3t7eWLduHYYOHYqoqCg0a9bM6ja0Wi369OmDkJAQHDx4EKmpqQb1OHS8vLwwf/58hIeH4/Tp0xg9ejS8vLzw7rvvYuDAgThz5gz+/fdffcDQx8fHaB0ZGRno0qULYmNjcfjwYSQmJuLFF1/E+PHjDYI327dvR1hYGLZv345Lly5h4MCBaNCgAUaPHm12Py5fvowNGzbg33//xeXLl9GvXz9cuXIFNWrUwM6dO7Fv3z6MHDkSTz/9NGrXrq1/3Zw5czB48GDI5XIMHjwYc+bMQcuWLS2+ZwqFAlqtVvQsNSIiIkfIzU5FXm6ayedO30+A9v4puOp/ggpIvHcKDz22IjqkpsnXyFy94Opu/P93ck4MbJQjuhQQqRk5Ju+WLKkUEERERERl2ccff4xOnTrpH/v7+yMmJkb/+H//+x9WrlyJNWvWYPz48WbXM3z4cAwePBgA8Nlnn+GHH37AoUOHjGZgFDRr1iwAwMmTJ1GrVi3RfZZKpahRowauXbsm+jUF/fTTT6hYsSKmT58OHx8f1KlTB3fu3MF7772Hjz76CHfv3kVeXh769OmDyMhIAEB0dDQAIDk5GampqejRoweioqIAwOAiK1FhI0eOxPTp07Fz5060a9cOQH4aqr59+8LHxwc+Pj4GaeFeffVVbNy4EUuWLBEV2NiyZQvOnz+PjRs3Ijw8HED+Z7Bbt24G7T788EP9vytXrox33nkHixYtwrvvvguFQgGlUgmZTIbQ0FCz21qwYAGys7Pxxx9/6Gt8/N///R969uyJL7/8EiEhIQAAPz8//N///R9cXFxQq1YtdO/eHVu3brUY2NBqtZg7dy68vLxQp04dtG/fHgkJCVi/fj2kUilq1qyJL7/8Ejt27NB/5lQqFZYtW4b9+/cDAF544QW0adMG33//PZRK0znGL168iF9++QVNmjSBl5eXtbeXiIieIFqtFvEPL+FRVir8FD6oHVgNUmnZvQ547cwipCVfMvmcDIAAAf/N2ADkECC5+i/irxrX9gIAL/9qqNHkpRLoqX052zg5CgMbZYBarbY4LdmeBnWqjv/NPWzyOUHIf5537ZQtumOjtI4RKjqOlXPheDkPjlXZoFarIQgCtFottFotAEAuk2Dxp4YXDgVBQFpaOry8lCbv4BcEAZN+3o+rd1KhFQCpBKgS7oNPX4kVfce/XCbR98EWutcU/m+jRo0M1peeno5p06Zh/fr1+gv8WVlZuH79ukE73fuhU69ePf1jhUIBb29v3Lt3z2JfW7dujRMnTuDDDz/EggULIJMZ/zwvvJ2Cywvuh6nnzb323LlzaNGiBSQSib5NbGws0tPTcePGDURHR6NDhw6Ijo5G586d0alTJ/Tr1w9+fn7w9fVFXFwcunTpgo4dO6Jjx47o378/wsLCjLaj1WohCALUajVcXAxnBPMzXXxuLq74o+8MUW3jH1zE57tmWm33XuuxqBtSQ9S2xapVqxZatmyJuXPnol27drh06RJ2796Njz/+GACg0Wjw2WefYcmSJbh9+zZyc3ORk5MjuoZGfHw8KlasqA9qAEBsbKxRu8WLF+OHH37A5cuXkZ6ejry8PHh7e4veD922YmJiDAqXt2rVClqtFgkJCfrARt26dQ2O+bCwMJw+fdriuitXrmwQaAgJCYGLi4vBhYyQkBAkJibqHy9cuBBRUVH6YGyDBg0QGRmJxYsXY9SoUfp2qampUCqV0Gq1yM7ORuvWrTF79myb9p2IiJzbwVvHMf/YEoNaWwEKXwxvNADNIxo6rmMWBEW0QKbqNjR5plMnFj5/sHQ+4SJTICiihV37VxJMjZO/uw86VmuDUGUwAx0FMLDhADNnzsTMmTOh0WgAAJs2bSq1wneCAAQqgaR0oOCkDQmAACVw5+Jh3DUdCCUHM5UnmMomjpVz4Xg5D46VY+nuYk5PT0dubq7Ftu6uLlDnmM/b3uepSpi+IP8Cn1bIf2ypfWG52aKbGsjOzoYgCFCpVACAzMzM/D5otfplAPDmm29ix44d+N///ocqVapAoVAgLi4O6enp+na6i4MFX5eXl2fwWLeNwssKtq9duzamTp2K3r17o1+/fpg7d65BcCMvLw+5ublG69BoNLhw4QL69etndv1qtdpkn3Tr1QUW0tLyp/fragSkpaUhIyMDS5cuxcGDB7F9+3b88MMP+PDDD7FlyxZERkZixowZGDlyJLZs2YIFCxZg8uTJWLFiBZo2bWqwndzcXGRlZWHXrl1GN8/o3n8qOolEIiodFADEhNRBgMLXqHB4QX7uPogJrQ2Zi/1PE0eNGoVXX30VM2fOxLx58xAVFYWnnnoKADB9+nR8//33mDFjBqKjo+Hp6Yk33njD6neNLfbv348hQ4Zg2rRp6NKlC3x8fLBo0SJ88803dttGQXK53OCxRGI9IGvqNdbWM2fOHJw9e9bge0M386NgYMPLywvHjh2DVCpFWFgYFAqFzftERETO6+Ct4/hm729Gy5OyUvDN3t/wdqsxaBoeU+ZmCfiFxkDpF4Ub8cuRknimyOvxDa6HSrX7Qu5mejZjWWFunJKzU7HkzFr947IekCotDGw4wLhx4zBu3DioVCr4+Pigc+fONt8pVBzBVe7i8z+OGywTALwyoCka1ggqtX6QOGq1Gps3b0anTp2MTmyobOFYOReOl/PgWJUN2dnZuHnzJpRKJdzd3c22y5+xkQYvLy+zd0y1auCFlbtu4NKtVFSL8EGrBpGlUp/B3d0dEolE/7tLd2OJl5eXwW+xI0eOYMSIEXj++ecB5F/wv3nzJlxdXfXtpFIp3N3dDV6nm6WhI5FIjNoUJJPJ4OrqilatWmHLli3o3LkzRo8ejUWLFumPdV2bwuuYO3cuUlJSMGjQILPrl8vlkMlkJp+Pjo7GihUrIAgCvL29IZFIcOrUKXh5eaF27dr6k9jOnTujc+fO+OSTT1ClShVs2bIFb775JoD82SatW7fG1KlT0apVK6xZswYdOnQw2E52djYUCoW+qHNB5gIyVDKkUimGNxpg8mRZZ2CtHpBKSuYCxoABA/D6669jwYIF+OOPP/DKK6/oP/d79+7Fs88+ixdeeAFA/oX5CxcuoE6dOqLWXbt2bdy8eRN3797Vzxw6cOCAQZt9+/YhMjISkyZN0i8rXPDe1dVVf/OZpW3Nnz8fGRkZ+lkbe/fu1aeKKk2nT5/GkSNHsGPHDoNaPsnJyWjXrh3Onz+vT3EnlUpRrVq1Uu0fERGVDVqtFvOPLbHY5tfDf2OeyxIkl8HZHHI3JaIaxCH53kncOLcceXnZkMBEjv1CBAAymQKV6vSFf2iM1falxVyaKTHjpFMwIOXo8XEkBjbKALlcXqoXaprUDkWgEniYf1MeJBKgWoQvmtYJY9HHMqy0jxMqOo6Vc+F4OQ+OlWNpNBpIJBJIpVKLd27p7iTWtTUnrnsd/LbyNOK61zFKUVRSdP0x9d+Cfa1evTpWrlyJXr16QSKRYPLkydBqtUb7VPixqffG2vulW0fDhg2xbds2dOjQAYMGDcKSJUv0x3tWVhYSExORl5eHW7duYeXKlfjuu+/wyiuvGAUSCq9bpVLh1KlTBssDAgIwbtw4fP/993j33Xfx5ptv4uLFi5g6dSreeustyGQyHDx4EFu3bkXnzp0RHByMgwcP4sGDB6hTpw6uX7+O3377Db169UJ4eDgSEhJw8eJFDBs2zOT+6+46L/z55ee59DWPaIi3W40xkYbCD3EN+qGWd9US27ZSqcTAgQMxceJEqFQqDB8+XP9c9erVsWzZMuzbtw9+fn749ttvcf/+fdGBjY4dO6JGjRqIi4vD9OnToVKpDAIYum3cuHEDixYtQtOmTbFu3TqsXLnSoE3lypVx9epVnDhxAhEREfDy8oKbm+GMmCFDhmDKlCmIi4vD1KlT8eDBA7z66qsYOnSoPg1VaZk7dy6aNWuGtm3bGj3XtGlTzJkzB9OnTy/VPhERlQatVotzDy7imuYOzj24iOjQWg6fWVCWxT+8ZHHGJgCk52YYLStrF8/9Q2Pg5ReFAwd+hCI7yeI1TEEQcCVPg/3ZuRiUp0XzUuynJZbSgSldPa2OU2Hzjy1F0/CYcnv8M7BRDkkkEjSpDPz7eAaXIAAvdK3NoAYRERGVmgY1gvHTe+YvyjvSt99+i5EjR6Jly5YIDAzEe++9VyqzC6Kjo/XBjf79+2PJkvw7tmbNmoVZs2bB1dUVAQEBaNy4MRYvXoznnnvO6jp37NiBhg0NT0RHjRqF2bNnY+3atXjnnXfQsGFD+Pv7Y9SoUfriyt7e3ti1axdmzJgBlUqFyMhIfPPNN+jWrRvu37+P8+fP4/fff0dSUhLCwsIwbtw4vPRS2S/ESPnBDVOpJoCSn0UzatQozJkzB88884xBPYwPP/wQV65cQZcuXeDh4YExY8agd+/eSE1NFbVeqVSKlStXYtSoUWjWrBkqV66MH374AV27dtW36dWrF958802MHz8eOTk56N69OyZPnoypU6fq2/Tt2xcrVqxA+/btkZKSgnnz5hkEYID8mV4bN27E66+/jqZNm8LDwwN9+/bFt99+W6z3xla5ubn4+++/8d5775l8vm/fvvjmm2/w2WeflWq/iOjJVVaKGRe+MLx396kyM7OgrHqUJe7/p+boLp4DcPgxcOzBRZxIuYcW7nJYuoopALiXp8Xt7NQyE5yxlg6sQai4GzoMX/sIGy5uR7fq7UWPhanPMvDf2HrJPaEVrM+IKQskguAkPX0C6VJRpaamlmoqKrVajXXr1mPhYRkys/MQ7KfA7EmdGNgoo9RqNdavX49nnnmGdzaWcRwr58Lxch4cq7IhOzsbV69eRZUqVSymotLVq/D29i63dw45i9IYK0vHjaN+C5d1lt4XsZ/DouBn13k421iV5HHrDPg7xnlwrMwrK0WnzV0Y1ikLF6/LomVn1xnUZyiKAfV6YOvlPUU6Buz12dJqtRi3dhJ6ynIQ7CK1OmMjUaPF/LSsx331w8wenzjs/5u6vts6I0MssWNh6rOsdPUAIDGYteMBN4xp/gJaVm5SIv21xJZzhLL/K4hKhEQCRIbkF8xpVjeUQQ0iIiIiIiIiIjKgCyYUviCru8v84K3jpl9YRFqtFmcTL2DP9cM4m3hBn+ZUTP2B+ceW6tvba7u2tilrDt46XuygBgAsObO2SMdA4bRhxXnP4h9eQnZ2KkJkLgbXMXX37Be8d18ikSBE5gKPx+2Ssh4h/uGlIm9bp6jHgJh0YMUhZizMfZbTczONUpFlIgczDs6x++fb3piKqhwL9FUA11MQ4u/p6K4QEREREREREZU5ZSUFkxj27qvYYIK9cvwXt/6A7uJ13eAaVrdV8L26l56ILZf3GBXOHtawH7zdvCy2seesleKMn7n0QmKLUReHuWNAbNqwwn2vGVAVCUlXjN6HR1mpqCI3rM2nFQTkCsDR7Fw0dpPDFQKkBYIeVeQuOJubB8B6Si5r739RZy5ptVqcvn/e4rbtZdbhBcjNU8Pfw9eg/7YUJi+orNfwYGCjHJPJ8g9KdZ7GwT0hIiIiIiIiIipbykoKJjFKoq9i7jK3JZhgibX6A8/UeFrUesTUkzD1Xpna7nf7Zltcjz2Laxdn/My9tkNU6xKdJaBj6hiwNp4D6vVAn9rdcPjOSaO+SyGBFv/NvlDKPfBMzachaAVUlbtAKwiQIH9WxkW1Bpsyc5ApCDiWo0ZnDzfUdJVBEAQIAKoWCGz4KXzM7oO199/a/pg7BsQca/akyk3HjwfnATDsf1FnjNjr811Syma4hUqF/HFgIy+v7E+dIyIiIiIiIiIqLaWdgqk4itNXS6l1xBadLm5xajF3k++5dkjUuixdvAaAAzeOmXyvisNSCqzC72+eJs/o/S7O+Fl6rT1SUIlV8BgQM55LzqzFqFUTTPa9YFADANLVmVhyZi2WnVuHqnIZpBIJcgRgdXo2VmVkI/NxCqpMQcCqjGysTs9GjgBIJRJEyWSQIL/Ghm4WS+ExMXdM6N7//TePFikNmrmxKS0Fj5/ifEYP3z5px17ZF2dslGMyl8czNjQMbBARERERlSeZqtu4fWkDKlTrBg/vCo7uDhFRmaAVBJx7cBGpuWn4/cQyi22LkqKlJNJaFSddlLW71K0FCXTEtjNHzN3kqtx0eLspocpJN9um4MVrU/bfPIrv988pajfNMndXu6n3VwIJhAIX7v3dfZCrzbO4/l8P/Q0PmQJ1g2sYjGFR0wuJJYUEfes8g6Xn1lltW/AYEDs7IEOdaVN/5ABSNFqkaAX9LA1TzqvzcEOlQWcPN/hIJZADGN6oP6RSqdkxsWTOkUVQ5Zo/7gDjY6Ckx8YWvx76G8/V6Vrk16+/sA21g6qVuVlqAAMb5Zpcn4qKgQ0iIiIiovLkUeJpqB4mwNO7IgMbRETIvyt5dc4OZO7eKKp9UtYjbLi4Hd2qtxcVnCiptFZFTRclJrVO0/AYBCh8La7f21WJmgFVi9p9AOJnfLSObIb1F7aZfV538dqUg7eOW00tVRy6fdAFrw7fPmmyr0Kh2QjJ2db3PV2dgf/t/N7oeCnpgtRaCKgVXA0BVy0fA4VnQ5RUPYlcAL+nZcF0OMOQbvaGCyR4PXa0xXRShcekMGtBDZ2Cx3FJj40t0tUZ+PPk8mKto6zW2ihbvaFSJXdhKioiIiIiovIoNfEcACDlwTkH94SIyPEO3jqOGQfnIBM5Nr3u9xPLMG7tJKtpqUoyrVVR0kWJuZv810N/42ziBcQ16G+xnSo3Ha+um2xyHyyluSpI7IyPphVi8HarMVDI3A2WByj8LNa5KI275/0UPjh46zjGrZ2Eadu/sxiAKarCx0tppAhKzU7D8EYDLLYpOBti3NpJWHFuQ4n1R0xQoyANBHi5K0vtGNApbno2c2RSF+uNSoAuOFrWcMZGOaYvHs5UVERERERE5YY6Jw1Z6XcBAFlpd6DOSYeL3MPBvSIicoziXvC0Vjy4OKmixChKuigxd5MXnCXQq1Yn7Lh6AKqcNJNtTb0HtsxQqR1YzerMEN2sAKlUinOJF7Hh4nYAgI+bF2b2+ARSqdRsqq+Svns+QOGHtOx0fLt/Volto6D5x5ZC0AolEjwpzE/hg7rBNfB2qzGYdWSBQSqwAIUfhjfqb3E2RFnwKCu12MeAu8wN2XnmA5+F06AVNz2bKW4yN0T5VcK5Bxftvm4xSipYUxwMbJRjTEVFRERERFT+qJISjB77hZa9vMlERLYoav0Ke130LlgHQbfeR1mpSM1WFSlVlDmF97NmQFWrQQF/d19otVrsuX4YfgofJGda7o9h31Kw5vxmdK3WDv9e2mGx7byjS+AhU+Do3dMmL7qbCwJJpVIMbzTA4oXxgmmmMtVZ+uWpOWnIzsvB6cTzZgMpao3lGhbFNaxhX/x+fGmJbqOgpKxHmH1sYYlvp+DF+uYRDZGanYbZR/O36yn3MAgolZV6Eqb4KXyKfVHeUlADME6DJiZYZ6tQz0CEe4UYBDb83X2RnG2/bVhSEsGa4mJgoxzTpaJiYIOIiIhKQ86Dh1CrVGafl/v4wC0woBR7JF67du3QoEEDzJgxw9FdISq21AfxgEQKCFpAIkXqg3gGNojIqRWnfoW97kLWzXBQunoAkCA9N8Om14vph6n9VMo9UD+0NvbdPGr2dblaNf6383v9Y29XT5v6BgDbru612iY5O8VgO+aYmqHSPKIh3m41BjP2zYFG0OiXu7rI0bt2FzQNj9EvK/ze/nr4L+y/dcxoO7pAyoB6Paz2qSg85R7oXvNpKOWepV5PwVIRdXspfLH+fvoD/b+z8rIhkeQX3S5L9SQK85R7oHZgtRJLoySXytCqUhPk5qlxNvGCPqAqJlhnjrerEnEN+8PfwxdzjizErbR7AIAQZRBClMEGbXvU6og/Tiyzy75YUnhGSlnBGhvl2H8zNjRWWhIREREVj1atxsl33sXJtyaY/3v7XWjVartut2fPnujatavJ53bv3g2JRIJTp04Vezvz58+Hr6+vwbL4+HhUrFgR/fv3R25uLubPnw+JRAKJRAIXFxf4+fmhefPm+Pjjj5Gaavlixo4dOyCRSJCSklLsvtKTLzc7FZmqWyb/MlS3kPowIT+oAQCCFqlJCchU3UJOxl1kqm4bvSZXRGFTS4YPH64/9iUSCQICAtC1a1e7fPZ0pk6digYNGthtfea89NJLcHFxwdKlxnfmTp06Vb+PMpkMlStXxptvvon0dNsuPt24cQPdu3eHh4cHgoODMWHCBOTlWb/beN26dWjevDkUCgX8/PzQu3dvk+2SkpIQERFh8jtl5syZqF27NhQKBWrWrIk//vjD4PkVK1agSZMm8PX1haenJxo0aIA///zTpv0j24itUeCs27XHdopbv8LedyGn52baHNSw1A/dezT/+FKT+5muzsS+m0fhLnODBBKD55SPAxiF+6MqQv9yNfb7jWYqX79Wq4VC5g7h8f+f5FKZfrtLzqw1qGWSkZtp8FpTQY2CNiRsh6er/VMuZqgzseTMWny3r3RSUNmT8vH74e2mNPl8lF+kUVDwTtp9/b+1ghYZ6vxxKIspinTqhdSEVCrVz6CwN7U2DzuuHcCPB+dh2vbvDI7T5hENixRUG930ebSp3Ax1g2sgSBmoX56SnYrV5zcatF12Zm3xdkCkwkGusoIzNsoxGVNRERERUSmRyGRwCwyEOlUFCCbK/kkkcAsMgERm35+no0aNQt++fXHr1i1EREQYPDdv3jw0adIE9evXt+s2AeDw4cPo1q0bnnvuOfz666/6EwFvb28kJCRAEASkpKRg3759+PzzzzFv3jzs3bsX4eHhdu8LlT/XzixCWrL4OxO1edlIOPSj2ee9/KuhRpOXitWnrl27Yt68eQCAe/fu4cMPP0SPHj1w48aNYq23NGVmZmLRokV49913MXfuXPTvb1xQt27dutiyZQvy8vKwd+9ejBw5EpmZmfj1119FbUOj0aB79+4IDQ3Fvn37cPfuXQwbNgxyuRyfffaZ2dctX74co0ePxmeffYann34aeXl5OHPmjMm2o0aNQv369XH79m2D5T///DMmTpyIWbNmoWnTpjh06BBGjx4NPz8/9OzZEwDg7++PSZMmoVatWnB1dcXatWsxYsQIBAcHo0uXLqL2kcQzdXe+v7sPOlZrg1BlsE3plkpzu2JTQhVnlkXBbRW3fkVJpIyxlbm7oU29R+YUTpXj5uIGVxe5vbpodwUvhpvaT7XWMKBbMI3Vg4wkm7aVprY9kFOYVCKFVjB9/SxdnWlyeUnxknsWe5+6VmuHZefW62d+hHgGYmB0L9xNu4+lZ9dB5iIz+izfUd03WEdaTgaUrp4OT1E0oF4PbL28x+D48ZArkKnOgpuLKwBx6c7soXC6tdBCMywsKVizBMj/XBRMO3Uh6arRazLzsovfaRv6VNaUvVALlRoZU1ERERFRMQiCAE12ttGfNifH5LKI/v1MBzXyV4aI/v1Mvrbwn2BuHSb06NEDQUFBmD9/vsHy9PR0LF26FKNGjUJSUhIGDx6MChUqwMPDA9HR0Vi4sOh5i7dt24ann34ao0aNwqxZswwupEgkEoSGhiIsLAy1a9fGqFGjsG/fPqSnp+Pdd98t8jYfPXqEYcOGwc/PDx4eHujWrRsuXvzvROj69evo2bMn/Pz84Onpibp162L9+vX61w4ZMgRBQUFQKBSoXr26/gI0OaegiBZwkSnssi4XmQJBES2KvR43NzeEhoYiNDQUDRo0wPvvv4+bN2/iwYP/0lrcvHkTAwYMgK+vL/z9/fHss8/i2rVr+ud37NiBZs2awdPTE76+vmjVqhWuX7+O+fPnY9q0aTh58qR+xkThz7zO8OHD0bt3b3z22WcICQmBr68vPv74Y+Tl5WHChAnw9/dHRESEyc/A0qVLUadOHbz//vvYtWsXbt68adRGJpMhNDQUERERGDhwIIYMGYI1a9aIfp82bdqEc+fO4a+//kKDBg3QrVs3/O9//8PMmTORm5tr8jV5eXl4/fXXMX36dLz88suoUaMG6tSpgwEDBhi1/fnnn5GSkoJ33nnH6Lk///wTL730EgYOHIiqVati0KBBGDNmDL788kt9m3bt2uG5555D7dq1ERUVhddffx3169fHnj17RO8jiWNuFkJydiqWnFmLHw7MNbo72JbZD+baHrhxrFjbXXZ2HcaunYRp278z2dba/omdZaEjJgWOqdkBBekueDqSqbuhzb1HYkgA5GhykCzitS4Sx1wa9HH3sjgTxZx5R5cg2QEzBMwFNRxBC/G/hQvzcvXE263GILZSY4Pl1QIqo3VkU9QOqg4AeJCehHGFPst30xMBQB8wS3scFFHlpEFaaLZQURSeceTn5gOFzN3iawIUfuhTuxtm9vgUU9q/iddajMSU9m9iZKOB+fuRmaxv2zyiIZ6p8XSx+ynG/GNLodVqRQd94hr0w8wenxgENb7Z+xtyrNT2KCmukOOD1uMM+lQWccZGOaZLRZWnKTtfzkREROQ8tDk5ODBwiN3Wd/7zL603AtBi8d9wcbd8kqMjk8kwbNgwzJ8/H5MmTdLnAl66dCk0Gg0GDx6M9PR0NG7cGO+99x68vb2xbt06DB06FFFRUWjWrJlN+7By5Uo8//zzmDp1Kt577z1RrwkODsaQIUMwd+5caDQauLi42LRNIP9i7cWLF7FmzRp4e3vjvffewzPPPINz585BLpdj3LhxyM3Nxa5du+Dp6Ylz585BqcxPPfDRRx/h3Llz2LBhAwIDA3Hp0iVkZWVZ2SKVZX6hMVD6ReFG/HKkJJq+a18M3+B6qFS7L+Rm0lQUVXp6Ov766y9Uq1YNAQH5dXXUajW6dOmC2NhY7N69GzKZDJ988ok+ZZVUKkXv3r0xevRoLFy4ELm5uTh06BAkEgkGDhyIM2fO4N9//8WWLVsAAD4+5i8kbNu2DREREdi1axf27t2rDzC2bdsWBw8exOLFi/HSSy+hU6dOBjO95syZgxdeeAE+Pj7o1q0b5s+fj8mTJ1vcV4VCYRCQqFy5MoYPH46pU6eabL9//35ER0cjJCREv6xLly545ZVXcPbsWTRsaHxx4dixY7h9+zakUikaNmyIe/fuoUGDBpg+fTrq1aunb3fu3Dl8/PHHOHjwIK5cuWK0npycHLgX+m5VKBQ4dOgQ1Go15HLDO78FQcC2bduQkJBgEPyg/2i1Wpx7cBHXNHdw7sFFRIfWsjq7QqvV4uyDC/j18F+itqELBPSq1Ql7rx8WNfvB3EyJlpWaYF3C1mJv11xb3R3M9phloSM2BY61ds0jGuKN5qPw08E/kAv7psW0RAoJ3oh90WiMil+MWQKIvPjt5uKGzLzS/f++BMB3+2YXKWVXaRVK1vF190ZKtvkacSWlTlA1XEy6ZjBzRenqifTcDH0KqKKQS+VoGh5jNOYVvEMBAF5u+enLLL3Pvm4+SMx8CFVOOg7eOo7v9s0WvX1T3xlKuSeeqdkevWt1QULSFYPZXofvnBRdVL5ucA398oSHlwEADwvN7mlaIcZkYXt70wVUawdWg4vExaBuTGEBCj90q95evx9loRh7c3ld1A2uWSbTTxXEwEY5xuLhREREVB6MHDkS06dPx86dO9GuXTsA+Wmo+vbtCx8fH/j4+Bjcvfzqq69i48aNWLJkiU2BjfT0dPTv3x8ffPCB6KCGTq1atZCWloakpCQEB4ufsg5AH9DYu3cvWrZsCQD4+++/UbFiRaxatQr9+/fHjRs30LdvX0RHRwMAqlatCq1WC5VKhRs3bqBhw4Zo0qQJgPwLr+T85G5KRDWIQ/K9k7hxbjk0mpz/6mpYJIGLzB2V6vSFf2iM9eYirV27Vh9My8jIQFhYGNauXas/YV68eDG0Wi1mz56tD0DOmzcPvr6+2LFjB5o0aYLU1FT06NEDUVFRAIDatWvr169UKvWzJazx9/fHDz/8AKlUipo1a+Krr75CZmYmPvjgAwDAxIkT8cUXX2DPnj0YNGgQgPzP2YEDB7BixQoAwAsvvIC33noLH374ob6/hR09ehQLFizA00//d3doVFQUAgMDTbYH8tN0FQxqANA/vnfvnsnX6IIUU6dOxbfffovKlSvjm2++Qbt27XDhwgX4+/sjJycHgwcPxvTp01GpUiWTgY0uXbpg9uzZ6N27Nxo1aoSjR49i9uzZUKvVePjwIcLCwgAAqampqFChAnJycuDi4oKffvoJnTp1MrtPzkRsCiUxCgcP9u4+ZTXNki1phwpbc36z0TJdQOHNli8itmJj/TZMXSRMykrBPwlb7LJdc3TBCltmWRS8UGmK2Luh7z2+09ySphViUF1aEWe1V1AnqDr61n0GWq0W3x+Yg/Tckkk1pIUAL3fj4HFxizELNtzRb2tQo6jF0QsSYFz3oyyKa9APXao9hWHL30CehQvTtupTuxvupz/A3ptHjJ5TyNyRlZeNSj4ReJCRrJ9x0CisHq6l3Cr2tpOzUxD/8BLqBFWHTCpD3uPAiVbQQqvVwlNuvRZJYuZDAEBKtgrLz64TtV0PuGNM8yFoWbkJno/ubfa7tvBnXldU3jgYazlFUoDCDwDwMPMRTt+L11+kr+YfKaq/9vAoKxVSqRSecgVUuebrbRWesVWaxdiVrh4G328BCj8Mrd8HD07etvCqsoOBjXJMzhobREREVAxSNze0WPy3wTKtVou0tDR4eXmZvBgkCALOTPoIGVevAVotIJXCs0pl1Pv0Y7MXB01t1xa1atVCy5YtMXfuXLRr1w6XLl3C7t278fHHHwPIz2n/2WefYcmSJbh9+zZyc3ORk5MDDw/bikwqFAq0bt0as2bNwuDBgw0uulqjS68l9j0oKD4+HjKZDM2bN9cvCwgIQM2aNREfHw8AeO211/DKK69g06ZN6NixI/r27au/k/vll19G//79cezYMXTu3Bm9e/fWB0jI+fmHxsDLLwrXziyCKinBanvvgBqoXG+Q3WdptG/fHj///DOA/PRnP/30E7p164ZDhw4hMjISJ0+exKVLl+Dl5WXwuuzsbFy+fBmdO3fG8OHD0aVLF3Tq1AkdO3bEgAED9BfbbVG3bl2D76eQkBCDmQ0uLi4ICAhAYuJ/F0Lnzp2LLl266IMSzzzzDEaNGoVt27ahQ4cO+nanT5+GUqmERqNBbm4uunfvjv/7v//TP791q7i74W2hSyE0adIk9O3bF0B+UCgiIgJLly7FSy+9hIkTJ6J27dp44YUXzK5n8uTJuHfvHlq0aAFBEBASEoK4uDh89dVXBu+Xl5cXTpw4gfT0dGzduhVvvfUWqlatqg8cOyt71HsouC5zwYOCMxfEvMYevt83B5JYCZpFNHDoXcC6YIW9ZlkA4utjLDmzFhV9wq2OZQrSAORfTI0OqQUAeKnpCyWal7/wfmq1Wpy+f77EtldcJRXkKYt83L1x9O7pYiR+Mk3m4oLj984aLFPI3NGzVkd4yj0w7/gSJGY8NDiuVTnpolKLifEoKxWHbp8wSK+17Ox6bL+yD+2qiP8NuP/mUVEX4F+Ifg6aC5loWiH/hgmpVGo1aFlQ84iG+qComMDzwVvHMe/xd50AAf/b+YP++7yiT+nVs9MFXnO0+bPACs/+MRecKc1i7G+2HA2pRGrwvmo0Gqx3ksBG2Z5PQiWKgQ0iIiIqDolEAhd3d6M/qZubyeUu7u6QKRSIfOH5/KAGAGi1iHzhecgUCrOvKfxXlIv/o0aNwvLly5GWloZ58+YhKioKTz31FABg+vTp+P777/Hee+9h+/btOHHiBLp06WI2n705Li4uWLVqFRo1aoT27dvrgwpixMfHw9vbW5+Wx95efPFFXLlyBUOHDsXp06fRpEkT/cXWbt264fr163jzzTdx584ddOjQwWT+fXJecjclPHwiAKt51CXw8I6we1ADADw9PVGtWjVUq1YNTZs2xezZs5GRkYFZs2YBgD4l3IkTJwz+Lly4gOeffx5A/sX6/fv3o2XLlli8eDFq1KiBAwcO2NyXwimVJBKJyWW6gIFGo8Hvv/+OdevWQSaTQSaTwcPDA8nJyZg7d67B62rWrIkTJ04gPj4eWVlZWLNmjdEMDEtCQ0Nx/75hcVbdY3OzUXTBnTp16uiXubm5oWrVqvri7Nu2bcPSpUv1/dcFYwIDAzFlyhQA+cHZuXPnIjMzE9euXcONGzdQuXJleHl5ISgoSL9uqVSKatWqoUGDBnj77bfRr18/fP7556L3sSyyV70HQHwx64L1L0o67YgWAr7dPwsr4jc4tEA2AP3FMzHEtLOlPsaswwuQp3l8d3qhGiN5mjyce3ARD7QpAGBw8VN3x3iAwlfUdmxVcD8P3jqOcWsnYcW5DSWyrSeBj5uX9UZ2ci89Ed/s/c1iGiFbKV09seTMWmSqDWfKZOVlY8mZtXiUnX9ROyHpikHgwV5BDeC//SpcNyQpKwXLz60XvZ7zD8zXrinIx90b0iL8fi9IFwxpHdkUdYNrWAxqfLP3N6P3S/d9vuvaQQBAgIef0Wc6QOGHt1uNscvnPUDhh9qB1ZCrUevrZHzTdbJBHRBz9StKqxh7gMIPdYNqiHpfyyrO2CjHZLrABmtsEBERUSnybdgAympRSL90GcpqUfBt2KDEtzlgwAC8/vrrWLBgAf744w+88sor+gDJ3r178eyzz+rvZNZqtbhw4YLBRUKx3NzcsGLFCvTr1w/t27fHtm3brK4nMTERCxYsQO/evYt0MlG7dm3k5eXh4MGD+pkWSUlJSEhIMNh2xYoV8fLLL+Pll1/GxIkTMXv2bAwbNgwAEBQUhLi4OMTFxaFNmzaYMGECvv76a5v7QmVXauI5EamoBKQ+iEeF6l1LvD8SiQRSqVRfz6VRo0ZYvHgxgoOD4e3tbfZ1DRs2RMOGDTFx4kTExsZiwYIFaNGiBVxdXaHR2O/CU0Hr169HWloajh8/blAD58yZMxgxYgRSUlLg6+sLAHB1dUW1atWKvK3Y2Fh8+umnSExM1Kel27x5M7y9vc1+lzRu3Bhubm5ISEhA69atAeTXLLl27RoiI/NTbixfvtygds7hw4cxcuRI7N69W5/aS0cul+triyxatAg9evSw+N2k1WqRk+OY4qb2YM96D4Btxax1dyyXVtqR9QnbS3wb1qRmqyCFBFJILBZAVso9odXmp8ax9r43j2iIAfV6YMmZtRbbqXLT8fI/E9GuSqxRjv/C/fnxwDyMbDxQf9FRd8f4hovb8fuJZSL2VBwfNy/UDsz/zijJWTtPkq7V22HxmX9KfDv+7r7YcnlPiW+nsO1X9gMAMh7PjHF1kSNXo0Zajn1Sd9lzvwrW/7DE190bKbhvvWExifk+33hxJwCgim9FvNPqJbOzQPRp8zIfIS0nXV/fJDEjCRsuWv8u1aWXSs/Mn6EhlUihdPUUNVNF7Ey04iqcAssZOXfvqVh0NTby8krmBICIiIjIFIlEgsihQ6CIiEDk0CFFmoFhK6VSiYEDB2LixIm4e/cuhg8frn+uevXq2Lx5M/bt24f4+Hi89NJLRndM28LNzQ3Lly9H8+bN0b59e5w9+1+qAUEQcO/ePdy9exfx8fGYO3cuWrZsCR8fH3zxxRdW13369GmDu9lPnjyJ6tWr49lnn8Xo0aOxZ88enDx5Ei+88AIqVKiAZ599FgDwxhtvYOPGjbh69SqOHTuG7du3o1at/BQbU6ZMwerVq3Hp0iWcPXsWa9eutSmNFpV96hwVstLvimqblX4H6pw0u/chJycH9+7dw7179xAfH49XX30V6enp6NmzJwBgyJAhCAwMxLPPPovdu3fj6tWr2LFjB1577TXcunULV69excSJE7F//35cv34dmzZtwsWLF/XHauXKlXH16lWcOHECDx8+tOuF9jlz5qB79+6IiYlBvXr19H8DBgyAr68v/v77b+sreaxDhw4GqakK69y5M+rUqYOhQ4fi5MmT2LhxIz788EOMGzcObo/T8B06dAjNmjXD7dv5aSK8vb3x8ssvY8qUKdi0aRMSEhLwyiuvAAD69+8PIL+2R8G+V6lSBUB+YFQXQLlw4QL++usvXLx4EYcOHcKgQYNw5swZfPbZZ/r+ff7559i8eTOuXLmC+Ph4fPPNN/jzzz8tprgq62wJRIhRlDRLpZV2JF3t+JoGv59YhhkH5lgMagD5ff3fzu8xbu0kUTNmQpXi6lOpctKx5vxmozEv3J9H2alGs3WkUim6VW9v15kbbSKbQSqVQqvV6lPniOVidRbek0V3N30l3woAgGCPQJTkL8iO1VrbdZZEgMIPA+r1sFpbJDXHsFB5zcCqAAC1Vg0/9+LfyW/v/cqvuWJegMIPtQKjLLaxFzHf57rC68GeARZngeiea1u5ObrX7ICnqrRA95odMKLRAIszOnzdvQ3SDaY9rq3h5eopPu2uDTPRlK6eULp6imqro/ss2ZpmsSzijI1yjKmoiIiIyFF8G8Sg0czvS3Wbo0aNwpw5c/DMM88gPPy/FBMffvghrly5gi5dusDDwwNjxoxB7969kZpa9AtNrq6uWLZsGQYMGKCfuQEAKpUKYWFhkEgk8Pb2Rs2aNREXF4fXX3/d4l3qOm3btjV47OLigry8PMybNw+vv/46evTogdzcXLRt2xbr16/Xp9fRaDQYN24cbt26BW9vb3Tt2hXffPONvq8TJ07EtWvXoFAo0KZNGyxatKjI+05lj+rhBcMFEglcXNwRXKkVEm/sNSosrkpKQEB4E7v24d9//9WnTPLy8kKtWrWwdOlSfV0GDw8P7Nq1C++99x769OmDtLQ0VKhQAR06dIC3tzeysrJw/vx5/P7770hKSkJYWBjGjRuHl156CQDQt29frFixAu3bt0dKSgrmzZtnEMAsqvv372PdunVYsGCB0XNSqRTPPfcc5syZg3Hjxola3+XLl/Hw4UOzz7u4uGDt2rV45ZVXEBsbC09PT8TFxelrAgFAZmYmLl68CLVarV82ffp0yGQyDB06FFlZWWjevDm2bdsGPz8/0fuq0WjwzTffICEhAXK5HO3bt8e+fftQuXJlfZuMjAyMHTsWt27dgkKhQK1atfDXX39h4MCBordT1tiz3gMgPoVIwXallXbEGVmqS1JQSb2HhWfr6C442mtmhe/jfq+I3yD6YrOLxAUaQYMXYvro0xc9iSQAetToiH8u5Be1/777NLi6yLHjav6MBqWbBxKLUe4jQOGHVpFNjGbv6OoeqDXiZiNYMqBeD4Qqg/WzAfbdPCrqdTKJi75YeYR3OG6k3EFqThp61OyAP0+uMPu6XrU6Ge2Pjj33q6Bnajxt8Rgc3qg/pKUUhLMlSKwRxM0IM6VgzQ/djI5/L+7A/YyHeCGmj8F3VVrO48CGjWk+zRVN93f3RcdqrQ2OKyA/qHP49kmsv7DN7DqfqfE0mlaIsVifxNkwsFGOyVwY2CAiIqLyIzY2Vl+kuyB/f3+sWrXK4mt37Nhh8fnhw4cbXUSVy+VYuXKl/nG9evWKfKG1Xbt2Jvuu4+fnhz/++MPs8z/++KPRMq1WC5VKhUmTJmHy5MlF6hc5h9SH8ci/RJR/DPkG1UWl2n0hd1MiqGIr3IhfjpTEM49bS5D64LxdAxvz58/H/PnzrbYLDQ3F77//bvI5b29vg89TYW5ubli2zHp6GFP9MPX5vnbtmv7fBQMIhf3000/6f0+dOhVTp061uP2C6zUnMjIS69ebz3Herl07PHr0yCAYKpfL8fXXX4tOIWfqO6V27do4ftzynfGffPIJPvnkE1HbcBb2rPcAAKqcNKtplnS513VsSTsilUgN8uLrLs6uOb9ZVP+clbV0YNX8I0tku4XThgHmLzgGKPwwrGFfJGemiE5X9TAjGQdvHbcpOKGr91DBOxS/Hv5L9OucjQCgQXhdrL+4DRpBi7ScdAR4+OlnPLhIXCyvoABvVyVaRTZFsGcAvN284O/hq7+4+3x0b5PpiM4mXrC+YjPMFYUW+z3i4+aFpOwUAIBW0CLAww+pOWkI8gzAgHo9sPzsemgKfQ/otqfbH90F98L7W5z9KkwqkaJP7W6o6BOOH/bPg1r73/8vC/bJ0v9H7cmWAOfGSztx5PZJDG80oEgzFwoXQL+Tdh+bL+/GvhtHEODhp3+/0x4fr15uts2qAGwrml43OL9WRu2gaia/m0wdj08CBjbKALVaXWofct328uV/CeZptKW6fbKNbmw4RmUfx8q5cLycB8eqbFCr1RAEQZ/v2hzdhTJdWyq7SmOstFotBEGAWq02qE0A8DNdWgStBqkPEwAIcJEpUKlOX/iHxuifl7spEdUgDkl3j+PGuRXQarKRmpQAQdBCUs7SnFD5JCaoUDgQYc7BW8fx3b7ZVtsNa9jX6EKVtVkAumBJwaCGv7svZvb4BFKpFFH+kaK27awKBhi0Wq3B+1czoCr23RB3J3xRmLoL3NIFR61Wi7UJWyweU55yD2SoM/EgI6nIheOz1Dmic/Ar5Z6oH1oL5x9eNpgZ4ubihhxNDhqE1sXN1Nt2y+kvgQRCgeCetWCfOanZafB190FS1iM8ykp9HNjIn6bhLfIO+LgG/dCtenuzQbHCF6h1ilPnYFjDviYvIotZp9LVE6rH6YuA/Avwri75M3B/OfyXQdFxhcwdPWt1RJ/a3QxmFVmq4yCmD7rjwhq5VAapVIrmEQ0R7rUO11Nvo1fNTmgYXs8hswJsHTOxM8KsOXjruP476NjdMzh29wwCFL4Y3mjAfzM2XG2bsaFjbTwLsyUY8iRgYMMBZs6ciZkzZ+qL223atAkeHpZz0pWEfXt2AwDyNALWrVuPUkhvTcWwefOTfQfOk4Rj5Vw4Xs6DY+VYMpkMoaGhSE9PR25urtX2aWn2z9FPJaMkxyo3NxdZWVnYtWsX8vIMUx9kZhYjfwSJptWq4eYRADeFv36Whil+ITEQZMFIubUZudmPoNXkwkXmXsq9JSp9YlILiSmwKqZorRQSdK/RAX8cX1bobtr8C2CD6vXCojNrTK/fxEXhdHWGvl+xFRtjufcG3FDdttgHZ/YoKxUHbx03uhu58EXz/+an2Ye5u8DNXXAUc0x1imqNVec34WLyNaiKUNfIReoCtUbcDQJ9anfDgHo99EGX+IeX8PWeX5ChzkKoMhDXU2+jRmBVvN9mLJacXYsV5zZYXeczNZ5G7aBq+PXwX/pAQ0G6oIYu9U3NgKpISLqCHVf2Yef1g6L300/hA1+FN5KyHiElOz/ApJuxEeEVhvi7F5AJ8xfgAxR+FoMalhQn7dgfx5ejeYWGRtsVs05TNThyH491waAGAH0qsoo+4aIvzIvpQ4OwOgb1ZXzdvZGS/V/tD3+FL5KzUpCjyUWeVgOZ1AUPM5MBAG0rN9fXQSltRR0zazPCLDl467jJ7emCJi0r5s+AVRZhxkZR2RoMcWYMbDjAuHHjMG7cOKhUKvj4+KBz586icirbi1qtxubNm9GxQzv8fWAHAKBT5y5wlYufxkelRzdenTp10ufJprKJY+VcOF7Og2NVNmRnZ+PmzZtQKpVwdzd/sVMQBKSlpcHLy6tUioJT0ZXGWGVnZ0OhUKBt27ZGx41KpTLzKrInF5k7ard4XdTsC5ncE1VjhkEiAWdrULmiSy0068gCqHL+u1Pa202J0U2eF3XBUEzRWi0Efb2AgnQXwNpVbmFTv3M1auy9cQStKj1OHWfHr3IfNy+MajQIv59Yare7+IvrXnqiyZRNhYM+9gxqiJ2tU5ildFWtIptg++M6EUUJagCARqvBHyeWimobHVrL6G7+CJ9wJDy8jJuquwDyx1sqlSI6pJaowIYuT/88lyUAzN+ocPDmcQyL6QupVIr03Aybghq6915XMDv58cyZjMeBFC83TzSW18Zu9Qmz6xATlLTE3DhaYyqFmbV1+rv7Ilertlpc3BRbL8xbOj6HN+qvT5EGAAq5O37u8RnOJ102mCU1ZPlrEAQB6TnpcJW5IuNx0CXIM8Dm/ttTUcbM0nhZIiagfezuaQDiZxiRbRjYKAPkcrlDLtQo3N3+eyBx4cWiMs5RxwnZjmPlXDhezoNj5VgajQYSiQRSqdTiSZMupZGuLZVdpTFWUqkUEonE5OeXn+fSY2uQgkENKo+aRzSEKjsNs44u1C/rWbOz6LugbSlaa87u64dsfs0fx5chNqIRpFKp/o52exgU3QstKjVCs4gGBilNUrNU+OHAXItphew9YwLIv+i75fIeO6/VuuJcGDeVEiYtOx3f7p9ll76pRFwANxeYCfYMQMLDy/rUZt7u+RddbUnNFv/wktWC57oLxrUDq9mcckv33usKrP83YyM/sOHh6oFKLqF4o9Eo/HlqeYnVFCg8jrdUd0UFfyx9J5g6NrRaLf638/si9bEoF+YtpSzSFWgH8t9LiURitG6lqyfSctLzg8E5/y1TyB0/21O3b2svbMFfJ83X5yqoKN/hYgLa2Xn5b47StfRmbJQnDGyUY7ri4QALiBMREZE4rJtBtrBU8NxZzJw5E9OnT8e9e/cQExODH3/8Ec2aNTPbPiUlBZMmTcKKFSuQnJyMyMhIzJgxA88884zd+sTPITkTZzpe76YlAvivQPftx3ezi2FL0VpzChYDFutRdiriH15CrcAopOXYfqe3KVKJFO2rtsz/t4mUJlKJ1OLF+ZL45u9YrbVNBbZ1Ctd6EEsKCd6IfbHYF8YLvn9arRbj1k4q1vpsZS4wE6IMNHjs4+YFwLbUbGIvBD/KShV1AVincFDC//Fn61FW/kxP3YwNpdwDGUhC0woxaFGpUYnWFCg4jmcTL4gKbFj7Tij82dpz/XCx+liUC/OmPt8Hbx3HnyeW6x/fUt3FuLWTjIpsez0ObOy7eRRuLq4AgCAP/yL23v6kUilq2TDbqijf4ba855yxUTIY2CjHpFIJZC4S5GkEBjaIiIjIIldXV0ilUty5cwdBQUFwdXU1mb5Iq9UiNzcX2dnZnLFRxpX0WAmCgAcPHuhnbDijxYsX46233sIvv/yC5s2bY8aMGejSpQsSEhIQHBxs1D43NxedOnVCcHAwli1bhgoVKuD69evw9fW1S3/Efg6Lgp9d5+EsYyUIAnJzc/HgwQNIpVK4uro6uktW3U67DwCoF1wTp+7H40aq+HoVxSk0XFyPslKhykmHAAESSOCn8LF6J31Burvvgzz88SAzGYEefpBamLnVolIjvC01TvWiCwgV1CgsGtdTbhrdTS+BBA+zkuEuc9Pf0WyKLsCQJ2hE709BXau3w4aL221+3estR6FFxUZF2qY5tlzct5W3m9IgjZq1GQvBnoaBDW93L/2/raUp0q1T7IVgP4WP6AvABeuB6Pg+TkX1qFCNDU/X/2rVlmZNAVtmtdiiuMFRewRXrdWL0BXZPnjrOBIzHgKAQZCnrP0/yUOuAGA9wFnUlHO2vOdeDGyUCAY2yjm5TIo8jQZqTdF+JBAREVH5IJVKUaVKFdy9exd37twx204QBGRlZUGhULDGRhlXGmMlkUgQEREBFxfnrOX27bffYvTo0RgxYgQA4JdffsG6deswd+5cvP/++0bt586di+TkZOzbt08fzKlcubLFbeTk5CAn57+LerraI2q1Gmq1cWHYihUr4v79+7h9274FggVBQHZ2Ntzd3fnZLeOcbawUCgXCw8Oh0WigKePnnbdS82doNA2P0Qc2dlzeBz+FL2oFRlm82A8AQ+v3xYyDc0qjqwa85J54mJ4EAPBx98IwG/rRt3Y3hHgGIv7hJTx4XPw3QOFn8vunoEYh9dCgax2cf3gZKdkq+Lp7Y9X5jTj74IJBO393H7zZdRQmb/sa11JvAQC+6Pg+Jmz+FADwXK2uWHhmtdntjG82HI3DonHuwUVR+2PUz9B68JApsDx+vaj2HnDHyCYD0SS0vtX3wFYP05Ntau/n7oPq/lVw6M4Jq22HRD8Hf4Wvfix0x6u5ffB39zV47CF1N2hranwLr7Oab6S+iLQ5/gpfVPONxPm8y1b3AcgPGhT+rvCS56fwSc58BLVarU9F5S7ND5bae5zEsPZZH1q/j83feWLeT3N073Nx3gutoMU8K+nC5h1bArVajR8OzTP5/OXk69h37QiaVogxWK7rV2mPlQz5vz+tpccryngB4sZMKpFAKwhQSN0ccqwWhaPGq/D2xWBgo5zLT0elQR5nbBAREZEVrq6uqFSpEvLy8sz+8Fer1di1axfatm3rtHfplxelMVZyudxpgxq5ubk4evQoJk6cqF8mlUrRsWNH7N+/3+Rr1qxZg9jYWIz7f/buPDyq8uwf+Pec2TJJyDZZIIQ9LGFLwhZxRVZxqxtQRVm00lqwluirUlusrdX2dSm1ooiCqG/7E7HWtopIxIKIyBoWJSyBCIRA9oVss53z+2NyJpnMkpnJJJNJvp/r4iJz5izPzDOBM+c+930vXYp//etfSEhIwD333IMnnnjC7fvw/PPP45lnnnFavnXrVoSHh7vYonksXe3OSKLWJElyWYpKkmWUShVogBF66JAgxkHshCCNu+NKsoxLUhlKzbbgwNGjRwAAFsmK1/a/BwAIhw7jNWnor+rt8RjXaDLwtfmw093BA4U+KJErUA/32Qn+0ECNM3tP4qJku3taMMooPXwBV6vTscty2OPFPD100J6RUCDnOyxvrKjH5s3eBQIUVSiG0eTcRPrMuQJsubgFtS2yCf79+X9QbbI1zW48VY1rNBk4YM5zem9ihV4oP3IRm49chCTLCIfOp/cvHGE4s/ckLknelRQbrRqMMeqhqPyuGJu/8+31e6PYWu71OHqLBiTIcSgt9S4YcurwcSSpbE2bq1CMH+A5EFQnN9h/FgBs/PwfSPTwe+hun6OsA7ETh9weZ5RlILZ8tsWr+VPm6wfB8Tjlki1To7iqFJ9++inqmjI29u/eh3AhDDk5OW732ZFcfW7DEYbxmhEoPXwBmw/7fgNCW++n2+2a3uf2KLaWo8Jc5XGdioYqvLH3/zyus3bP31CsK3T5WersuTLLFgCABBlXqcdij+V7WND8Haa98wW0PWdKVdYDu/fjlJjn1zGCJVi/W/X1zv+XuMPARg+nUdu+DLEUFREREXnDXSNohUqlgsViQVhYGAMbXRznyrOysjJYrVYkJSU5LE9KSsLx48ddbnPmzBl8+eWXmD9/PjZv3oz8/Hz8/Oc/h9lsxtNPP+1ymxUrViA7O9v+uKamBv369cPMmTMRFRUVuBfUBrPZjJycHMyYMYOfhy4u1Odq34XDePfIP1BhrLIvi9PHYMHYO53u8vWGJEsu7yr39rhXpozHN4UHHJbvtRxz2r4eRuw0H8IvMhe32Xfh6Ke/RpWxBnNG3oT88h+QW/w90oeOxqDY/gHP6BiZNAw3X3UTdvzwLbYfPIB+iSm48SpbT59xhblu76wGgJ9m3YuJfdPRaDHis383B2wzho3BjSN96wu078JhXDiwHWh1aUEdo8WN192IXdu+Q1l1FQBgcOYwyHtsjcBvm/0jqEWVwzwW15biw7zNiIuJw43XN48j6UKKT+/fkqz5mNg3HcdKT2HXziNtrn/TpFkozC3osN8tSZZwcMspj3d3h6l1eOKWX9g/w95sE6ePwcIb5reZUdTSnsJcYO8OALY72beZ9/n9ezhe+d1qMUZX+2pr/pT5aq2yoRpbPtuNRphwzfRr8fdPPwcADM4YiqJD5zBr5syg/Vvo7b8/vnD1frojQMDDkxYFpEn6N+cP4It9bff5MMLz3fT1aMTgScMwMmGofVmw/t+SZAkf/PMLAMD8mXMhHP0Xvj6/D5NTxmHqoKsCMl+A5zmzB7kH6nDDqBsCcryOFuzzDCV72RsMbPRwarXtzjGzlYENIiIiIqL2kCQJiYmJWLt2LVQqFcaPH48LFy7ghRdecBvY0Ol00Ol0Tss9BRA7UrCOS77rKnMlSZLXTXv3FOa6vLBZ0VCFVXvW2eu3e2tPYa6LPgAxTk1uvz130O1xPzm1zevjAcCrezdArVLjiv6u+y9IsoTLZtsd5dcPuRKNFiNyi7+HSTLjyoEToFKrsP7gRp+azk4ZOBlHivMcLppFaPSoMzdAr7UFp5Vjxulj7J+LqwdNgkajabNXgkajgUEfi/KGSgC2TBWVSuV1Vpi7eQWAk+UFOFj8HcySxb7s/GVbScte2gjodWH25enJIwEAeaWn8GHeZtSbGxw+41cOnICiumKvmojPHX0zrhw4AQAwpvcIr3oijO49HIUo6NDfrcVtNOaeMnAydFrH/xPa2mbxuLlO23iyx03Ay9/fwysHTvCqebfy+W/r89havCoOgiBAlmU88cXz9uUv7XkT4dAhqSTFPtfBoHxuA6Xl+7nvwmFsPvml23V/eeUDmNxvfECOGx8ZuMbfucXfu3xfgvH/ll4dhgZLI8ywotFqy64Z03tEQOdNmbOP8j5z++/Tf05+gf/+sBs/nTg/IIGozhDMc1FvMbDRw2lUzNggIiIiImotPj4eKpUKxcXFDsuLi4vRu7frUjR9+vRxKr+VlpaGS5cuwWQyhUTzZApdvgQYAsVVYCEuLBrTU69B78hEh3FIkoQNbdRv33BwEyYmp3s1bm+b3O4+fwB/2R24LAkJMl7e/SYeFV1f/K0z1cMq2UqdROt6IUxtu+DcYG4EYGvMXN1Qg7cOvu/V8Qz6WPxs4r0A4DC/lQ3VeOXb9ahutJV0qmq03eEao3fM9MpKycTE5HSPn409hbmoMV62P/7PyS/wzfn9TgEil++Hl/PasihNQaWt10ZMmOustEitraeC0iS6JYM+1uOxFL0jE+0/i6KIRW0EBxaNm9Mpd1K7a8yt2H3+AEYlDXN4371t5u2NQP8eKrxt3u3N59HVvvUqHeotjQ4N0gFbJtWqPeugUqtC5mKxN5T3c1TiMKQlpAZk7tviTVP0KG0kaky1bp9XbD75JdISUrvEnOg1tsBGg7kBdWZbCbZwjftSn+2x7fTXHp+vNdU5/P9E7cfARg/HUlRERERERM60Wi3Gjx+Pbdu24bbbbgNguyC0bds2LFu2zOU2V111Ff7+979DkiT7RZqTJ0+iT58+DGpQh/I2cyHQx3R1obiisdrhjlVlHJHaCI8XzACgvKESeWX5bV4g9fbirCzJ+PPutzyu56+3D3zg8uKvEmiI0IZDo9JAr7FlJDRYbHcKS5KETd9/6vVxFo2bYz9Gy/flWImtSXdVY3XTcZsCGy6CBZ4uOnsbIHInryzfq3mN0Ojtj3+oPA8AiG4rsGGuhyRLDgEHi+Rdc99YfbTDY2+CA53VKDcrJROyZAuQtVZtvOzyffcnIOCKt/Plze+hv7wNgih2nz+Aekujx3X8CcaEikDNfVu8CQA+MOHHeDf3wzY/Q0DXmRO9JgxoAOrNjahr6gMUqQ18YMOb3y1FV3lvugMGNno4JbDB5uFERERERI6ys7OxcOFCTJgwAZMmTcKqVatQV1eHxYsXAwAWLFiAvn374vnnbaUxHnroIbz66qt45JFH8PDDD+PUqVN47rnn8Itf/CKYL4O6ufZemPaHN4GF1uO4cdhUr9b3pkSTtxdn3zr4/7w6pj8qGqvwUd5nuGvUTQ7LlUBDjM520T5MrQQ2bBdm88ryUd0iO8KdKF0kHpxwj9u5U4ICThkbboIFrgTi7n1vS2qZrM2lqCqV98jNWCOaLjrKsowGc6P9MQBoVW2XKDHoY5EWn+q0vLMuELdFkiS8c2iTx3Vcve++BgRc8Xa+fCmV1pH2FObiz9+0HZzs6GBMsAVi7r3hTQBQFESPwQ9FV5mT8Bb/BteZbYGN8BaB1kDx5Xemq7w33QEDGz0cMzaIiIiIiFybN28eSktLsXLlSly6dAkZGRnYsmWLvaH4uXPnHC469evXD59//jmWL1+OsWPHom/fvnjkkUfwxBNPBOslUDfXUWVl2uLLnamKr3/Y69V6re+0d8XbC0ity9YE2gfffYJ+0ckOwYeqpkCDUhJKuajW2JSx4e3YF2Tc5TEgpQQF6s0NMFnN9sCGuywIVwJx97438wUA1hY9NhTuxqpVaaBTaWG0mlBrqnMIbFysLXa5TUsts1xa66wLxJ4EM2vC2/nydr2O5EsAFeg6wZhQ11YAMCslEzcOm+qx94eiK8xJuNYWxGgwN6LeZCtF1REZG77+znSF96Y7YGCjh2sObHiXzklERERE1JMsW7bMbemp7du3Oy2bPHkyvv322w4eFfV0kizjWOmpoF0g9eeCTI2pFlG6SI/BBhECLje2HYzoChddFa0DR0pJqGhdLwBw6rHh7dgN4Z57SYSpdBAFEZIsYX/hYfuc+JKxEYi7972py+/ueU9jjdRGwNhgQq2pHklNyyRJQl5JPgAgI2kkztUUOTRU74i+Ax0hmFkT3s2X64yXzuZrALUr/bsQ6toKAE7sm+5VYKMrzIlebQts1Jrq7Jlz4R0Q2PDmd6ulrvDedAcs5tXDqZuah1uszNggIiIiIiLq6vZdOIx/GbfjDzv/io/yPvNqm0BfIPX3gszVAyZ5fF5pzL2nMNfjesoFpK5ACRwpWpeEUnpsNDZdUEuLT22zDEpbF5b3FOZi2ae/hiTbvsev+nad/YLdpcslkCTvvt8H4u59pS6/J/eMvd3l8uiwXm63Ue6oVmri7ynMxdJPnrK/14eKjwGyjLmjb8YvrrgfT1+/HKtvfrbLBzWA4GZNeDNfnjJeOpMv/251lWBMT+HNv8FdZU6Uf4PL6ivtyzqiFJU3v1uKrvLedAfB/5eKgoqlqIiIiIiIiELDnsJcrNqzDvUw+rRdoC+Q+htYmNg3HT+dML/N9TYc3OTx4rwoiliYMcfn47syOWWcPatCYdDH4ubh07zeR8sLsErPC6XMkj1joynwIIoi0nunedyfpwvLSk8Vd3cF/+nr17H0k6faDA4Bgbs4qdTld7WvcI0eY3uPcLldTJj7z2WkrqmBuKnO7WtWGtVrVGqMShzWJS7GeyPYF4XdzZdBH9shPXn85cu/W10lGNNThFKAzB7YqKsAYPs3WS2qOuRYyu9WW6Wuusp70x2wFFUPp1HbfpkZ2CAiIiIiIuqaJEnC96Un8ca+//N52464QKpc1PKmgWzrcRRUnGtz3bbKZ+0pzG2z+bK3dhcehFqwfS+eMnAyrht0hb2efLhGjw+++6TNfbS8AFttdOx1oVca15qNkGUZgiDYL+iHqXX23htA26WUvO054G3jeG/m0dsLcK3r8kuyhFf3bIAMGSarGQCgFtVQiyr7a47xkLGh9NWoMV7Gv/K2ejx2R/SR6UiBfN/91VUaqXviTWkfAcDDkxZ3mWBMT+JNo/GuINyesWELbERoAl+GqiXld+ujvM+w+eSXqG3KOgO63nvTHTCw0cMxY4OIiIiIiKjr2lOY63ThyBcddYFUuaj12p530GBpO4NEGccPVYVe7d9dGRrl7v1Assi2npOJkfEOwZQ70mbji9NfO/RxaK114KiqwXUpKqtshVmyQKvS2Msr3TFyNoYaBnl9YdnXngPeXPAP5MXJlnX5lYuIZqvFHtjQqjSI0kbikqUUAFBcW4r+0X1dji9Sa8vYKKgsDFqj7Y7UFS4Kd4VG6p54EwC6Sp3Oi8RBFAoBMqXHhvJvktJMvCOJooi7Rt2EO9Jmd+n3pjtgYKOHswc22GODiIiIiIioS2nPRfzOuECalZKJwxeP4YszXwOwXcxvMDfCaDW5HIckSbh4udirfbsqQ+NtxoK/cvK/wh1pN9gvPImiiMU+3llfZVQCG47NwwGg0dxoC2yYbYGNSG2ETxeWfe2V4u0F/464OKlVaQEAFskCY4vAV1lDc537l755EwZ9DBaNm+v0OVUCG1VBbLTd0ULhonCweQoA3Tf2DpQevhC8wRGArh8gU4LLSv+jtspEBVJXf2+6AwY2ejiNihkbREREREREXU17LuJnpWRi+eSfdMoF0pZlNhosRgyI7ouTFQUAgLSEofjNdb/AifIz2JC7CV+f3YsaY22b+3RXPsvXjAVfVTZW46O8z3DXqJvsy3y5s16SJdS06rEhCiLUUMECK+otjYhCL9SbGwD4foHNn14p3l7wD/QFOK3YfLmprun1Kq+7JXdls5T3RpJlr47XEY22OwMvfLbNXQDIarViMwMb1AalFFXz447P2KDOw8BGD6dmKSoiIiIiIqIupz0X8a2y1K6ghiRJDhcRhxsG40T5GZd3lV82NQcqjBYjTleetT+uNdbi4U9/4/PrcFU+S5IkHC0+7vdr8tYH332CftHJDhfZlQur//v16zh48TtcN/AKPDTxPqcx1hhrYZVt360vVF9CbFMvDQ3UsMCKRrOtgbgSDPL1Aps3PQdaC9YFf41KY//5shfBrNZls5SMDbWoavM1d2SjbeoaXAWArFZrkEZDoUTfKrAR0YkZG9TxGNjoYYylZWioqICqrBx1ZwoQUXkJSY3lUBWHofa0HproaOjiDcEeJhERERERUY/WntI6pbVlfm/rqqeHCAESmu+cb1k+qHUGhnJhHwDO11z06djuyme1t8+Ir1z1phBFEUPiBuDgxe+gEdVOQY09hbl4a///sz9+9qtXYNDH4L6xd9qak8tAfVNgo97kX8aGr03bg3nBXyWqIAoiJFlCfvnZNtdvXTZLeW/qzPVBb7RNRKFL6bGh6Ojm4dS5GNjoQSSzGYcfexzmqmrEAvj+35+iH4DFAFAIHP4PoImJwYS31kDUaDzvjIiIiIiIiDqML3faR+l6ocZ42f64pL4csixDEASfjumup0fLoAbgWD5IuRvfoI9FeVP/BAECZHhXQqil29JmIlIbAUlqzjjpiGbhbXHXmyJWHwMAqGh0DDq5G2N5QxVW7VmHSNgurDVamjI2mnpshPtx57C70liuBPuCv0algdFiRKWXAamWwTwlsFFrqkdWSiayr3wQL3/zpsP6ndlom4hCU+tSVBGd0DycOg8DGz2IoFZDFx8Pc3UN4KpOpSBAF2+AoObHgoiIiIiIKJh8KTt047CpeP/ovxAfHoey+go0mBtRZ6pHpC7C6+P509Njw8FN9oyNliWp/AlqAMC6gxsBNGeETExO79Bm4Z64ypiJawo2tbxQ7837Vo+mTA1zIyyS1d5MO8LPWu8tew7su3DYqXdJV7ngrxXVMMLY9opNWgbzlFJUtaY6AMDoxOH2534+aQESIgxstE1EbXIqRcWMjW6FV7B7EEEQ0H/+3Tj2zLOuV5Bl9J9/t8939RAREREREVFg+VJ26GT5GQBA78gEmCULqhtrUFJX5jaw0bqHRlp8ql89PZQMDQAwWc0+bet5v7aMkLmjbw5o+SmDPhbD4wfjm/MH2lzXVcaMkrHRMujhzfumZLw0mBsdGmi3p4mt0nNgVOIwLEi/02k+u8IFf61KC6AOYWpdm+u2LpvVHNiohyzLKKkrB2Bryj5l0OQOGS8RdT/ssdG9MbDRw8RkZiBiyGDUnimA0CJrQxYE9BoyGDGZGcEbHBEREREREdkpZYde2/MuGprKGAFAOMJgFEz2fhYnyk4DsF2MN1pNTYGNcgyOG+C0T1f9Kgz6GGT1G9exL8YPm0/8t937mDv6ZvSOTLRf8AeA42WnUeFHM2ol2FHdeBlWyQqVqPKpF0qDxZZJAwB6dRhUosqHV+Keq8bKXYFGZbvkVGdpaGNN57JZSikqi2SB0WpCSZ2tb0xiBHuCEpH39GrHwEZ7AsrU9QQ/hE+dShAE9L17nkNQAwAEZmsQERERERF1OVkpmbiiRUmh8X3G4GbtNQ5NupWL5XH6GCSExwGwBTC+LzkJSWpeT+kF0TrDoLyhCptPftmBr8I/teY6v7c16GPx6FVLcNeom3D1gIkYlTgMoihCFEUsHjfX47buelNE6SIhCiJkyKhutPU0idb18npMSokwoGfcNaxR2Xp3Kq95VMIwGJqyXhTKPLUum6URNRAF2xwcLDqK4lpbxkYCAxtE5AOVqIJOpbU/juwB//b2JMzY6IGi08fCHG+AprwCkG3VT6ujk5itQUREREREFGCuyj75WiaorKHC/nOYWgerYHW5Xo3xMg5e/A4AsOvcfuw6t9/er2J8nzF4c//fPR5HhODUKDzYIrXhqG26MN6WO9JmIyW6T5vvs7sG3G31phAFEbFh0ShvqERFQxVOVRTg7QMb2xyXGipYYLVlbDQ1Dve3v0Yo0YqOgY2+Ub3xmymPtPn7oGQVSU3Bu1W710GnspWzYsYGEflKrwmD0WoCAISzx0a3wsBGDyQIAurHZSB66zbbYwDHB0/GTczWICIiIiIiCghJkvBR3mfYfPJLhwvzSqDBl8bOJXXNgY16cwPMsusLM/8t2O20TOlXEaYOQ2OLclYux9wJQY0obSSuHjgJCeFxeOfQh22uf+Owqfjgu0+82veY3iO8LsnUsgG3L0GnWL0tsLGnMBf/Or7Vq2P1FRNxVrrYlLFhK8sU3gPuGraXomr6/GtVmjbLZilZRa0ZrbYm5LVG74JcREQKvSYMVY01AJix0d0wsNFDmfsmI3zwINSfKQAAVOrjgjwiIiIiIiKi7mFPYS7e2Pd/LjMNlECDq/I7rkiShLL6loGNRphha9StEkSHklSetBXUUNw4bCq+PLMLjRajV+u3RYQICRJ6RybgpxPvtQcPJEnCJye+8Nh426CPxR1psyFJMj489qnH47jri+FxbH70plD6bHxxemeb6xr0sbhv7B34+sA3tsCGpWeWoqptylLRqjUe15ckCRsOfuBxnb0XcvGT8T/uEs3RiSg0hKubM+TCtd0/W64nYWCjCzCbzTCbzZ16PAgC+vx4Lk7/6SXAakGvykudOgbynjIvnJ+uj3MVWjhfoYNzFVo4X6Ej2HPFzwh1V+7uOG9tw8FNmJic3uYF2srGalil5tJTtowNCwAgMTIeJbXlsMquS1P5Y2LfdHxffAJnqy8EZH8SbIGXIXEDHIIIoihi0bi5Ht+rrH6Z+L70pMfgh8JdX4xAUwIbdea2G2L/PGsBRsQNwZ6DewE09djoSaWomgIb9U1ZKtoWde5dySvLb3Oua4y1+L70JMYkjQjIGImo+9NrbA3EBUFAmFoX5NFQIDGwEQSrV6/G6tWrYbXaTj63bt2K8PDOvVtDrK3D/u++g5jQG9GXChF36SQ+f/c9+/OyPgxSRESnjok8y8nJCfYQyEucq9DC+QodnKvQwvkKHcGaq/p6lhOh7keSJLzdxh3nivKGSuSV5WNU4jCPfThK68odtqs3N8CMpkCGLEMOYPkoAcD3l07gXHWRz9u27s8RrtGjvsXF/8SIeKdt3PW6UPa1+eSXTk3NWx+nrb4YgRbXqvm1J0qDcZVsm8uS2jJEam3fs3tSxobyGVUCHe5UNlR7td8/f/Mmfjrx3k6bcyIKbUowQytqkVea71evK+qaGNgIgqVLl2Lp0qWoqalBdHQ0Zs6ciaioqE47vrG+HrlLfg6xsTkVeWRlPvDvfPtjTUw00l9/FaLG84kHdTyz2YycnBzMmDEDGs5Hl8a5Ci2cr9DBuQotnK/QEey5qqmp6fRjEnW0j/I+Q4UX2QWKyoZqe6NkxybWzX04SpoCG3H6GFQ0VKHB0ghTUymqi7WlgRw+ZAAf5m32a9tHrnwAUbpe9uBMeX0FXt3zjv35pEjnwAbQ3Ovis1P/tffc8NTrQ3nuxmFTMbFveqdfoIrW9fJ63Vh9NPZdOIx9lmMAgIu1JbhYWwIA+KHyPCRJ6tYX15Tm4fbHbQQ2lGyYttSa6n0q50ZEPdeewlwcKT4OwNar55n//tmvXlfUNTGw0QVoNJpO/TIp6/WwRkZANBoB2cUJoyBAFx8PrV4PgQ3Fu4zO/pyQ/zhXoYXzFTo4V6GF8xU6gjVX/HxQV+EpW8IXewpzvW5yrbhUW+JyG6UPx/Irf4Lvik8AsAU7Khqq0GBuhEnVtUq53TxsGib3G++w7MilPIfHiREGt9uLooislEyvmokr9pzPxYL0Ozs1MLCnMBd/P/Ivr9Y16GNxubEWq/asc/n8sdJT+Mm/HsdPJ87vthfXNKrWgQ3PpajS4lNh0Md4VXoM8L6cGxH1TO5KQ/ra64q6LgY2eiBBEFA/LgPRW7e5XkGW0X/+3QxqEBERERFRt9ZWtoS3vGl63FpcWAy+OP21x3X+8s06e4bCqYofANjK+pTJVe43CoLM5NFOy6J0kQ6PXZWiaknJZPBWy1JencHb3imKBZl34p3cTR7XqTXVdeuLaxqV4yWntjI2vOm70lJnfwaIKHR48/8yg6OhjzPXQ5n7JiNiyGBAaPUREEVEpg5BTGZGUMZFRERERETUGZQL1a3vDlfu5NxTmOv1vrxpetza9NSr2yxb5a4kU4XkfSk3padDILUOWvTSRjqt0/K4AoQ2ywwp/Sh84W1PhvbyJXBl0Mfi0auWIErXy6fMA0mS2jHCrql1IKOtwAbQ3HclUuNdD5LO+gwQUWjx5v9lJThKoYuBjZ5KEND37nmA3OrkSZKYrUFERERERN2at3dytnWxWZIkfF9yEv/K+9zrY/fSRuDRq5agd2Si19u0Vot6r9aLDYvGWz/6X9uF4gAGOOaPvd3h8cXLxQ7v1Z7CXPx62wv2xzJk/OLTlR6DRd72V2jvNv7wNnC1MOMurL75WWSlZPp0wb27XlxzDmx4LkWlyErJxPIrH/Rq3c76DBBRaPH232AGR0MbS1H1YNHpYxE2aDAaCs5AAABBQOSQwczWICIiIiKibs2XOzndlblxVcaqLaMThuHXUx6BKIr4vuSkDyN25L61tqMGcyMEQUBWSiZ+qDyPfxz7DGnxqbhw+RJqjLU+H9egj8WicXMA2LIw5KaR/Hn3W/YSXgD8qmmeFp+KMLUOjRaj12NJi0/1+TX4w9sLX9FhUfaSJr5ecO+OF9c0PjYPb2lU4rA2+2105meAiEKLt/8GMzga2pix0YMJgoA+8+bCnpshy0iYOgV1ZwpQe/qM0x9jWXkwh0tERERERBQQ7b2T010Zq7ZMGXyl/cK30ii5IzVajbjcFMC4cLkYADAxJR0PTrjH530p2QiALXAhtwqvKIGLN/b9zeN+3GXC7Cs6DFn2NmQDLBo3p9PqovtzgczX+e2OF9ecm4d7H9hQ+m140pmfASIKLd78G8zgaOjj/wA9XOy4DNSommpXCgIK1q7D4ez/cf3n0cchmc3BHTAREREREVE7tedOTn8ahStMVpPD42lDrvZrP4qbh09zunCj9HiID48DAFyqLQUAXKi+CADoG9W7uY+B1rs+BoAtGwFAm6+91lTn8XlXZZeUQJGx1fvjivL6OrPZtjcXyKJ0vRwukHlzYV7RXS+uaZ2ah3tXikqhfE7dfca7Y8N1IgoMBkd7Bpai6uG0GjVORPbHxOrjELRayCYT4OouGUGALt4AQc2PDBERERERhTblQrU/ZW78aRSe3CsJRZeL7WWW/Clj5crYpJG4d+wdyCvLR2VDNWL10UiLT4UoithyajvK6itwqbYUg+MGoKi2BACQEtUHgO2i8cTkdKzZ9x62//Btm8eK1Uf79dpdaZkJ402gqJcmAovGzUVceIz99XUm5QKZqxJbivljb3MaV1ZKJn6Z9QBe2/MOTLC43ba7XlxrTykqhfI5dfUZJyLyRAmOtv7/VimryOBo6ONV6h5OJQoo1icA1cehTeoN47mzrleUZTYVJyIiIiKibsGbC9XuLjb70wuhd69EFF0uRoO50Z6dEAjhmjCIouiyD0hSRAK+x0nsKcxFYfVFWCUrNKIGsWHNWSiiKOJnE+/DkeLjqPAiyPPN+QMBGXfLTBhvgiWXzXWIC49x2++kM7i7QAYAalGNawdkudxuYt903KmbBtNgEZ+f3oFaU3Pj9+5+ca09pahacvcZJyJqC4Oj3RsDGwSrxpYOKosiIlOHoPb0GcesDVFE5OBBbCpORERERETdhnKh+u2DHzhc1NeqNLgtbRYmJqe73M7XXggGfSySIxNxELZm3v6WsQLg1Fw7XKN3ud6ewlx8W2gLQuy7cBj7cBgAYJbMePjT32DRuLn2i+miKGKxl0GeQPSBaJ0J095+J51JuUD2Ud5n+OjYFlgkWxaGRbJg2ae/dnhfWxIFAXekzcac0Tf3qItrrQMZvpaiIiIKBAZHu6/u+z8oec2q1gEApIYG9J9/t3MpKklitgYREREREXU7WSmZeHb6/zgsM1nN+OC7T7D0k6ewpzDXaRtfm0IvGjcHek0YAKCotqRdpZwye49yeOwqsKFkhNSbG13uQ2ny3fK1edvLwJvXHqmN8Ph860yY9vQ7CYZ9RYfxwXef2IMaClfva2vKxbWrB0zEqMRh3TqoAbgKbPiXsUFEROQKMzYIkrYpsNHYgJjMDGjj4mCqqLA9yWwNIiIiIiLqxvacd30hWrlQ3fLCviRJyCvLR1a/cdh88kuP+21ZZqi0rhwAUNeiDJE/DhfnOTxWAiYKXxqbbzi4CROT0+0X170p1+FNCa+fTpzftH/vapq3p99JZ/Pm/W39vvZkLUtRCYIAlagK4miIiKi7YWCDICuBjYZGCIKAyOHDULG7qXkcszWIiIiIiKibkiQJ/8zb4nGdDQc3YXyfMfj4+OfYfPJLhx4JIgRIaM54j9JG4uqBkzCxb7pDUCBMbQtAyK2z431Ub26w/yxAgE7tWNrHl+be5Q2VyCvLdyjP4U25Dm+bsXpb07w9/U46mzfvr6v3tafSiM2XnLQqLa8rEBFRQDGwQZC0TXf5mIyQrVaowpvTmXWJiczWICIiIiKibimvLB81xlqP65Q3VOL+j/8HjRbn0k4tgxq/vOIBXNFvnMsL8GFN5X81orrN7ARv6TVhEAXHY/nah8LfvhXeZnd4e3Hf22BJsIVSP5CuoGXpKZahIiKiQGNggwBdc/qytaER1rrmO5Aihw7hXRVERERERNQteXsB2lVQo7UxvUe4zSpQSkY1Wo1tZid4S68Oc1rmax+K9vStCHQzVm+CJcEWav1Agk3DwAYREXWgrnOGQEGj0mpgabrTx9pQD0tt8x1LktEUrGERERERERF5JEkSvi85ia/P7sP3JSchSZJP21Q31gRsLD9UFrp9TsnYaLQY7dkJUbpIh3XiwmLabLwdrYuy/9y6vwbgW2PzrtK3oqWu3lzbm/e3K76vwcKMDSIi6kjM2OihahuB0xeqoVarYbHKMIpaqK2NKCgoRn1l88l9Q6H7k3MiIiIiIqJg2VOY66J0UQwWjZvrtnSRq20Cpdp42e1zeiWwYTYCsGUn1DRexpsH/h/6RSXj/vHzkBafin1Fhz1mc9w16kasO/h+0z6dAxve9KtQdJW+FaEklPqBdAWOGRtaD2sSERH5jv/b9kBmixX/ygX+56+7sPzPO/DDxRqYRNsJx6oNu1FeXGFft7G4BFajMVhDJSIiIiIicrKnMBcv7VrrFKAob6jCS7vWYk9hrlM2x7fnDrrcJlA8lR9SMjYaWpS0ulRbCgAYlTjMnp2gZHO0zgow6GPx6FVLcGX/8fZlrjI2ALjdR+t9dZW+FaGmrTni+9pMKzJjg4iIOg4zNnogtUpEhA5otAByU687Y9MJh1YyI8zaIpAhyyj/di/CU/raF2mio6GLN3TmkImIiIiIiADYSkltOPiBx3Xe2Pc3vK36ABUtghgiOq53oEoQPZYfClN6bFiMkGUZgiCg6HIxACA5KslhXU+9JsxWs309s9UCSZJcZge03Ed5fSUuG2sRpeuFuPCYLte3IhSFQj+QrkCjar7kxMAGEREFGgMbPZAgCJgwENjyXfMyk2A7yYiwNkAnWxzWP/XyKofHmpgYTHhrDUQNT0yIiIiIiKhz5ZXlt5l1UWuqc1omQe6gEQGJEfEeL2orGRuSLMFsNUOr1jYHNnolOa3vqjG3UkZLkVd2Cks/ecpt6a1AN/cmR3x/26YWWwY2WIqKiIgCi7cT9FB9Y4HUlGiITTctKRkbvSz1njcUBOjiDRDUjIkREREREVHnq2yo7rB9R2rDfVpfCVgkRsZ7Xk+ls//caDHCIllRUlsGwHVgozVvSm8RdTWCINj7bDBjg4iIAo2BjR5KEIC7Zw6DpJSiarp7os3Ahiyj//y7IQgdl8ZNRERERETkzqXakg7b943Dpnq97siEoZg3+hYA7vtdKERRhK7pO1eduR67zu6DVZagEdWICYvyuK03pbc2HNwESZK8HjtRZ9EysEFERB2EgY0eLGNoPIb2i4GA5oyNZLWtv4agUtmiHy2JIiJThyAmM6NzB0pERERERARb5sIH333SIfuO1kXhjrTZHhtvL86cg6v6TwQA9I/pC6PVBAAI1+jb3L/SZ2Pltpeweu87AACzZMHDn/7GY8aFN6W3yhsqkVeW3+YYiDqb0kCcpaiIiCjQGNjowQRBwL03pEFGc4+NPmrbibk23tDcWVwhSczWICIiIiKioPAmc6E95oy+CaIoIislE6tv/gOy+mYAAIYZBgMANKIas4ZOweDY/gCAWmMd6s0NAIBwteeMDQD21uXVxssOy9sqJ+Vt6a2OLNFF5C+lgTgzNoiIKNAY2OjhMocnoI8hwp6xIdRUAgC08fEIH9C/eUVmaxARERERURB5k7nQHlc3ZWIAttJRGX1GAQAKqs4DAHr3SoQoiOiliwBga1Beb24EAIRrPWdsSJKEy0bnhuYtuSsnFauP9mr83q5H1FkkSYIk2z7TNY2XWS6NiIgCioGNHk4QBNx67WCYmgIbUqPtxFwTGYGUOXc2r8hsDSIiIiIiCqKOyEhQ+l4IgoAwjc7huX7RyQAAs9UMoLnJd6TWFti4bGqRsdFGKaq8snxYZavHddyVk0qLT3VbGkth0MciLT7V4zpEnWlPYS6WfvIUyuptN0/uOr8fSz95io3uiYgoYBjYIEwa1duesaFQR0Qidvw4++OIIYOZrUFEREREREHTERkJSo+MCE04RMHx63FKVB+Hx2pRDUmS7IGNWmMdGpoCG/o2SlG1p5yUKIpYNG6ux+0WjZsDUeTXe+oa9hTm4qVda50yrNoqu0ZEROQLnvkE0O23347Y2FjcddddwR6KT2J76ewZGwp1ZARUYc0n533vvJ3ZGkREREREFDTeZC74y1XGxdGS4xDR/B1o17l9WPrJUyioPAdAydjwrhRVe8tJZaVkumxqbtDH4tGrliArJdOr/RN1NG964bgru0ZEROQLdbAH0J088sgjuP/++/HOO+8Eeyg+0ahVEMPDHZapIyMhiCJErRaSyYReqUOCNDoiIiIiIqLmzIWXdq0N+L7VgsrhsXLHeWvlDVV4O9d20bbe3IBak61vRlsZG2nxqdCptPYMEVfaKieVlZKJicnpOHrpOLZ/uwNTrrgOY3qPYKYGdSne9MJRyq6NShzWOYMiIqJuiWdAATRlyhT06tUr2MPwi65XpMNjdaQtvVpsytqwNho7fUxEREREREQtKZkLqlaBiPZSic378+aOc0VpXTmAtntsiKLY5kVcb8pJiaKIkQlDMVCVjJEJQxnUoC6nPWXXiIiIfNElzoIuXLiAe++9FwaDAXq9HmPGjMH+/fsDtv+vvvoKt9xyC5KTkyEIAj7++GOX661evRoDBw5EWFgYsrKysHfv3oCNoasLj4pweKyKsAU6lHJUSlNxIiIiIiKiYBqfPDbg++yla77Ry5s7zhWmpsbi4RrPGRsAMDA2xeVylpOi7qS9ZdeIiIi8FfRSVJWVlbjqqqtw/fXX47PPPkNCQgJOnTqF2NhYl+vv2rULkyZNgkbj2BPi2LFjMBgMSEpKctqmrq4O6enpuP/++3HHHXe43O/GjRuRnZ2NNWvWICsrC6tWrcKsWbNw4sQJJCYmAgAyMjJgsVictt26dSuSk5N9feldSmRslMNjJWNDFaYDAFiNzNggIiIiIqLgu3S5BFbZCo2ohlly/n7mjz69Eu0/+3MneVsZGwAQ1qpc1ejE4bhz1I1Ii09l5gV1G0ovHE/BwbbKrhEREXkj6IGNP/3pT+jXrx/efvtt+7JBgwa5XFeSJCxduhRDhw7F+++/D5XKli584sQJTJ06FdnZ2Xj88cedtps9ezZmz57tcRwvv/wyHnzwQSxevBgAsGbNGnz66adYv349nnzySQDAoUOH/HmJbTKbzTCbzR2yb3fHa/k3AEREO5aiQlgYzGYzBK0WAGCqq+vUMVIzV/NFXRPnKrRwvkIH5yq0cL5CR7Dnip8R8te56gsAgMTIeFyouRSQfTZajJAkCaIo+nUnuTeBjdZ9OMb2TmOPAep2vOmF403ZNSIiorYEPbDx73//G7NmzcKcOXOwY8cO9O3bFz//+c/x4IMPOq0riiI2b96Ma6+9FgsWLMB7772HgoICTJ06FbfddpvLoIY3TCYTDhw4gBUrVjgca/r06di9e7ffr82d1atXY/Xq1bBarQBsGR/hrZp3d4acnBz7zxcvyhgGESpIAIBvDhyA9XQ+ourqoAVw4NtvYSop7vQxUrOW80VdG+cqtHC+QgfnKrRwvkJHsOaqvr4+KMel0CZJEg4UHQEAJIYb0GBuRIWXZaM82XVuH46XnsKicXMxMTm9zTvOW2aLqAQRGpXG7bqKMLXO4XFCRFy7xkzUVSm9cDYc/MDh98igj8WicXNYdo2IiAIi6IGNM2fO4PXXX0d2djZ+9atfYd++ffjFL34BrVaLhQsXOq2fnJyML7/8Etdccw3uuece7N69G9OnT8frr7/u9xjKyspgtVqdylglJSXh+PHjXu9n+vTpOHz4MOrq6pCSkoJNmzZh8uTJTustXboUS5cuRU1NDaKjozFz5kxERUW52GPHMJvNyMnJwYwZM+wlvSJyL8D45QcIl2wlp6beOBuamBicPPwdqi5ewtgRaUicPrXTxkjNXM0XdU2cq9DC+QodnKvQwvkKHcGeq5qamk4/JoW2PYW5DhdKcy99j0ht4G4QK2+owku71uLRq5a0ecf5kLgBOF52GoAtW0MQhDb3r2/VhyMh3NC+ARN1YVkpmZiYnI68snxUNlQjVh/NsmtERBRQQQ9sSJKECRMm4LnnngMAZGZm4rvvvsOaNWtcBjYAoH///njvvfdw3XXXYfDgwVi3bp1XJ5Id7YsvvvBrO41GE5Qvky2PmxATgUJRYw9shMXEQNRooNbbUqoFi5kXJ4IsWJ8T8h3nKrRwvkIH5yq0cL5CRzDPRYm8tacw12WgodZky/yJ1Eag1lRnXx6ljUSNqdavY204uAmrb37W4x3n35ectAc2Wgcs3GmdsZEYwcAGdW+iKLLcGhERdZigBzb69OmDkSNHOixLS0vDP/7xD7fbFBcXY8mSJbjllluwb98+LF++HH/961/9HkN8fDxUKhWKix1LLRUXF6N3795+7zeUxETpcFq0fbkUdTqITV80RaV5eCObhxMRERFRz7N69Wq88MILuHTpEtLT0/HXv/4VkyZNcrnuhg0b7D37FDqdDo2NjZ0x1G5LkiRsOPiBx3W0oga/ue4RVBsvI1YfjeGGwXj40994LCflTnlDJfLK8j3ecX626oJ9fW/6awCOgQ2NSoPosM7L2iciIiLqboKeA3jVVVfhxIkTDstOnjyJAQMGuFy/rKwM06ZNQ1paGj766CNs27YNGzduxGOPPeb3GLRaLcaPH49t27bZl0mShG3btrksJdXdGEvLEFZ2ERJsWS+iTofa02dQe/oMpKaAhsQvY0RERETUw2zcuBHZ2dl4+umncfDgQaSnp2PWrFkoKSlxu01UVBQuXrxo/3P27NlOHHH3lFeW32aAoqKxCqIo4uoBEzEqcRjUKjUWjZvr9zErG6oBNN9xruxXKaPTSxthX1fvR2AjITyuS1QdICIiIgpVQc/YWL58Oa688ko899xzmDt3Lvbu3Yu1a9di7VrnNGNJkjB79mwMGDAAGzduhFqtxsiRI5GTk4OpU6eib9++WL58udN2tbW1yM/Ptz8uKCjAoUOHEBcXh/79+wMAsrOzsXDhQkyYMAGTJk3CqlWrUFdX53THVXcjmc3IzX4c1ppq9GlaZqmpweHs/3FYz8LmjkRERETUw7z88st48MEH7d8J1qxZg08//RTr16/Hk08+6XIbQRB8yvo2Go0wGpuzo5XeI2azGWazuR2j941yrM48prfKaiu8Xs8c2zz+cUmj8cusB/DukX/43GC8lybC43uhVzeXn9KrdF69b2KL+wrDVFoYTUaIgu/3GnbluSJnnK/QwbkKLZyv0MG5Ci3Bni9fjhv0wMbEiRPxz3/+EytWrMDvfvc7DBo0CKtWrcL8+fOd1hVFEc899xyuueYaaLVa+/L09HR88cUXSEhIcHmM/fv34/rrr7c/zs7OBgAsXLgQGzZsAADMmzcPpaWlWLlyJS5duoSMjAxs2bLFqaF4d2OBgItmDeLhOn1HBiAAsBhZioqIiIiIeg6TyYQDBw5gxYoV9mWiKGL69OnYvXu32+1qa2sxYMAASJKEcePG4bnnnsOoUaPcrv/888/jmWeecVq+detWhIcHrjG2t3Jycjr9mG0ptpZ7td6JQ8dQdbTYafksOQulmgo0wIgwWYtvLEfRAPffb8IRhjN7T+IH4ZTbdYqspfafK0oqsHnzZo9jO2e9hP3mPPvjM1Xn8dN/PoHxmjT0V/lX/rgrzhW5x/kKHZyr0ML5Ch2cq9ASrPmq9+Hm+qAHNgDg5ptvxs033+zVujNmzHC5PDMz0+02U6ZMgSzLbe572bJlWLZsmVfj6C40ahVODr0KiUf+5fJ5e3K0iVFVIiIiIuo5ysrKYLVanW50SkpKwvHjx11uM3z4cKxfvx5jx45FdXU1XnzxRVx55ZX4/vvvkZKS4nKbFStW2G+8AmwZG/369cPMmTMRFdV5PRjMZjNycnIwY8aMLtfYXZIlHNxyymPWRZw+BgtvmO9VBsSYC4exas86t88vyZqPiX3TPe7jdMVZ/Hf7AQBA6sDBuDHjRrfr7rtwGH/bs8VpeT2M2Gk+hF+Oe6DN47XUleeKnHG+QgfnKrRwvkIH5yq0BHu+lOxlb3SJwAYFjyAImH7PLJw58TX6GMvRssqrBAE16nDEWOogMWODiIiIiMijyZMnO/Tou/LKK5GWloY33ngDv//9711uo9PpoNPpnJZrNJqgfJkM1nHbsnjcXLy0y7lcccvndVrn99GVKwdOgEqtwoaDHzj07jDoY7Fo3Bxkpbi/aU4RHd7L/nODxQiVSmXvv9GSJEl478g/PO7rvSMf4Yr+41xu70lXnStyjfMVOjhXoYXzFTo4V6ElmOei3mJggzBuRCK+GH41kltlbYiQUZw8AjHnDsDK5uFERERE1IPEx8dDpVKhuNixtFFxcbHXPTQ0Gg0yMzMd+v2Rf7JSMvHoVUuw6pt1sMpW+3JfghGt9zcxOR15ZfmobKhGrD4aafGpXgUX9hTmYv2BjfbHu87tw/HSU1g0bq7TOLxpfF7eUIm8snyMShzm02sgIiIi6sl871RG3Y6StVGkM0BqytmQIKBIZ8Do6ybYHjNjg4iIiIh6EK1Wi/Hjx2Pbtm32ZZIkYdu2bQ5ZGZ5YrVYcPXoUffr06ahh9ihZKZnQa2xNu+8Zexuevn45Vt/8rM9BDYUoihiVOAxXD5iIUYnDvA5qvLRrLSobqx2WlzdU4aVda7GnMNdheWWD43rueLseEREREdkwsEEAbFkbRwdkQYStF4kIGWeGX42hqbaawszYICIiIqKeJjs7G2+++Sbeeecd5OXl4aGHHkJdXR0WL14MAFiwYIFDc/Hf/e532Lp1K86cOYODBw/i3nvvxdmzZ/GTn/wkWC+hWzFaTKg11QEAZgy5xutgRKBIkoQNBz/wuM6Gg5sgSZL9caw+2qt9e7seEREREdmwFBUBsGVtZN54LYrO7kGysRxFOgOm3zMLKqEKAAMbRERERNTzzJs3D6WlpVi5ciUuXbqEjIwMbNmyxd5Q/Ny5cw4X1isrK/Hggw/i0qVLiI2Nxfjx4/HNN99g5MiRwXoJ3Up5fQUAQK8OQ7hG3+nH96esVFp8Kgz6GI/bGfSxSItPDeBIiYiIiLo/BjbI7rrxKVhpyMSM0n3IH3417hqRiPqzDQAAqZGlqIiIiIio51m2bBmWLVvm8rnt27c7PP7zn/+MP//5z50wqp6prL4SABAfHgtBEDr9+P6UlRJFEYvaaHy+aNycTs08ISIiIuoOePZEdrG9wnAxOgVvDfgRJtx8HQRBgKiz1bC1sscGEREREREFUVlTxkZ8RFxQju9vWSml8blBH+Ow3KCPxaNXLfG7RwgRERFRT8aMDbITBAEpCb1wpqga0b10AABVmO1vyWiELMtBuTOKiIiIiIiotK4psBEenMBGe8pKZaVkYmJyOvLK8lHZUI1YfTTS4lOZqUFERETkJ55FkYM+8REAgItltqZ8SsYGZBmSyRSsYRERERERUQ9nz9gIUmBDKSvliaeyUqIoYlTiMFw9YGKnNz4nIiIi6m54JkUOWgc2VDqt/TmJDcSJiIiIiChIgh3YAFhWioiIiKirYCkqcmAPbJTbAhuCSgVRq4VkMsHaaITGu7KyREREREREASNJEopqigEAl021kCQpaBkPLCtFREREFHwMbJCDPgbHjA0AEMPCIJlMkIzM2CAiIiIios61pzAXbx/8AJWN1QCADbmb8J/jOVg0bm7QMiSUslJEREREFBy8pYQcKBkbJRX1sFglAM0NxK2NxqCNi4iIiIiIujdJkvB9yUl8fXYfvi85CUmSsKcwFy/tWouKVg27yxuq8NKutdhTmBucwRIRERFRUDFjg+xKKxtQdbkRapUAi1XG/rxixMfoYRE1AIDK8hr0CvIYiYiIiIio+9lTmIsNBz9AeYsARlxYNEySxeN2Gw5uwsTkdJaBIiIiIuphGNggAIDZYkX2qh2oqm3OyvjD23sBAAsqjUgGsPaD/Xh6YgY0alWQRklERERERN2NkpXRWkVT6SlPyhsqkVeWz7JQRERERD0Mb2shAIBaJSIhVg9BcH7OLNriX3FhItQqfmSIiIiIiCgwJEnChoMftGsflQ1tB0CIiIiIqHthxgYBAARBwL03pOHpN3c7PSfLtr+v6i2g7kyB0/Oa6Gjo4g0dPUQiIiIiIupm8sryHcpP+SNWHx2YwRARERFRyGBgg+wyhydgaL8Y5BdW2YMZKtmKFGMpAMDy5Wc4/OVnTttpYmIw4a01EDWazhwuERERERGFuPZmWxj0sUiLTw3QaIiIiIgoVLCuENkpWRtKUAMArBBhEjwELAQBungDBDVjZERERERE5Jv2ZlssGjeHjcOJiIiIeiCeAZKDzOEJGNy3+cuFKAqoik12v4Eso//8uyG4as5BRERERETkQVp8Kgz6GI/rRGojEK7ROywz6GPx6FVLkJWS2YGjIyIiIqKuioENciAIAhbeONL+WJKBfqPdpHaLIiJThyAmM6NzBkdERERERN2KKIpYNG6ux3V+OnE+7hx5IwBguGEwnr5+OVbf/CyDGkREREQ9GAMb5CRzeALCw2ylpRJi9Uju66YxuCQxW4OIiIiIiNolKyUTj161BGpR5bA8Th9jz8qQYauXmxSZgFGJw1h+ioiIiKiH49kgOREEAeNHJAEABvaOgiosDAAg6rQtV2K2BhERERERBcTE5HSITV9PlRunHpl8vz0rQ5IlAGBAg4iIiIgAMLBBbmSN6g0AqG0wQxWmAwBIRlPzCuytQUREREREASBJEnae3QuTZIZGVGNk/FAAwMXLJc3rKIENgV9hiYiIiAhQB3sA1DUNTI4CAPxwsQbC6Ein5zWxMczWICIiIiIiv0mShI/yPsPmk1+i1lQPADBLFpyuPAsAKKy51LwuAxtERERE1AIDG+SktLIBjUYLVKKABqMFZ8oanNYJ79+f2RpEREREROSXPYW5eGPf/9kDGi01Woy2dc4fxPjkMUiLT4VVsgU2VAxsEBEREREY2KBWzBYrslftQFWt0b7s718W4Met1pMluXMHRkRERERE3cKewly8tGttm+uV1lfgmf/+GQZ9DIbEDQTAjA0iIiIisuFZITlQq0QkxOohCEAvcx2SGsvRy1zntJ6x+BKMZeVBGCEREREREYUqSZKw4eAHPm1T3lCFvRcOAWDGBhERERHZ8KyQHAiCgHtvSIMoWbGw8FMsLvwUN5XudlrPWFKKw48+DslsDsIoiYiIiIgoFOWV5aO8ocrv7VkOl4iIiIgABjbIhczhCRjcLw6X1RGQPKynjYuFoGY1MyIiIiIi8k5lQ3W7tq9o5/ZERERE1D3wqjQ5EQQB984eiQ0nMjDv4ja36/W+YVZA7pgylpbBXFPj9nlNdDR08YZ2H4eIiIiIiIIrVh/dru1NVlOARkJEREREoYyBDXIpc3gC3h4yAkUVh9DbWAERzs3CGyPa96UEACSzGYcfexzmKvd3XmliYjDhrTUQNZp2H4+IiIiIiIInLT4VBn2M3+WowjX6wA6IiIiIiEISAxtdgNlshrkTe1Uox/J0TLPFitKqBuyMc5+18X/vf4vs8WOhUav8Hossy9AaDDBX1wCyc/AEggCtIQ4WWYbQQ/t5eDNf1DVwrkIL5yt0cK5CC+crdAR7rvgZ6ZlEUcSicXPx0q61fm2fGBEf4BERERERUShiYCMIVq9ejdWrV8NqtQIAtm7divDw8E4fR05OjtvnZBnQq4GC8GQU6Qz2rA0JAhpFLcIlI3qZq7H188/R3mpUmiGDEH36jNuBFA0ZhLOffda+g3QDnuaLuhbOVWjhfIUOzlVo4XyFjmDNVX19fVCOS8GXlZKJR69agjf2/Q21pjr78jCVDo1Wo8dtNSp+hSUiIiIiBjaCYunSpVi6dClqamoQHR2NmTNnIioqqtOObzabkZOTgxkzZkDjobxT8tBS/H79PoesDREyCsL7YFTtD5g0IBITbrqx3eORZRnHTheg7kyBY9aGKCJi0EBMfPAnAenlEaq8nS8KPs5VaOF8hQ7OVWjhfIWOYM9VjYcea9T9ZaVkosHciNf2vov+0clYPG4e0uJTsa/oMDYc/MChVJVBH4ukyHgcKz0FsQd/LyAiIiKiZgxsdAEajSYoXybbOu7EkX0wtF8MTp2TUaQzINlYjiKdAefDkjCq9gdo6mtxtrgOMZE6xMe0r9btgHvvwbFnnnVcKEkYcO890Gq17dp3dxGszwn5jnMVWjhfoYNzFVo4X6EjmOei1LOZrLZyZL0jEzEqcRgAW8BjYnI6Xtz1BvYXHcG1A7Pw84kL8OredwAAoiAGbbxERERE1HXwrJDcEgQBP54xHBAE7DBkokwTjR2GTFzWRAAAzp48h+V/3oHlq3bAbLG261gxmRnQ9U5qXiCKiEwdgpjMjHbtl4iIiIiIuiajxQQA0Kodb2QSRREJEQYAQHx4LERRhCTZvm8wsEFEREREAAMb1IYJaYnQaVQ4G56MjcnT0SjqoJNsX0CizLXobSzHUNVlNP7wA4xl5X4fRxAEGK6Y1LxAktB//t09ugQVEREREVF3ZrTavleEqZwztFVNAQyrJAEApKaStQxsEBERERHAUlTUBlEUMXfaMPz9s++wsPBTRFob7c+FSyYsOv8pcB44sv99aGJiMOGtNRD9LCugS2zO2IgYMpjZGkRERERE3ZjRYmsUrlPrnJ4TxabAhiw1/W3L2FAJqk4aHRERERF1Zbzdhdp017RUqDUa1KgjILlbSRCgizdAUPsfK5OMRvvPfe+8ndkaRERERETdmFKKSqd2zthQMjOUElRSU4CDzcOJiIiICGBgg7wgiiLmzRyOnXEZ7j8wstzu0lEtAxuRgwb6vR8iIiIiIur6lFJUOpelqGyZGUrGhhLYUInM2CAiIiIiBjbIS3dNHQr18JEo0hmcszYEAfqUFKijolB7+ozfvTasjc1lrqwNjR7WJCIiIiKiUNdcispFYKNVKarmjA1+hSUiIiIi9tggLwmCgHtnj8S7x8dizqX/Oj4py2goLMSRRx8HAL97bbTM2LDW17d7zERERERE1HU1Ks3DXfXYUEpRMbBBRERERC7wrJC8lpIUicb+w2ESVJDdrdSOXhvWxhaBjYYG/wZJREREREQhQcnY0HooRSVJTc3DJQY2iIiIiKgZzwrJK2aLFY+u+goXKuqxO3YM3HbSaEevDalFKSpLPQMbRERERETdmcmiZGy4bx5uldk8nIiIiIicMbBBXlGrRCTE6iEIwO6Y0TAJzk37JAiISB2CmMwMv45hNTJjg4iIiIiop1BKUelclKJq3WPDyubhRERERNQCAxvkFUEQcO8NaZBlAKKIXbFjndYRISNx6hTUnSlA7ekzPjcSlxyahzOwQURERETUndmbh7soRWXvsSGxxwYREREROWPzcPJa5vAEDO0Xg9OFVdgTOxrDa8+ij6nCoSxVwdp1Dtv40kicGRtERERERD2H0aJkbLjvsWEvRdUU4FAxsEFEREREYMYG+UDJ2pBkAIKAnXEZ7ntt2DbwqZG4Q8ZGfX27xkpERERERF2b0YtSVEqmBjM2iIiIiKglnhWST5SsDUEACiL6olzTy/3KPjYStza2zNho9LAmERERERGFMlmW7RkbYZ5KUbXqscHABhEREREBDGyQjwRBwC1XD7b12hAEbI2fBEnlIiNDFBHpYyNxqWUpKmZsEBERERF1W2arGTJkAIDWRSkqJYBhZY8NIiIiInKBZ4XkE7PFivX/+d7++GxEX2xKvM55RUnyKVsDAKxsHk5ERERE1CMoZagAIEzlvhSVvcdGU2BDWU5EREREPRvPCsknapWIhFi9Y8Pw8GRUqJtLUkkQEOFjtoZstUK2WOyPGdggIiIiIuq+lDJUGlEN0UWwQmkezlJUREREROQKzwrJJ0oDcdlxIfbHjLA/FCFjQDuyNQAGNoiIiIiIurNGq60MravG4YD7UlQqBjaIiIiICAxskB+UBuJii7hFXuRA+88RQwb7lK0BODYOBwBLPQMbRERERETdlZKxoXPROBwAVKJjxoYkMWODiIiIiJrxrJB8pmRtSC3SNhpUYbA0fZzEK6fg9IVq5BdWoazKuwCFZGTGBhERERFRT2EPbLhoHA4AYlP2d+seGwxsEBEREREAqIM9AApNmcMTMCQlGqcLq20LBAHVmkgYzDVYu+08zu7eAQCI6aXD+l/PgEat8rg/e8aGKAKSBGtDA2RZ9qmcFRERERERhQajvRSVm4wNpceG1KrHBpuHExERERGYsUF+EgQB992Q5rCsWh0BAIiy1KGXuQ69jeUYqrqMxh9+QO3pMw5/jGXlDttKRtsXG01UVNMCCZLJ1PEvhIiIiIiIOp2SsRHWVo8N2bHHBjM2iIiIiAhgxga1w7gRiUiOj0BRWR0AoEYTCTQAyQ3FmFq2H3rJBJwHjux/32lbTUwMJry1BqJGA6C5ebgmJhrmqirbsvp6qHSuv+gQEREREVHoarTYbmzSuu2xoQQ2rE1/s3k4ERERETXjWSH5TRAE/OyOMdCobR+jyyo9ACDz8mlbUMP9htDFGyCom+NqUlMpKlVYGFR6237YZ4OIiIiIqHsyWT332LCXopLlpr+ZsUFEREREzXhWSO2SOTwJv16cBQCoUkcCAGRPGwCALKP//Lsd+mdYm5qHOwQ26hnYICIiIqLgWr16NQYOHIiwsDBkZWVh7969Xm33/vvvQxAE3HbbbR07wBDVqJSiUnkuRSVJVoe/lYAHEREREfVsDGxQu2UOT0BqSgxqtLbAhsd234KAyNQhiMnMcFisZGyIOh1U4czYICIiIqLg27hxI7Kzs/H000/j4MGDSE9Px6xZs1BSUuJxux9++AGPPfYYrrnmmk4aaegxKqWo3GRsOPfYkJuWe/y2QUREREQ9BAMb1G6CIODWawajpkXGhuzuC4eLbA3AdcaGhRkbRERERBREL7/8Mh588EEsXrwYI0eOxJo1axAeHo7169e73cZqtWL+/Pl45plnMHjw4E4cbWgxWs0AgLA2e2xIkGQJclNeuCgyY4OIiIiIfGweLkkSduzYgZ07d+Ls2bOor69HQkICMjMzMX36dPTr16+jxkldmNlixfr/fI/L6nBIECBCBmTXBalcZWsALTI2wnTssUFEREREQWcymXDgwAGsWLHCvkwURUyfPh27d+92u93vfvc7JCYm4oEHHsDOnTvbPI7RaITRaLQ/rqmpAQCYzWaYzeZ2vALfKMfqrGM2mGzn+hpR7fKYktWWqWGVrDCamvv3SRYrzGLnvS9dUWfPFbUP5yt0cK5CC+crdHCuQkuw58uX43oV2GhoaMBLL72E119/HRUVFcjIyEBycjL0ej3y8/Px8ccf48EHH8TMmTOxcuVKXHHFFX4PnkKPWiWiv96C4rJK1Kt0iLQ2QoLrdCBX2RoAYG1sytjQtQxs1HfgqImIiIiI3CsrK4PVakVSUpLD8qSkJBw/ftzlNl9//TXWrVuHQ4cOeX2c559/Hs8884zT8q1btyI8PNynMQdCTk5OpxzntPkMAKAgvwCbf9js9HyNVAcAMJqM+Oyz5ue/yPkCGsGn+/O6rc6aKwoMzlfo4FyFFs5X6OBchZZgzVd9vffXg706Ixw2bBgmT56MN998EzNmzIBGo3Fa5+zZs/j73/+OH//4x3jqqafw4IMPej9iCmmyxYIbj34I1F62L3NX40wWBNSePmN/rImOhi7eAMmoZGyEQdX0Bc7a0NhhYyYiIiIiCqTLly/jvvvuw5tvvon4+Hivt1uxYgWys7Ptj2tqatCvXz/MnDkTUVFRHTFUl8xmM3Jyctx+3wu0/D2XcObCBYwdNQazhlzn9HxJXRn+8/lOqNQqzJg1E+//2/bl+oZZN0Dnpi9HT9HZc0Xtw/kKHZyr0ML5Ch2cq9AS7PlSspe94VVgY+vWrUhLS/O4zoABA7BixQo89thjOHfunNcDoNAnqNWI6J2I2vzLnhuHA8j77e8dHmtiYjDhrTWwNpWismVshAEArD5E6IiIiIiIAik+Ph4qlQrFxcUOy4uLi9G7d2+n9U+fPo0ffvgBt9xyi32ZJNnKKanVapw4cQJDhgxx2k6n00Gn0zkt12g0Qfky2VnHNUsWAEC4Ntzl8bQaW/DCKktQqZr7aui0WmhUvCgCBO8zQv7hfIUOzlVo4XyFDs5VaAnmuai3vGoe3lZQo/XBXZ2wU/clCAIGzL+7zaCGiw2hizdAUKvtpajEsDCo7Rkb7LFBRERERMGh1Woxfvx4bNu2zb5MkiRs27YNkydPdlp/xIgROHr0KA4dOmT/c+utt+L666/HoUOH2I+wFaPV1jcjzE32hUqwBTMkyQqrbHVaTkREREQ9m1/FSXfu3Ik33ngDp0+fxocffoi+ffvivffew6BBg3D11VcHeowUAmIyMxCROgSX8087RMvc9doAAMiyveeGUopKFaaDpPTYqGdgg4iIiIiCJzs7GwsXLsSECRMwadIkrFq1CnV1dVi8eDEAYMGCBejbty+ef/55hIWFYfTo0Q7bx8TEAIDTcgIaLbbzf63KdWBDFG3fIqyyBKss2Ze76tdHRERERD2PVxkbLf3jH//ArFmzoNfrkZubC2PTBenq6mo899xzAR8ghQYla6P1B0oEUK7pBal1PocoIjJ1CGIyMwA0Nw8XdWEtmoczsEFEREREwTNv3jy8+OKLWLlyJTIyMnDo0CFs2bLF3lD83LlzuHjxYpBHGZqMlrYyNpq/WViaylaJgsjABhEREREB8CNj49lnn8WaNWuwYMECvP/++/blV111FZ599tmADo5CS+usDQkCLunisDMuA/MubnNcWZLs2RoA7BkbpspKWBtsvTWM5eUuG40TEREREXWWZcuWYdmyZS6f2759u8dtN2zYEPgBdRNKKSqd2rm/COBYcspibQ5sEBEREREBfgQ2Tpw4gWuvvdZpeXR0NKqqqgIxJgpRStbGsWdsAS4RMnbGZaAgPBlFOgP6GMshAJABlOrjMXHMGPu2lqbsjB/WvW1fVnvyFA5n/4/9sdJoXGSjISIiIiKikGZsKkWlc1eKqkVmhtJoXMXABhERERE18fnMsHfv3sjPz3da/vXXX2Pw4MEBGRSFLiVrAwCKdAYUhCcDgoCdcRn2YlQCgAt9R8F49ixqT59B7ekzsNTWet5xi0bjREREREQU2pRSVDo3pahEsTljw8yMDSIiIiJqxeerxA8++CAeeeQRrF+/HoIgoKioCLt378Zjjz2G3/zmNx0xRgohgiBg4H3zcWjVGuzQjwWa7rQqCE9GsSYGSeYqAEBm/g4ceXSH9ztu0WiciIiIiIhClyzLXpSictFjQ2Rgg4iIiIhsfA5sPPnkk5AkCdOmTUN9fT2uvfZa6HQ6PPbYY3j44Yc7YowUYmIy0nHt+tV49VebAbPVtlAQ8KVhPH58aVvrNuIOBK0WstkMyHLzQlFE5OBB9kbjREREREQUukxWs/3nMLelqJqDGMr6zNggIiIiIoXPZ4aCIOCpp55CRUUFvvvuO3z77bcoLS3F73//+44YH4UoURQxb8Ywh2VnI/vioi7O43bJt9zsGNQAnBqNExERERFR6GowN9h/PlX+AyRJclpHEAR7IMPCHhtERERE1IrfZ4ZarRYjR47EpEmTEBkZGcgxUTfxo2sHQyXaghG9zHVIaixHqSYWgK2BuCvGK6dC3X9g8wJBgLr/QJQlDERZVYObrYiIiIiIKBTsKczF41ufsz/+/Y6/YOknT2FPYa7TukpgQ2kezowNIiIiIlJ4VYrqjjvu8HqHH330kd+Doe5Fo1YhKS4cxaU1WFj4KSKtjfbnXOVeyAAee20PBpmHYB5+aFoo42/mIShY9RVieumw/tczoFGrXGxNRERERERdjSRJyCvLR2VDNS7VluCD7z5xWqe8oQov7VqLR69agqyUTPtylSDCAjYPJyIiIiJnXgU2oqOjO3oc1A0JgoAlt4/Bb9fuRo06AuHWRo8pQlZBBUEUUBCeDKOghk62oEodiYLwZAgCkBCjh1rFLzNERERERKFgT2EuNhz8AOUNVV6tv+HgJkxMTrc3CRdFEbAC5qYeGyxFRUREREQKrwIbb7/9dkePo1u4/fbbsX37dkybNg0ffvhhsIfTJYwbnoi+iZHYWZ+BeRe3eVxX1Ott7TUEAYX6RAypL8J5fSIgCJBl4N4b0thng4iIiIgoBOwpzMVLu9b6tE15QyXyyvIxKtHWq08l2DK1WYqKiIiIiFrjmWEAPfLII3j33XeDPYwuRRAE3H/LaBSEJ6NIZ4DksgiVTZ3Rij6mCvQ2lqNabevbIkOAKABD+8Ugc3hCZw2biIiIiIj8JEkSNhz8wK9tKxuq7T8rGRpKxoaSyUFERERE5FXGRmsffvghPvjgA5w7dw4mk8nhuYMHDwZkYKFoypQp2L59e7CH0eVMSEuETqvGzjjPWRu9rA1YeM6x5m60uRYSszWIiIiIiEJGXlm+1+WnWovVN5dBVgIZzNggIiIiotZ8PjN85ZVXsHjxYiQlJSE3NxeTJk2CwWDAmTNnMHv27HYN5o9//CMEQcAvf/nLdu2nta+++gq33HILkpOTIQgCPv74Y5frrV69GgMHDkRYWBiysrKwd+/egI6jpxJFEXOnDXPK2pCb/riiLI821zJbg4iIiIgohLTMuvCFQR+LtPhU+2MlkGFpCmywxwYRERERKXzO2Hjttdewdu1a3H333diwYQMef/xxDB48GCtXrkRFRYXfA9m3bx/eeOMNjB071uN6u3btwqRJk6DRaByWHzt2DAaDAUlJSdm1ZwkAALr8SURBVE7b1NXVIT09Hffffz/uuOMOl/vduHEjsrOzsWbNGmRlZWHVqlWYNWsWTpw4gcTERABARkYGLBaL07Zbt25FcnKyty/Vidlshtls9nt7f47X8u/O8KNrB+CDbScdsjY85V8oz/Wy1mPetCEu3/eeIhjzRf7hXIUWzlfo4FyFFs5X6Aj2XPEz0n21zLrwxaJxcxzKTTWXomLGBhERERE58jmwce7cOVx55ZUAAL1ej8uXLwMA7rvvPlxxxRV49dVXfR5EbW0t5s+fjzfffBPPPvus2/UkScLSpUsxdOhQvP/++1CpbM3kTpw4galTpyI7OxuPP/6403azZ89uM5vk5ZdfxoMPPojFixcDANasWYNPP/0U69evx5NPPgkAOHTokM+vzZXVq1dj9erVsFqtAGyBkfDw8IDs2xc5OTmderwxfYH9JlvWRrKxHEXaOEAQ0MdY7hDkkCCgWBeHRGMFVJBRfPgrbD4T4XHfYm0dhMZGt8/L+jBIEZ730dV19nyR/zhXoYXzFTo4V6GF8xU6gjVX9fX1QTkudby0+FQY9DFel6My6GOxaNwcZKVkOixv3TycGRtEREREpPA5sNG7d29UVFRgwIAB6N+/P7799lukp6ejoKAAsuyusJBnS5cuxU033YTp06d7DGyIoojNmzfj2muvxYIFC/Dee++hoKAAU6dOxW233eYyqOENk8mEAwcOYMWKFQ7Hmj59Onbv3u3XPj1ZunQpli5dipqaGkRHR2PmzJmIiooK+HHcMZvNyMnJwYwZM5wyXzrSbFnGE6u/wVcNmZheug874sdBlGWnvhsiZHwVl4GZZXsRa76Mq8eMRq+RaW73K5nNOPSzZbBUu09518REI/31VyF24usNlGDNF/mOcxVaOF+hg3MVWjhfoSPYc1VTU9Ppx6TOIYoiFo2bi5d2rfW43vyxtyHVMAhp8akuG4Pbe2wozcMZ2CAiIiKiJj4HNqZOnYp///vfyMzMxOLFi7F8+XJ8+OGH2L9/v9syT568//77OHjwIPbt2+fV+snJyfjyyy9xzTXX4J577sHu3bsxffp0vP766z4fW1FWVgar1epUxiopKQnHjx/3ej/Tp0/H4cOHUVdXh5SUFGzatAmTJ09uczuNRhOUL5PBOO59s0fi6cJqvDXgR7YFsowinQF9TBUQZBkQBBRp41AQnoxqdQRizZdhqajwOE5ZrUZYQjxqa2oAV8E1QYAuPh5avT6kG5AH63NCvuNchRbOV+jgXIUWzlfoCOa5KHVfWSmZePSqJdhw8AOHzI2YsChUNdqCWtOHXIMIrfvM9dYZG66CH0RERETUM/kc2Fi7di0kSQJgyzwwGAz45ptvcOutt+KnP/2pT/s6f/48HnnkEeTk5CAsLMzr7fr374/33nsP1113HQYPHox169Z1iQvWX3zxRbCH0OVlDk/A0H4xOHW+CjqNCkaz1aHvBmQZO+My0DexF6pLI4EGoLboEhI97FMQBPSffzeOPeMm20eW0X/+3V3iM0JERERE1FNkpWRiYnI6nvriTzhdeQ4AcFvaLGzI3QS9OgzhGr3H7cWm83cLe2wQERERUSs+nxmKogi1ujke8uMf/xivvPIKHn74YWi1Wp/2deDAAZSUlGDcuHFQq9VQq9XYsWMHXnnlFajVansPitaKi4uxZMkS3HLLLaivr8fy5ct9fRkO4uPjoVKpUFxc7HSc3r17t2vf5EgQBCy4MQ39EiNx6zWDEKZT27Izom3ZMjUxvVGmjcYAuQqCyvY5u3T0OGpPn7H/MZaVO+03JjMDkalDgNZ3cYkiIlOHICYzo6NfGhERERERtSKKInRqnf3x8bLTAABDeGybNx41Z2ywFBUREREROfI5Y+Ptt99GZGQk5syZ47B806ZNqK+vx8KFC73e17Rp03D06FGHZYsXL8aIESPwxBNP2JuDt1RWVoZp06YhLS0NmzZtwsmTJzFlyhTodDq8+OKLvr4cAIBWq8X48eOxbds23HbbbQBsjcq3bduGZcuW+bVPci9jWCL+8ugU3P/7HDQaLYAgYHPEGMyob8Q2/UgsLNyMyLPNjcDlvKM4nP0/9seamBhMeGuNQ78Mt1kbksRsDSIiIiKiIFJKSQFAXmk+ACA+PLbN7Zp7bLB5OBERERE58jmw8fzzz+ONN95wWp6YmIglS5b4FNjo1asXRo8e7bAsIiICBoPBaTlgCzbMnj0bAwYMwMaNG6FWqzFy5Ejk5ORg6tSp6Nu3r8vsjdraWuTn59sfFxQU4NChQ4iLi0P//v0BANnZ2Vi4cCEmTJiASZMmYdWqVairq8PixYu9fj3kPbVKREKsHlW1RgDA2fBkW98NWUaNOgLh1kbX6USCADE2FoLa+aMbk5kBfb9+aDh/3r5u5JDBzNYgIiIiIgoipZQUAFQ39deID49rczslkGHvscHABhERERE18fnM8Ny5cxg0aJDT8gEDBuDcuXMBGZQ7oijiueeewz/+8Q+Hslfp6en44osvnLJIFPv370dmZiYyMzMB2IIYmZmZWLlypX2defPm4cUXX8TKlSuRkZGBQ4cOYcuWLU4NxSkwBEHAvTekuXoCO+My3H8wZRk55t6oPpXvVJJKEAQkXHOVw7rM1iAiIiIiCq6WGRsKgxcZGyqxqRSVtakUleic0U9EREREPZPPGRuJiYk4cuQIBg4c6LD88OHDMBgM7R7Q9u3bPT4/Y8YMl8uVoIUrU6ZMgSzLbR572bJlLD3ViVo2Em+pIDwZRdo49DFVwFVI4trC3fj+f3a7LEmljom2/6xLTGS2BhERERFRkLkKbHiTsSE6ZWzwhiUiIiIisvE5Y+Puu+/GL37xC/z3v/+F1WqF1WrFl19+iUceeQQ//vGPO2KM1E21lbXh8WuLIEAXb3AqSWWuqLT/HD16JLM1iIiIiIiCrGUpKsVlYy0kSfK4nRLYsNh7bDBjg4iIiIhsfM7Y+P3vf48ffvgB06ZNg7rporIkSViwYAGee+65gA+QurfM4QlITYlGfmG1w/KCiL4o1/SCwXzZ9YZuyky1LE8laLSttyIiIiIiok5mlsxOy949/A98enIbFo2bi6wU19n3zj02eNMSEREREdn4nLGh1WqxceNGnDhxAn/729/w0Ucf4fTp01i/fr1D3wsibwiCgPtmj3T1BL4wTHS9kSgiMnWIyzJTpoqK5p/Ly52eJyIiIiKiztVoMbpcXt5QhZd2rcWewlyXzys9NZTACDM2iIiIiEjhc2BDMXToUMyZMwezZ89GZWUlKisr296IyAWl1wYA6DS2LyupKdGQUtNQrunlvIEkQT3rVpRXNzo91TKYYSqvcHqeiIiIiIg6jyRJMFmdMzZa2nBwk8uyVPaMDauSseH311ciIiIi6mZ8PjP85S9/iXXr1gEArFYrrrvuOowbNw79+vVrs/E3kSuCIGDBjWnolxiJu2cOQ7/ESMy/YQTKqhuxNX4SzFBBaf0uAyjSGfDkljIsX7UDZovVYV8tS1EZmbFBRERERBRUx0pPtblOeUMl8srynZazFBURERERueNzYOPDDz9Eeno6AOA///kPzpw5g+PHj2P58uV46qmnAj5A6hkyhiXitSem4c6pw/DaE9MwfkQS+sRH4GxEX3yWeIW9kbgA4FjkQPQ2VWCo6jIaf/jBHsywNjbCWldn36elpgaSydT5L4aIiIiIiAAAFfXeZfZXNlQ7LRPtGRu2jA+lNBURERERkc+BjbKyMvTu3RsAsHnzZsydOxfDhg3D/fffj6NHjwZ8gNQzCYKA+25Ig0q2Ymr5AYfnppcfwKLzn2La/vdx5NHHcfjRxyGZzfbSU2JYGMSmfi8te24QEREREVHnitRFerVerD7aaZkoMmODiIiIiFzzObCRlJSEY8eOwWq1YsuWLZgxYwYAoL6+HioV76ChwMkcnoDB/eJQo46wl6JyKTwcdWfPoaopsKaLN0AbFwcAMLLPBhERERFR0AyO69/mOgZ9LNLiU52WK83CLU09Ntg8nIiIiIgUal83WLx4MebOnYs+ffpAEARMnz4dALBnzx6MGDEi4AOknksQBPx45gj834kMzLu4ze165qIiHHn0cftjTWwsIMtovHTJoZk4ERERERF1LldNwVtbNG6OPTujJaXHhtx0mxObhxMRERGRwufAxm9/+1uMHj0a58+fx5w5c6DT6QAAKpUKTz75ZMAHSD3bhLRE/G90PxRVGNDbWO5VipGo00JQ2T7aLZuJExEREVH3JkkSXnjhBfz73/+GyWTCtGnT8PTTT0Ov1wd7aD2WWbL1x1CLakTrIlHeUGV/zqCPxaJxc5CVkuly29bBDpWL4AcRERER9Uw+BzYA4K677nJatnDhwnYPhqg1URQxd/pw7PzHeY9ZGy1V7T8IsSngxh4bRERERD3HH/7wB/z2t7/F9OnTodfr8Ze//AUlJSVYv359sIfWYyn9MXRqLVbf/AfkleWjsqEasfpopMWnuszUULQuPcWMDSIiIiJS+BXYIOpMd01LxQdfnHDI2pABeGodKGg0gNGIy6fyUXv6jH25JjoaunhDRw+ZiIiIiILg3XffxWuvvYaf/vSnAIAvvvgCN910E9566y2PF9Cp4yj9MTSiGqIoYlTiMK+3bR3IYGCDiIiIiBQMbFCXJ4oi5s0cjp2bmrM2PAU1AMBaWwsAqD1+Aoez/8e+XBMTgwlvrYGo0XTUcImIiIgoSM6dO4cbb7zR/nj69OkQBAFFRUVISUkJ4sh6LiVjQyP6/tWzdekpBjaIiIiISMEzQwoJd00dCvXwkbios2VbmCA2tRD0gSBAF2+AoGY8j4iIiKg7slgsCAsLc1im0WhgNpuDNCIyN2VsqFW+n4O3DmSoGNggIiIioia8wkshQRAE3Dt7JNafzMSM0n042mswrq/I9W0nsoz+8++GILSV70FEREREoUiWZSxatAi6pn5rANDY2Iif/exniIiIsC/76KOPgjG8Hsliz9jwPWOaPTaIiIiIyB2fAxs1NTUulwuCAJ1OB61W2+5BEbmSOTwB2uEj8VZ4MiDLGF57FsmmCpf9Nlwt0yUmwlRTg5IdX0EdGQltTAx7bhARERF1IwsXLnRadu+99wZhJKRgKSoiIiIi6gg+n13GxMR4vOM9JSUFixYtwtNPP80GfRRQgiBgwY1peOOjI7BYJexoGIcbi79BtLXeeV0X2xtLSpD/51cclrHnBhEREVH38fbbbwd7CNSK2WorAxaQUlT8fklERERETXw+M9ywYQOSk5Pxq1/9Ch9//DE+/vhj/OpXv0Lfvn3x+uuvY8mSJXjllVfwxz/+sSPGSz1cxrBEvP7kdDx0ZwbOhifj9YF3okgbBwD2nhtS0582e3Cw5wYRERFRjyHLMj777DPcddddwR5Kj2KRrAD8y9hoHdhgxgYRERERKXw+u3znnXfw0ksvYe7cufZlt9xyC8aMGYM33ngD27ZtQ//+/fGHP/wBv/rVrwI6WCJF5vAEpKZEI7+wGjviHTM3RABHIgdjbO0Zzzthzw0iIiKibq+goADr16/Hhg0bUFpaiunTpwd7SD2KvceGHxkb7LFBRERERO74fGb4zTffIDMz02l5ZmYmdu/eDQC4+uqrce7cufaPjsgNQRCw8KaRiI8Oa87c0Nl6ZRTpDNicMBmmVl+EHHcgIjJ1CGIyMzpnwERERETUaYxGI/72t79h6tSpGD58OJ577jlkZ2ejpKQEn3zySbCH16OYrbbAhpo9NoiIiIgogHw+M+zXrx/WrVvntHzdunXo168fAKC8vByxsbHtHx2RBxnDErH+NzORmhINCAJ2GDJRponGDkMmoFJhV+xY9xvLEuKuuw51ZwpQe/qMwx9jWXnnvQgiIiIiCpgDBw7g5z//OXr37o1Vq1bhtttuw/nz5yGKImbNmoWoqKhgD7HHMUu2HhuBKEWlYmCDiIiIiJr4fHb54osvYs6cOfjss88wceJEAMD+/ftx/PhxfPjhhwCAffv2Yd68eYEdKZELSubGqv93EGeRjLcG/Mj+3J7Y0Rhedw69jeUQYeu5IbT4+9y69XCVV8SG4kREREShKSsrCw8//DC+/fZbDB8+PNjDITSXovKneThLURERERGROz6fXd566604fvw43njjDZw8eRIAMHv2bHz88ccYOHAgAOChhx4K6CCJPMkYloi3V87Cz/64DUVldc1PCAJ2xmVg3sVttofKYk87EwRooqNRd/ac294bmuho6OINARk7EREREQXOtGnTsG7dOpSUlOC+++7DrFmz2E8tyJRSVBrR95uGxFZzpxI9lJolIiIioh7F99tmAAwaNAh//OMfAz0WIr8JgoCf3TEGv1+/F2aLZF9eEJ6MIp0BycZye6aGR7IMY1kZjjz6uNtVvM3oMJaWwVxT434/DJAQERERBdTnn3+O8+fP4+2338ZDDz2EhoYGeyY5AxzBYVaah/vVY6N1xgbnkIiIiIhs/ApsVFVVYd26dcjLywMAjBo1Cvfffz+io6MDOjgiX2QOT8KvF2fh6Td3Ny9s6r0xo2QvtLIZvawNHoMb4UMGQxAE1J0+A8iy8wqCAF28AYLa86+OZDbj8GOPw1xV7XYdlrwiIiIiCrx+/fph5cqVWLlyJXJycvD2229DrVbjRz/6Ee666y7ceeedGD9+fLCH2WO0pxRV69JTosCMDSIiIiKy8blI6f79+zFkyBD8+c9/RkVFBSoqKvDyyy9jyJAhOHjwYEeMkchrmcMTMLRfjMOys+HJeGvgbfgs8co2MzbC+/eDvl8/10ENAJBl9J9/d5t3/AlqNXTx8YC79bwMkBARERGR/2bMmIG///3vKCoqwi9+8Qt89tlnmDRpUrCH1aM0l6LyJ2OjdWCDGRtEREREZOPz2eXy5ctx66234s0334S66aKsxWLBT37yE/zyl7/EV199FfBBEnlLEAQsuDENb3x0BDKAC6XNPTeUslR9jOVuAxxl/93hcf8RQwYjJjPDq3H0n383jj3zrOsVvAyQEBEREZF/GhsbceTIEZSUlECSJPTv3x/PPPMMTp8+Heyh9Sj2UlRsHk5EREREAeTz2eX+/fsdghoAoFar8fjjj2PChAkBHRyRPzKGJeL1J6fj0MkSrPnHYZRUNdr6brRqJu6P/vfe43UwIiYzA5GpQ1DbuqyVKCJy8CCvAiRERERE5LstW7ZgwYIFKCsrc3pOEAQsX748CKPqmSxNGRtqPzI2Wgcy2DyciIiIiBQ+3/ISFRWFc+fOOS0/f/48evXqFZBBEQVCxrBErFkxA3fPHG5fpmRtSG23EXcSltwHsT4EI5SsDaeyVpLEbA0iIiKiDvTwww9jzpw5uHjxIiRJcvhjtVqDPbwexSyZAfhXisq5xwbPn4mIiIjIxufAxrx58/DAAw9g48aNOH/+PM6fP4/3338fP/nJT3D33Xd3xBiJ2uWuqUMxtF+MLZTRlLUhojnY4KabhpOBixb4HIyIycyAqNM2LxBFRKYOYbYGERERUQcqLi5GdnY2kpKSgj2UHq9dpaha9dhoXZqKiIiIiHoun88uX3zxRVsfgwULYLE0naRqNHjooYfwxz/+MeADJGovQRBw7w1pePrN3QCaszaSjeUo1/SCwXzZq/0YKyptZaWaaKKjoYs3eNxGMhohmcwtFjBbg4iIiKij3XXXXdi+fTuGDBkS7KH0eM2lqDQ+b+vcY4Pn0ERERERk43NgQ6vV4i9/+Quef/55e+O9IUOGIDw8POCDIwqUzOEJGNovBqfOVwGCgB2GTMwo3Yec+Am4ruIQehvLIcKWvSG0+LulgjVrHR6rIyORtvIpiGq12yBH7al8h1JUzNYgIiIi6nivvvoq5syZg507d2LMmDHQaBwvqv/iF78I0sh6HnvGRkBKUTFjg4iIiIhsfD+7bBIeHo4xY8YEcixEHUYQBCy4MQ1vfHQEkizjbFky3hrwIwDATsDeUFwJZnhzL5ilthZHH18BANDExGDCW2sgtvrSfPnESYfH/e75MbM1iIiIiDrY//t//w9bt25FWFgYtm/f7nD+JQgCAxudyBLAUlStAx1ERERE1HN5dXZ5xx13eL3Djz76yO/BEHWkjGGJeP3J6Th4vMRelgpwLE1lElTQylaYRTU0TV/CvKGOjETd2XOAJEFQNd9JVnHgoON6ERHtfyFERERE5NFTTz2FZ555Bk8++SREsX0Xw1evXo0XXngBly5dQnp6Ov76179i0qRJLtf96KOP8NxzzyE/Px9msxlDhw7Fo48+ivvuu69dYwhlZnspqvZnbLQOdBARERFRz+XV2WV0dHRHj4Oo02QOT0BqSjTyC6ttC1qUpjoSNRhja87Y/q4+DUGQEWuudWg27kpDYSGOPPo4IAgOpaday/v9c5i44S2nzA4iIiIiChyTyYR58+a1O6ixceNGZGdnY82aNcjKysKqVaswa9YsnDhxAomJiU7rx8XF4amnnsKIESOg1WrxySefYPHixUhMTMSsWbPaNZZQ1a7m4U49NhjYICIiIiIbr84u33777Y4eB1GnEQQBC28aib+8n4uy6kYAwNnw5tJUe2PH2P8eVHfBXqbKG6JWC8lkchvcUEVGQFD7XQGOiIiIiLywcOFCbNy4Eb/61a/atZ+XX34ZDz74IBYvXgwAWLNmDT799FOsX78eTz75pNP6U6ZMcXj8yCOP4J133sHXX3/dYwMbSvPwwPTYYGCDiIiIiGx4hZV6pIxhiVj/m5l49C9f2RqKu6GUqeptrGgzawMAYiaMQ8Wu3e6fz8hgjw0iIiKiDma1WvG///u/+PzzzzF27Fin5uEvv/xym/swmUw4cOAAVqxYYV8miiKmT5+O3bvdn+8pZFnGl19+iRMnTuBPf/qT2/WMRiOMRqP9cU1NDQDAbDbDbDa3eZxAUY4V6GOarE37k33ftyxJDo8lq9Sp70lX1VFzRR2D8xU6OFehhfMVOjhXoSXY8+XLcb0KbNxwww347W9/iyuuuMLjepcvX8Zrr72GyMhILF261OtBEAWD0lB8zT8Oo6SqEWaL5Gol7IzLcMjakOG+ubinoAYAqML1/g+YiIiIiLxy9OhRZGZmAgC+++47h+e8vcmkrKwMVqsVSUlJDsuTkpJw/Phxt9tVV1ejb9++MBqNUKlUeO211zBjxgy36z///PN45plnnJZv3boV4eHhXo01kHJycgK6v9rGWgDAnm/24JSY59O21VKtw+NdO7/Gd2JkwMYW6gI9V9SxOF+hg3MVWjhfoYNzFVqCNV/19fVer+tVYGPOnDm48847ER0djVtuuQUTJkxAcnIywsLCUFlZiWPHjuHrr7/G5s2bcdNNN+GFF17we/BEnSljWCLWrJiBTdtO4t3Nrr9otWwuXq7pBYP5st/HM1dW+b0tEREREXnnv//9b9CO3atXLxw6dAi1tbXYtm0bsrOzMXjwYKcyVYoVK1YgOzvb/rimpgb9+vXDzJkzERUV1Umjtt0dl5OTgxkzZjhluLTHvz7ZCZiMmHLtdUiJ6uPTtkWXi/FJztf2x1Oum4I+vZx7m/Q0HTVX1DE4X6GDcxVaOF+hg3MVWoI9X0r2sje8Cmw88MADuPfee7Fp0yZs3LgRa9euRXW1rfGyIAgYOXIkZs2ahX379iEtLc2/URMF0V1Th2L30YvIP1/lXHCqRXPxnPgJuK48F8mmCu93LgrQJSTAWFwCU4UP2xERERFR0MTHx0OlUqG4uNhheXFxMXr37u12O1EUkZqaCgDIyMhAXl4enn/+ebeBDZ1OB51O57Rco9EE5ctkoI9raWoerteG+bxfndbxfdFqtbwg0kKwPiPkH85X6OBchRbOV+jgXIWWYJ6Lesvr7ms6nQ733nsv/vOf/6CyshKVlZUoKipCY2Mjjh49ihdffJFBDQpZgiDg3hvS3HbRUJqLn43oix3x41At+lBSSpLRe6at/AADG0REREShQavVYvz48di2rbkkqSRJ2LZtGyZPnuz1fiRJcuih0dOYmwIbapXv7R1VrZqFt35MRERERD2X32eG0dHR6N27NyNt1G1kDk/A0H4xba53NjwZrw+6C+WaXl7tNzJ1CGInTQTAUlREREREoSQ7Oxtvvvkm3nnnHeTl5eGhhx5CXV0dFi9eDABYsGCBQ3Px559/Hjk5OThz5gzy8vLw0ksv4b333sO9994brJcQVJIswSpZAQAa0Z/AhsrhscjABhERERE18f3skqibUpqJv/HREUiyjKIyD81qBAFb4yfhrovboYLVKUIoaNSQzRaoo6KQOH2qfbmlthZWoxEqF+UGiIiIiKhrmTdvHkpLS7Fy5UpcunQJGRkZ2LJli72h+Llz5yCKzWeCdXV1+PnPf47CwkLo9XqMGDEC//d//4d58+YF6yUElaUpqAEAGtH3G+JavrcAMzaIiIiIqBkDG0QtZAxLxOtPTsehkyX4y/u5KKtudLvu2Yi++KjPFMy7uM3pOdlsS7m31NTgzJo3oYmJgaDVQjaZYK6shMpDXWYiIiIi6jqWLVuGZcuWuXxu+/btDo+fffZZPPvss50wqtBgsVrsPweiFBUzNoiIiIhIwcAGkQsZwxKx/jczkb1qB/ILq92uVxCejCJtHJJNFZABCG7WU0dGQoYMi8mE4m3boU9JdnhOGxMDTXQ0dPGGwL4QIiIiIqIgMUtm+89qUeVhTddaBzJaZ3AQERERUc/FwAaRG4IgYOFNIz1nbggCdsSPw43F3yDa6r50VUNhof3nwg82uVxHHRmJtJVPQVTbfi0Z6CAiIiKiUKY0DleJKr+yLZixQURERETu+HxmeP78eRS2uEi7d+9e/PKXv8TatWsDOjCirkDJ3FCaimvVzr8yZ8OT8frAO1GkM0BqlbMhATAJKkheHMtSW4ujj6/A4ez/sf159HFIZnPbGxIRERERdUFKKSp/GocDgCiyeTgRERERuebzmeE999yD//73vwCAS5cuYcaMGdi7dy+eeuop/O53vwv4AImCTWkq3i8xEj+eOdzdStgZlwERssNiEcDu2DG+/6IJAnTxBghqJlURERERUWhSMjb8DWy0zthg83AiIiIiUvh8Zvjdd99h0qRJAIAPPvgAo0ePxjfffIO//e1v2LBhQ6DHR9QlZAxLxGtPTMNdU4ciNSXa5ToF4ckOWRsSBBTpDNgdM7ppuQ9kGQlTp6DuTAFM5eXtfwFERERERJ3MIlkB+Nc4HHDRY4OBDSIiIiJq4vOZodlshk6nAwB88cUXuPXWWwEAI0aMwMWLFwM7OqIuRum7ER8d5upJh6wNETJ2xmUAoti03DcFa9fhcPb/4PsnfgVYre0eOxERERFRZzJbbWVV/c3YEAQBgtBc6pWBDSIiIiJS+HxmOGrUKKxZswY7d+5ETk4ObrjhBgBAUVERDAY2Oqbur3XfjZaUrA0AKNIZUBCebF9+0desDQAQBGgNBoj1Dag7U4Da02dc/jGWMauDiIiIiLoWi70UlcbvfagEW5+N1kEOIiIiIurZfL515k9/+hNuv/12vPDCC1i4cCHS09MBAP/+97/tJaqIujul78YbHx2BJMsoKqtXnsAOQyZmlO7DDkMmoHz5EgR8FZeBeRe3+XYgWUafOXfi8qq/4vtNH7ldTRMTgwlvrYGo8f9LIxERERFRICk9NvwtRQXY+mpY0BzgICIiIiIC/AhsTJkyBWVlZaipqUFsbKx9+ZIlSxAeHh7QwYWa22+/Hdu3b8e0adPw4YcfBns41MEyhiXi9Sen49DJEvzl/VyUVTcCAM6GJ+OtAT9yWl/J5kg2lsMMEZq28jcEAfq+faGJiYEUpoNoNAKy7HI9NhonIiIioq5AkiTkleWjsqEaJbVlAPwvRQUAoigCVkBktgYRERERteDzGWZDQwNkWbYHNc6ePYt//vOfSEtLw6xZswI+wFDyyCOP4P7778c777wT7KFQJ1JKUz36l69w6nyV+xVbZHMc7TUI11QehRqS62AFAMgyGgoLkffkU55/UWUZ/effzdR8IiIiIgqqPYW52HDwA5Q3VDksb7A0+r1PJVODGRtERERE1JLPPTZ+9KMf4d133wUAVFVVISsrCy+99BJuu+02vP766wEfYCiZMmUKevXqFexhUBAopalSEiKQHO+YuSQKQN+ECMT20tmzOfbEjUXDnYsdgxoqVXPpKm+JIiJThyAmM6P9L4KIiIiIyE97CnPx0q61TkENALhQcwl7CnP92q+qqWE4MzaIiIiIqCWfAxsHDx7ENddcAwD48MMPkZSUhLNnz+Ldd9/FK6+84vMAXn/9dYwdOxZRUVGIiorC5MmT8dlnn/m8H0+++uor3HLLLUhOToYgCPj4449drrd69WoMHDgQYWFhyMrKwt69ewM6DurelNJUD92ZjvjoMPtySQbuv2W0U2LG6lyjQ6PxrX2ucp+94Y4kIWHqFFQeyEXJjq9QceAgm4sTERERUaeSJAkbDn7gcZ0NBzdBktooxeqCqAQ2RGZsEBEREVEzn0tR1dfX27MStm7dijvuuAOiKOKKK67A2bNnfR5ASkoK/vjHP2Lo0KGQZRnvvPMOfvSjHyE3NxejRo1yWn/Xrl2YNGkSNK2aJB87dgwGgwFJSUlO29TV1SE9PR33338/7rjjDpfj2LhxI7Kzs7FmzRpkZWVh1apVmDVrFk6cOIHExEQAQEZGBiwWi9O2W7duRXJyss+vXWE2m2E2m/3e3p/jtfybAmvUoFi88eT1eGL1N8gvrEZqSjTSU2MRHxOGqlpj84otSlPtjEvHTRe/8et4BWvXtbmOJiYa6a+/yubiHYy/W6GF8xU6OFehhfMVOoI9V/yMdB95ZfkuMzVaKm+oRF5ZPkYlDvNp36KoZGz4fE8eEREREXVjPgc2UlNT8fHHH+P222/H559/juXLlwMASkpKEBUV5fMAbrnlFofHf/jDH/D666/j22+/dQpsSJKEpUuXYujQoXj//fehUtnu2jlx4gSmTp2K7OxsPP74407HmD17NmbPnu1xHC+//DIefPBBLF68GACwZs0afPrpp1i/fj2efPJJAMChQ4d8fn2urF69GqtXr4bVagVgC4wEo/F6Tk5Opx+zJxkaC5RVAENjq7FlyxakxgD5hY7r2BuNyzJq1BGIsDbC3yR7GXC5rQygXq3Glq1bfS91RX7h71Zo4XyFDs5VaOF8hY5gzVV9fX1QjkuBV9lQHdD1WmIpKiIiIiJyxefAxsqVK3HPPfdg+fLlmDp1KiZPngzAdnE+MzOzXYOxWq3YtGkT6urq7PttSRRFbN68Gddeey0WLFiA9957DwUFBZg6dSpuu+02l0ENb5hMJhw4cAArVqxwONb06dOxe/duv1+PO0uXLsXSpUtRU1OD6OhozJw506+gkL/MZjNycnIwY8YMp8wXCqwHW/wsyzLym7I4nAgCdsZlYN7FbX4fy91XPQHAqJ8tQUxGut/7Ju/wdyu0cL5CB+cqtHC+Qkew56qmpqbTj0kdI1YfHdD1WmLzcCIiIiJyxefAxl133YWrr74aFy9eRHp684XSadOm4fbbb/drEEePHsXkyZPR2NiIyMhI/POf/8TIkSNdrpucnIwvv/wS11xzDe655x7s3r0b06dPb1fj8rKyMlitVqcyVklJSTh+/LjX+5k+fToOHz6Muro6pKSkYNOmTS4DNK1pNJqgfJkM1nF7svtmj8TTb7oOlhWEJ6NIZ0BvYwVE+NhrA4Cg0UC2WBz7dIgiIgcPQvyE8RB4l1un4e9WaOF8hQ7OVWjhfIWOYJ6LUveQFp8Kgz7GYzkqgz4WafGpPu+7uRQVz2WJiIiIqJlfhUp79+6NzMxMFBUVobDQVltn0qRJGDFihF+DGD58OA4dOoQ9e/bgoYcewsKFC3Hs2DG36/fv3x/vvfceNm7cCLVajXXr1nWJi7ZffPEFSktLUV9fj8LCQq+CGtSzZA5PwNB+Ma6zK5qyNvwJagCAbDY7Nx+XJPSff3eX+P0gIiIiou5JFEUsGjfX4zqLxs2xByl82ndTKSpmbBARERFRSz6fWUqShN/97neIjo7GgAEDMGDAAMTExOD3v/89JEnyaxBarRapqakYP348nn/+eaSnp+Mvf/mL2/WLi4uxZMkS3HLLLaivr7f3+fBXfHw8VCoViouLnY7Tu3fvdu2bqCVBEHDvDWluQxdK1obUFPqQAJj9DnUAUKkQNXpUm6sZS8tQe/qM2z/GsnJ/R0BEREREPUBWSiYevWoJDPoYp+cm9B2LrBT/yhY399hg83AiIiIiauZzKaqnnnoK69atwx//+EdcddVVAICvv/4av/3tb9HY2Ig//OEP7R6UJEkwGo0unysrK8O0adOQlpaGTZs24eTJk5gyZQp0Oh1efPFFv46n1Woxfvx4bNu2Dbfddpt9DNu2bcOyZcv8fRlELilZG6fOVzk/2arXhghgZ9xYXFdxyK9jaWNjIbZR5kEym3H4scdhrnLfzFETE4MJb61pc1/+MpaWweyhzrYmOhq6eEOHHJuIiIiIAiMrJRPj+4zBPR8+7LC8f3Rfv/epZGr4k+1BRERERN2Xz4GNd955B2+99RZuvfVW+7KxY8eib9+++PnPf+5zYGPFihWYPXs2+vfvj8uXL+Pvf/87tm/fjs8//9xpXUmSMHv2bAwYMMBehmrkyJHIycnB1KlT0bdvX5fZG7W1tcjPz7c/LigowKFDhxAXF4f+/fsDALKzs7Fw4UJMmDABkyZNwqpVq1BXV4fFixf79HqI2iIIAhbcmIY3PjoCGcCF0jqH55WsjWRjOYp0BuyOGY2hdeftvTckCCjXxyHeUgPBbPZ4LG1iAkq/2gkAMF++DGt9A1Themh69YI6MhLamBjIsgx1r14wV9c4l7KyDRi6eAMEtc//XHilKwRWiIiIiCgwJNk5i7+yvgqSJPlXikpkxgYREREROfP5SmVFRYXLXhojRoxARUWFzwMoKSnBggULcPHiRURHR2Ps2LH4/PPPMWPGDKd1RVHEc889h2uuuQZarda+PD09HV988QUSEhJcHmP//v24/vrr7Y+zs7MBAAsXLsSGDRsAAPPmzUNpaSlWrlyJS5cuISMjA1u2bHFqKE4UCBnDEvH6k9Nx6GSJc4BDELDDkIkZpfuww5AJiGKrLA4ZX8ZkINFYgesrcj0ep/ZYHk4dy2vfYGUZCVOnoO5MQYdkTghqNXTx8UELrBARERFR4Jgli9Oy//6wG0eK87Bo3FyfS1Kp7D02GNggIiIiomY+XylMT0/Hq6++ildeecVh+auvvor09HSfB7Bu3Tqf1ncV8ACAzEz3J8hTpkyB7OqCaSvLli1j6SnqVK0DHA0mC8qrjTgbnoy3BvzIvl7rLI6C8GQUhCdjeN059DaW+94sxwVBq4VsMrl8rmCt7fe0IzInBEFA//l349gzz7peQZbZAJ2IiIgoROwpPORyeXlDFV7atRaPXrXEp+CGyB4bREREROSCz2eH//u//4v169dj5MiReOCBB/DAAw9g5MiR2LBhA1544YWOGCNRt6cEOB6ZlwmNWoTTNfymLI4yTbQti0MQ7P04AvUVL2HqFM8rdGDmRExmBiJThwCtyxOIIiJThyAmMyPgxyQiIiKiwJIkCe8f/ZfHdTYc3ARJci5X5Y5KZMYGERERETnz+ezwuuuuw8mTJ3H77bejqqoKVVVVuOOOO3DixAlcc801HTFGoh4jc3gSfr04y2VFJiWL42x4sn2ZksnRWpUuyudjl2zZ6nmFDsycULI20PpLriQxW4OIiIgoROSV5aOqscbjOuUNlcgry/e4Tksim4cTERERkQt+3XqdnJzs1CS8sLAQS5Yswdq1awMyMKKeKnN4Aob2i8Gp81VIjo9AUVmd+5WVfhwleyEIMgzmyyjSGXB88BWYmvdp4AYliogcPKhDMydiMjOgjTfAVFbeacckIiIiosCpbKgO6HpAc6YGS1ERERERUUsBOzssLy/3uV8GETkTBAELbkxDv8RI/OyOMRjS13P2xdnwZLw18DZsTciyl6raa4pDkc4A75P829AJmROCICBi0MBOPSYRERERBU6sPjqg6wGAKDZlbDCwQUREREQt8OyQqAvKGJaI156YhszhSbj3hhGI0LW9jUOpqkD23xCETutzIVms9p/DB/RntgYRERFRCEmLT0WULtLjOgZ9LNLiU73eJzM2iIiIiMgVnh0SdXHpQ+Px40lAaortzjat2rtf25b9N0xNv+ouWne0TZaRMHUK6s4UoPb0GdSePgOjUi4qwIzFxfafk6ZPY7YGERERUQgRRRE3DJ3icZ1F4+b41C9DCWiweTgRERERteRXjw0i6lyCAMyfNRzr/3MM0yb2wydfF6CsurHNjXYYMjGjdB+ORA3G+KoTiLbWNz8vis7NupWDiSJgbc6eKFjrWGZOHRmJtJVPQWcwQBfv3LzcH7LVCmNJqf2xLiE+IPslIiIios6TGjcIAKASVLDKzeeTBn0sFo2bg6yUTJ/2x4wNIiIiInLF68DGHXfc4fH5qqqq9o6FiDxIHxqP156YBgC44/qhePQvX+HU+SqP2yjlqQBgb8xoLCjcjGRjOYp0BhzsOxE3n9nivJEsIywpEY1FF93u11Jbi6OPr4AmJgYT3loDUaPx+3UpjGXlkC0W+2MT/00hIiIiCjkWyXY+NygmBfMz7kBlQzVi9dFIi0/1KVNDoWzjz7ZERERE1H15HdiIjvbc4C06OhoLFixo94CIqG1Kg/E3PjoCSZZRVFbvzUb2DI4dhkw0GvpDakiBeLEQMgChaR3dwIEYtGA+8p55ts1dqiMjUXf2nL1klCY62u8MjsZLlxwem6uq/dpPsBhLy9BQUQFVWTnqzhRArXb857U97w0RERFRqFACGxq1FqMSh7V7fyqBzcOJiIiIyJnXgY233367I8dBRD7KGJaI15+cjkMnS/CX93PbLk0FxwwOVDZiozACN6oqmktUyTL+IQ7HM2PGIDJ1CGrzT3vcX0NhIY48+rj9cXsyOJwDG1U+7yNYJLMZhx97HOaqasQC+P7fnzqtE8jslu6otLIB1XVGt8/HROoQH6PvxBERERGRP8xWW2BDLaoCsj8Ve2wQERERkQvssUEU4jKGJWL9b2Z6VZqqtbPhyXh94J0OJapK4/pj15EiCJOmQ9NGYMOBIEAXb4Cg9u+flcZLtsbholYLyWSCKYQyNgS1Grr4eJirawDZRYv2dr433Z3ZYkX2qh2oqvUQ2Oilw/pfz4BGHZiLJERERNQxzErGhhiY8x7BlleMsvpKfF9y0u+SVkRERETUvfAqG1E30LI0lQzgQmkdkuMjUFRW583GDiWqiisb8fLfcwFZxgKdAb2N5fDqq6MsI2HqFFQeyIWlrta+WB0ZCW1MjP2xu5JMjRdtGRuRqUNQcywvpDI2BEFA//l345i78l2yjP7z77aX7CJHapWIhFg9quuM7uJCSIjRQ63iRQwiIqKuziKZAQBqVfu/au4pzMVX5/YCAE6UncYz//0zDPoYLBo31+cm5ERERETUvTCwQdRNtCxNtfafR/HgbaPx7uY85Be2nfngUKJKIQjYGZeBeRe3eT2GgrXr2lxHFR6OQT+5H5qYaECGPQhy+VQ+AEATHQPA1rPCWFYeMn0pYjIzEDFkMGrPFEBoeXVeFBE5eBBiMjOCNrauThAE3HtDGp5+c7fL52UZuPeGNAaGiIiIQoBSiqq9GRt7CnPx0q61TsvLG6rw0q61ePSqJQxuEBEREfVgDGwQdTMZwxLx2hPTANguGK/6fwdRXuO+xI8nBeHJKNLGIdlUEbDxWevrkf/Kq26fL99tu7htKi/H4UcfD5m+FIIgoO/d83Dy2ecdn5AkZmt4IXN4Aob2i0F+YZVD1oYoAENSYpA5PCF4gyMiIiKvWSQrAEAj+n/+JkkSNhz8wOM6Gw5uwsTkdJalIiIiIuqheBZI1I1lDEvE2ytnITk+wr8dCAJ2xI9DtRge2IF5SWuIC6m+FNHpY2FulWESmTqE2RpeULI2WpeikpitQUREFFKUHhvtKUWVV5aP8oYqj+uUN1Qiryzf72MQERERUWhjYIOomxMEAT+7Yww0ahH+XBs+G56M1wfdiXJNL7hof9Ch+tx8U0hd0BYEAfXjMhyW9fvx3JB6DcGUOTwBfVoE4UQBGNqP2RpEREShxN5jQ1T5vY/KhrZLqfqyHhERERF1PwxsEPUAmcOT8OvFWU53w2u8bcYsCPgifhI6+/K8PrlPJx+x/ay9Ih0em6qqUXv6jP2Psaw8SCPr+gRBwNXpyfbHzNYgIiIKPYHosRGrjw7oekRERETU/YROjRciahelh8Gp81XomxABQRAwbUIK/r71JCxWCbIMCIDbrIyC8GQU6QzobayACNm+XkdecjZX13Tg3gNPMpsR/ckWh2WnX33N4bEqOhqT1r0REn1DgqFvQnPGxuC+0czWICIiCjFKKSpNO0pRpcWnwqCP8ViOyqCPRVp8qt/HICIiIqLQxsAGUQ8hCAIW3JiGtf88iiW3j0HGsEQAwOC+sXj6TVvDbhlAcnwEisrqXO0AO+MyMO/iNtvDjhqoKELUaiE1NqI2/xR0rXpWAIAmOtrl8mCzQEAl9IiH62btEoASkwYWCNB27tC6PGNpGcw1NbAUFiGp0ZbVcvuwBNSdKQDQdeeciIiIHP3/9u48Pqr63B/455zZMkuSSWayJwTIRpAlQZZSbxXZwbYiqBRREO+V0kp/vYIbva5dLnbRYnstFJHaet1baW9dUEQJaFEQ2VxAIAESQkgmIQnZZjvn98csmcnMJJOQZDLJ5/165QVz5jvnfE++JMw5zzzP42kerryM5uGiKOL2CTfjiY82hxxz+4Sb2DiciIiIaAhjYINoCCnKT8Yf7p/ht803kyMvy4jb5hXimb8fxajhCdixr9xvrCdrI91ai0p1IiAI3gwOCYATIlSQLm+SkgTZ4fqkX8Wrf0PFq38LGKIyGjFxy6YBl/WgUirwtTkP5nP7gz4vAvg67yosUPa85vRgY62xwFpXh69++gs4mppgALDC8+Qzb+Kw+68Ddc2JiIjIn6MXSlEBwJTMYqy9aiWe++xVv8wNkzYBt0+4CVMyiy9r/0REREQU3RjYIBrifDM5ls0v9AY/ZFlGWWUjTlY0+A5GiakYs2r2o8Q8AaIsezM4RAC7E8bhqotHoYQTAlwZChK6/kWjSUuFUq9H88lTiMnIgKOxEY5Ll0JNGBqzCYJy4P36EgQBycPigHOu7BffrBYJAqo0iZh5yxz2jHCT7HYcvuc+2Ou7aPw5gNeciIiI/Nl7oXm4x5TMYkxKH4+vLCdxsbUBCdp4FJpzmalBRERERAxsEFHwTA5BEHDbvNHeMlUeZ3Tp2JJ9veuBLLdncGhM+DhxLC7EmPyCHX9Nm44Zlv1ItF8KWr5KUKmQs2olZIcDX/3icbSdO9f5ZGUZSdOneUsUdRTpkkVJGtfFfMdzFSGjtODfcOOo5P6f1AAlKJXQmM2uXiodO9v7kmUMW7qEASEiIqIo0Bs9NnyJoogrkvN7ZV9ERERENHgwsEFEIRUXJCE3M94/a8OXbwaHqRgQBP9yVRoTSnUZkM2CN9jRUeFP7kdC0XjIsgzDyBFoOlXa+U1uhQJlm58N+XSkSxaJNhsAoE1UQSPZvQ3Zz2tMzNboQBAEDFu6BF8+9vPOBsGQMxLG4qJ+mxcRERH1nKcU1eX02CAiIiIi6gpzeIkoJEEQsPy60TDHx4Qc48ngOKNL97wIJaZiWFTxKDEVQxDbgx1ShzwGfW6O94a15yZ3p0ENADEpyUCo4EAflCyy1ljQdKo05JfVUus33hPYaIhP8Z6tAKC04N8wgdkaAYzFRTDk5gChSkowW4OIiCiqeDM2LrPHBhERERFRZ/huk4g6VZSfjK0PzcaaDSWhMzc68C9XBUAQsCexyC9rQ0xIhGreAtQ2tMFs1AJov8kdKmtDn5uDYUuX4KtQn/APchPcWmOBvbEx5Fw7K10VTg+IjhkigjuwkVaYi+r9l2C2N8AJgdkaIXSWtSFDQGwuszWIiIiiiUNyAui9UlRERERERMHw3SYRdcmTufHUywdhaWjr0T46lqj6S+J84O0aaHbuxJxvZEMpitDGKGEcfy1iT54Kuo+ka66GKi4O2qxMtFac8w9+iCIMI0f43QTvSWDC77y76gERJEPEE9hIzTDjtdIiLKoqgQIyxg+P6+I7NHQZi4ugNptg65D9IoDZGkRERNHG4fQ0D+elJhERERH1HZaiIqKweDI38rKMAACNSuH3Z5c6lKjylJOy2pz4v92leH3XSbyw/RiePmR1l60KdPrZP+HI2vvQWl4RGGiQpICb4J7ARE9LV3VZHitIhognsGFXanDCkI1WUQ0AaDtfFXwfBEEQEDfmioDtbXFmZmsQERFFGU8pKgY2iIiIiKgvMbBBRGETBAHL5hciK9mAJbPzvX9mJumRZtJ1+fqAfhzBD4I9iUXd/uWkzR4GZVyct/dF3aefoWb3HsSNG9utwERH9uEFUA4bHhgcEQQohw2HY0SB32bR5vqUYqu7YWadypWp0XD2XDfPaGhRxcd7/253r/6FrEJmaxAREUUZb48NlqIiIiIioj7Ed5tE1C1F+cn4w/0zAACLpud7//zsWDUeeWZvrxzDt2xVuKxVF3Bk7X3dOo4+p/P+DXaHE2uf2o0Eew4Wy6f9n5RlvNWShMb1r+OR/5gCbWIixPg4b8ZGs6wCYMVFVSwyrBbUnS5HRrdmN7TIVisAwKrSwiLqkWG1oEWhjfCsiIiIqLscTjYPJyIiIqK+x3ebRNQriguSkJsZH7TBuABXD/GwuctWzareB0GQkWC/1GUGh+S+Md4dSTOuRXNpmfdxx0biSoWIpAQtyhqTXT3QO7x+tmU/YNmPL+7dBpXRiPEbfw/B6gpsXJJcJbouql0ZG83lld2e31DibHX1bjmRPRGO6vPIsFqApksRnhURERF1l6d5OEtREREREVFf4rtNIuoVnTUYlwGkm/U4b2kOO8BxRpeOLcMXYETzOSw+v7PX5wsApzc/6/e4YyNxQRBw69xC/P73ZQFBDT8+vTpEd8ZGg8Md2FDFAgBsF9hjozPOtlYAQJughNWdqaFobYrklIiIiKgH7JKrLCdLURERERFRX2KPDSLqNaEajOdlGbHyhrHdy9pw85SlCtZMvLcpDQY0nznr7dPRdKoUecpLmKzuoiSWT68OTymqOpuAWHszBHd/D7mmym+/TadKYbWEX2prsPNkbLRBgRZFDABA1cbABhERUbRh83AiIiIi6g98t0lEvcrTYHzztqOYMSkLO/eXY9n8QozPS0JelhEnyuu7u0PsSSwKmrUhqNWQ3YGE3tBaURG0T8c4petXZZuggka2+2dviCIMI0fAWFwEW0sLBKer/IKl1YnlFW/C4HTdsFe2teDwmnv99tsxQ2Qo8wQ2WqFEk9KVsaG2tkRySkRERNQD7LFBRERERP2BGRtE1Os8DcYXTc/HH+6fgaL8ZG/AIzNJj4wkPYD2jI7czHjkurM8lGJg0SdP1kZHH5vG9t1J+HK4LtBjOgY1AECSvNkazhb3jXhBQHWrgEalPnSWik/5KmovRdUqK7xNw7X2FkhST/J8iIiIes/TTz+N4cOHIyYmBlOmTMG+fftCjn3mmWfwrW99CwkJCUhISMDMmTM7HT/YyLLcnrHBUlRERERE1IcY2CCiflOUn4yND8zEqoXjkJVswJLZ+chKNmD5daOxfH4hspINWDq3AIqOwQ13M3GLMg617p4VlRoTvsyYACk9q1tzyFq65LLOQYZ/I3RtZiaUcXFoOlWKS8e+BgAodDrUNdmwJ7EodG8On/JVBEhtroyNFklEs7sUld7RhjabI5LTIiKiIe6VV17BmjVr8Mgjj+Czzz7D+PHjMWfOHFRXVwcdv2vXLixZsgQffPAB9u7di6ysLMyePRvnzp3r55lHhtPdOBxgxgYRERER9S2+2ySifufJ6ACARdPzvds920akG/Holo/9XuNpJp7dUolZNftRYirGhXorXpPzsRjlYR03Jj0NmTcuRN2/PkZzWVmP5t4xDBGsfJWo1aKhyYYGXTrErGw4y8+ELF9FLp5SVC2SwhvY0Mh2XGpogS4mPpJTIyKiIezJJ5/EnXfeiRUrVgAANm3ahDfffBNbt27FAw88EDD+hRde8Hu8ZcsW/O1vf8POnTuxbNmyfplzJDmk9g8kMLBBRERERH2J7zaJaMCZMCoZ6WY9Ki3NAc+d0aVjS/b13seeMlXp1lrYBAXUshNSohliYz3gdAKyDAgCBKUSI79/J0RRRPaypfjysZ93e14yALuggEp2hs7EAIAYVyklhULEsFuW4PQvH/d/3qd8Fbk42zw9NhSwiio4BBFKWUJTdS1SUhjYICKi/mez2XDgwAGsW7fOu00URcycORN79+4Nax8tLS2w2+1ITEwMOcZqtcJqtXofNzY2AgDsdjvsdnsPZ999nmNdzjFbrG3ev8uS3K/zH0p6Y62o/3C9ogfXKrpwvaIH1yq6RHq9unNcBjaIaMARBAGrFo7Fz7bug90hdTUYJaZizKrZjyNxIzGusRQ7YoogauT2huOyjMKf3I+EovEAAGNxEZTxcXA0NHZvXgD2JozFNXWHOh0nuwMbcQY1WjJzUKeKQ6K90TtfZVY2LEnD4axvhdmo7dYcBiPJbofs7mNiE1SAIKBVqUOsvQnNlloAIyM7QSIiGpIsFgucTidSUlL8tqekpODYsWNh7eP+++9Heno6Zs6cGXLM+vXr8dhjjwVsf/fdd6HT6bo36V6wY8eOHr+2RXYFNgQI2P729t6aEoVwOWtF/Y/rFT24VtGF6xU9uFbRJVLr1eLpXxsGBjaIaEAqLkjBgyum4JFnuv5EpG8Wx74Ed0NxWfZmciiHDYdjRAFqLraiodkK58U6KEePhWPvR4BCAUiSK7OjEzKA8xoT9hrHoLC1AsmtFv8BggDRmADpYh2aJCUgAg1NNqx5ag9yTRNwY9Uu77xesOegbMNuGGM12PrgLKiUim5+dwYXTxkqALC5y1bYYvSAvQmttRcjNS0iIqLL8vjjj+Pll1/Grl27EBMTE3LcunXrsGbNGu/jxsZGb2+OuLi4/pgqANen43bs2IFZs2ZBpVL1aB/VzbXY9s4uqBUqzJ8/v5dnSB69sVbUf7he0YNrFV24XtGDaxVdIr1enuzlcDCwQUQDVnFBEvKyjDhRXt/9F/tkcuxw5KJ+QwkAoOlSK35w+m8wON03053OTnbiszsAexKLAFHEB8bxWNy603+ALOOYVYd81KG8qhGxyc24pNQDAE7qs2AVlNDIDtQr9SjTpUMQgCSjFkqFGPR41hoL7J38MlfFx0NjNoU194HO2dYKABBUKsiCCKVCgCNGD1wCrBfrIzs5IiIassxmMxQKBS5cuOC3/cKFC0hNTe30tb/5zW/w+OOP47333sO4ceM6HavRaKDRaAK2q1SqiFxMXtZx3W9rlAolb1z0g0j9G6Ge4XpFD65VdOF6RQ+uVXSJ5HvRcDGwQUQDliAIWDa/EH98/QgkWUalJfx0NMA/kyNZJUIQBDRARKNSD52zDcFDCt6D+2VxVGpMKNOlAwDOalPghAAF/LM88lsqAAB5LRVIK7dg4/BFcAoKxDpaUBGTjJzWSjQpYpBirQMA3DI2A82lZQFBCslux+F77oO9viHk9FRGIyZu2QRxELwp8GRsCBrXp1lVSgWcOgMAwF7PjA0iIooMtVqNK6+8Ejt37sSCBQsAAJIkYefOnVi9enXI1/3qV7/CL37xC7zzzjuYOHFiP812YPA0D2fjcCIiIiLqa3zHSUQDWlF+MjY+MBOHvq7GUy8fhKWhresXBVF90f06QcCexKL2/htBJF07DTUf7PI+tuniUGIsdgU7ADgFBepVBpjsl4K+XgbQqNTDCREK2YnlFW96M0QyrbVYUfEmAMD6uzdxGIFBCkGphMZshr2hMXiJLEGAxmyCoBwcv8Ild+NwISYGsfZmpIgSlKLrey1XnUfTqVLv2MGUqUJERAPfmjVrsHz5ckycOBGTJ0/Ghg0b0NzcjBUrVgAAli1bhoyMDKxfvx4A8Mtf/hIPP/wwXnzxRQwfPhxVVVUAAIPBAIPBELHz6C92JwMbRERERNQ/+I6TiKJCUX4ytj40G2uf2o0T5fXIzYyHDOBUReishlDKdOmo1JiQaq0NyNoQNRrk/OiHaC0vR9PJUzDk5uCfoxfizJcXkJSgheViK2RBwHvmySGDIwKAz2NHIsVah1aFpvMMkSBBCkEQMGzpEnz52M+Dn4AsY9jSJRDcgZZo52x1laKSVSq/IBAAaE8exeE193ofD6ZMFSIiGvgWL16MmpoaPPzww6iqqkJRURG2b9/ubSh+9uxZiGL7//AbN26EzWbDjTfe6LefRx55BI8++mh/Tj0iPBkbSgY2iIiIiKiP8R0nEUUNT2mqzduOYvl1owGgZ1kcnWRtaOdch4uXbMi+bSlKn9mK7NuWwvKBqxzSrMnD8OI7xwG4giO1SgMSHU0IFl6YbdkPAGhSxGDvyGlIP7E9+FxkGUnTpwWUpDIWF8GQm4Om0lJA8snaEEUYRo6Asbioe+c8gHmbh6tdQSC9sy3o93SwZaoQEVF0WL16dcjSU7t27fJ7fPr06b6f0ABm9wQ2FPy/moiIiIj6Vqcl5omIBpqi/GT84f4ZKMpP9mZx5GUZAQBqZfi/0jxZG5L7FroEAZUaEx76Qo8fPfEBqhKyELfuMVjM2bhQ6+rtMTI9Dgp3iSS4szY6y5mQ4Cpjdd0d30alOhFBikq55rL5WRxecy8Or70Pkt3u3r0ra8MvqAEAkjSosjWA9ubhUMdgT2JR6O/pIMtUISIiGmxYioqIiIiI+gsDG0QU1TxZHFnJBtwypwDm+JhwX4g9iUUQ3eEGETL2JBYBgoCmFjvu/d0e3P3bEtz92xI0tbqCDb979RCSE3XeXZTpM1Crig15CBFA6k2LMbEwFZ+mTew0CAIASoMBzWfOwmqpBQDEF42HoFT47FCEITdnUGVrAO0ZG5JajTJdOi7GpkDuGLwYpOdOREQ0mLB5OBERERH1FwY2iCjqebI4Fk3Px9aHZiM3Mz6s13myNgCgUmNCmS690/HJiXqsXDCmfYMg4D3TpKBjJQioi03Gld+5Gpb6NiRMKOo0CAIArRUVOLL2Phz68Ro0Hv8aNR+UQHY4fXYqectWNZ0qRdOpUm8QJJo53c3DJaUaEAR8PuIbEDo2TZckKOd8F7U9bB5PREREfc/BUlRERERE1E/4jpOIBhVBELD8utFd9t5IjNOgrtGKElMxZtXsR4mpGOiixNGMiVmIN2iQkqjDhTpXeSpP1obJfslvrAgZaYsXwynJWLOhBPVNVlSaJmFx1ftdnoOjqQlH71sX9Lmyzc/6PR4MzbQ9zcMdCtc5fNQchxyNCWnWWghwlfSq0pjw+HYLjP8qwdYHZ0Hlm8lCREREAwJLURERERFRf2HGBhENOh17b3SUl2XE/1tcDAA4o0vHluzrcaaLbA0A+OO2o1izYbe3NBUAQBDwrnky7FB4yydJEGBPycSV374GSoWIpAQtBKHr0lXdNkiaaXtLUak0rg3uMmGeMJMIuB6LApKMWigV/K+LiIhoIPI2D2dgg4iIiIj6GO8OEdGg5Om9kZmkR0aSHgCQkaRHZrIBy+YXYkJBctglq/z3C6QmatubiAM4o8/A62nTvOWTRMh4W3cFHE4JgiDg1rmFkGX4BEHEkI3Eu2WQNNOW3KWonEq1d1uZLh2NCi0AoEV09d6QZeDWuYVRf75ERESDFUtREREREVF/YWCDiAatovxkbHxgJlYtHIesZANWLRyHjffPQFF+MgRBwG3zRnd7n7IM3DZvNFJ8mogDgf06GlNH4sz5RljqW1FckOTNHnEFQa7tspF4lwQB2sxMKOPior7XhqcUld396c44vRqiKOBQfD4AwCqqIIoC8rKMKC5Iitg8iYiIqHMsRUVERERE/YWBDSIa9DzNxYvyk/22FxckdStrQxRcZawmjErGyhvG+j8pCCgxFcOiikeJqRgVNc24e8Nu3L2hBA6nhO/NKvAOLdOlo1KdCAA9z9yQZW+z8cNr7sXhtfdBstu7ft0A5GkebhddPTZGZSdAkoHPY3MAAHGOFgiSk9kaREREA5wnY4OBDSIiIiLqa3zHSURDVriNxj0kn1JIEwqSkW7WodLS4n3e06+jff/w9oSYWJgMjUoBq93pCoKYJ2D+hX8h3tkS7FB+1KkpcFysh2S1hjoRv14b1hoL7I2NIfenio+Hxmzq8rj9xZOxYXMHNjKSDMjLsuLEWRltohoxkg3FCRKzNYiIiAY4O0tREREREVE/4TtOIhrSPI3G1z61GyfK673Bh3SzDjX1bXA4JciyK1sjJ7O9FJIgCPj+DePxyDN7Q+7btyeEIAi4eUY+nt/+FQBXEGTj8EVYVv4m0m11kIGQ5alyvn8nmk+ewtkXXgp5oKTp09BcWgaFToejD/wE9vqGkPNSGY2YuGUTRJUqnG9Rn+uYsaFWK3DLN1Kw6cQpXFQakGarw9yERjSXlnlfM9CCM0REROTTY4MZG0RERETUx/iOk4iGPE+j8c3bjmLGpCzs3F+OlTeMhSTBG7iQgjSu9pSyOlkRGEToGAgBgBtn5OKV947D5pA8B+4yc0OTloaE4iIYi8aj/LW/QbbZgo4r2/ys67gxMVDFxXV2sn7ZHQOBs9UV2LAKCgCARpAhbfw1VvgEZxw73sThHW96Hw+04AwRERGxxwYRERER9R/22CAiQnsfjkXT8739OHybfgdrXN1ZA/JggRBRFLF4Vr7fOE/mRseeGxIAh6BA0/TrceBYNUorG5H43evRFamtDdbq6tADfLI7mk6V+n1FqgG5pxRVmzvWro5RQ2M2Qw6VwzIAgzNEREQE2CVXvy8VS1ERERERUR/jO04iohB8MzmWzQ/euDpY1kawbA2Pm2bkY+f+clRamn0PFJC5IQJ4LXUayj5pAT75GABgNMTjx2lpsJ4/f1nn5cnu6EhpMKDw4f+CqFTCdrEeEAC10Rh0bG+WgpLaPBkbSgBOqFUKDFu6BF8+9vPgL5BlDFu6hI3EiYiIBhiHk6WoiIiIiKh/8B0nEVEnPJkcoQRrQB4sW8N3/MoFY/Holo/9tnt7blS8hXRrLSo1JpTp0n1eByQl6DDiu3fg2E9/0Utn58/R1ISj960La2xvlYKSZdnbY6NFdpWiUqsUMBYXIWbESLSUlUH05rEAEEUYRo6Asbjoso5LREREvc8hOQEAKpGlIomIiIiob7EUFRHRZfI0IM/NjAcA5GbGB83W8JgwKhnpZn3gE4KAElMxLKp4lJiKXdEMN1kGxuaacUQ2Q0o09/o5dEuHUlDWGktAWatwS1xJVqvr5AC0ye5SVEoFBEHAiGW3+Ac1AECS/EppRap8FhEREQWyu5uHsxQVEREREfU1vuMkIuoFgiBg6ZwCPPXSPiydU9BpmSRBELBq4Vj8bOs+2D2NxN3O6NKxJTt4L43XPzgJAMjWjMeN2AUFnJGJTvuUgpLsdhy+5z7Y6wMbqHv4lrgC/MtYebI1AKBVcp2NWuX6M37MFZAEAaLsH9zwLaXFJuJEREQDhyewoRQVEZ4JEREREQ12DGwQEfWS8Xlm3DjR9WdXigtS8OCKKXjkmb3dPs4ZfQZeT5uGxed39mSal02fm+MtBSUoldCYzbA3NHozLzrqWOLKNxjhaRwuxsTA6g7yqFUK1FxsRX1TG1q1RuhbLgafCJuIExERDSgOp6t5OHtsEBEREVFf4ztOIqIIKS5IQl6WESfK66FWirB1yN7oTJkuHZUaE9KtQUoxCULIIENvSJ4+DRcPHISjuQlKgwFJ069F08lT4b24QzDC2erK2FBoY2B3uOpyi6KANRtKUN9kxYj4CVjcEiKAwybiREREAwpLURERERFRf+E7TiKiCBEEAcvmF2LztqOYMSkLb3xY5m1AHsaLUWIqxqzqfRAEGSb7pfbnZBkwJwOWaqhSUmC/cKFX5+1bCqrbOgQjJHcpKkVMDKx2V2BHq1EgKUGLhmYrynTpqFXFItF+Cb7hCwkC1MOy4RhR0PO5EBERUa9i83AiIiIi6i9sHk5EFEFF+cn4w/0zsGh6PrY+NBt5WUYAgEbVdW3qM7p0bBm+AO8mTYFFGYdaVSwAoFJjwkuqcbCo4vGatgiKYcP78Ay6QRBg8CljBcBbikqh1cJmd90M0aiUuHVuoSvpRBDwnnkyOuZkiJDxVksS/nv966j/+gSbiBMREQ0ADqenxwY/P0dEREREfYuBDSKiAcKTwZGVbMCS2fnITNIjI0kfcFO/I78AhyoeJaZinNG7mpAfU6bgRXtOwGtCFb3q034Vsoys790MQRBgrbGg6VQpmk+f8T5nvHQBKW21kCvLMdokIjczHgBwVpsCZ5DvwmzLftx4fBu+uPcBHF57HyS7ve/mTkRERF1i83AiIiIi6i/8KA0R0QDiyeAAgEXT8/HZseqwG4yf0bmCGR0F68chAqhVxSLB3gQRMiQAolKFrCU34ezzL/bGqQQQ1GoojUY0Hv8aX/30F3A0NXmfay47jVtwGgBw7qdvotpoxK33/hSP/ulTOAUF6lUG/3JbfjtmE3EiIqKBwC65PmTAHhtERERE1NeYsUFENIB5GowD4ZWnCsrdj6Njuar3zJMhwtVkXARQ+F/3I3PRQhhyXRkeokYDAIhJS7usc/BOA8DRe+7H0fvW+QU1gs1XYzaheHSaK2vDXY4qJDYRJyIiihhJkvBF9df48Mx+tNhcJSbZY4OIiIiI+hoDG0REA1io8lQAoFKE/ys8WLkqTyYHANhTMlGbNBynzjXAuPAmaDMzkbXY9efI7/8H9DkjwztQJ1kTks0W3j7cgQpRFHHbvNEA4G0iLnccK4oBfTuIiIiof3xScRB3vfFfeOyD3+J3H29Fg9WVXflB2V5IUqjCl0REREREl485wkREA1zH8lSHvq7G5m1HMX1iJl5892vYHeHfOOhYrqrEVIxZNfuxQzEKZzbsBgAYdCr8+AcPoEohwjjlWtQCUM29Hnj6t13u/5Ok8Zhy/kD3TtCHBAGxuSO9gYrigiTkZsbjZEUD3jNPxuLzOzu8QELcuDGo2b3Hu0lpMEBtNEIVHw+N2dTjuRAREVFon1QcxBMfbQ763I5Tu7G3/AC+P2kppmQW9/PMiIiIiGgoYGCDiCjK+AY6RmYkhN2DI5hgfTmaWuz4xZ/2+Q+UZSxTJyLdVgcZCNrQ/LzGhIr8qbg6pg7W06cBOSC/oksiZGT7lJUSBAHLrxuNJ1/8DGVyOirViUiz1fkdv/L1fwTdl9JgQOHD/wWNycQABxERUS+SJAnPffZqp2OabM144qPNWHvVSgY3iIiIiKjXsRQVEVEUC9aDI92s7/0DCQJKzBPQoNAFBDUsqlhYVPHYZSrG9+YU4m9CgV9QI9zwhgQBF7TmgLJSV4w0uXYnCNiTWBQ0qBKMo6kJR+9bh8Nr74Nkt4f5KiIiIurKV5aTqG2tD2vsc5+9xrJURERERNTrGNggIopiHXtwZCUbsGrhWG+wozed0aVj4/BF3r4cnoDGjqQp2Dr8eqgLRmNiYTKsw/Jw3j2mVhUbdiBChIxP0ycGNAFXKkQkJWghACjTZ3gboIfF3Yhc6KT3BxEREXXPxdaGsMfWtl7EV5aTfTgbIiIiIhqKeKeHiCjKdezBAbgCHn98/QhkAOdqmgNeIyD8TAr/FwrtfTmSJuGMLt21XQYmj05BycFzGJubhF1fu8eYJ+Ka2oMB5aN8xaSnoa3yPCo1JlQnZgc5pIBb5xa6Sm4JAt41T8aN53dBCWfXQRNZ9vbg8PTe8O5Xr+vJd+CyWGsssDc2hnyefUGIiCgaJGjjuzW+O4EQIiIiIqJwMLBBRDQIFeUnY+MDM3Ho6+qgAQ4ZrpJV5y3N3Q5wBOvLAQAvvHO8/YHPmD1AYNNvN2VKCmIWLkHzS/+LEs04QBBwsqLe+7zRoIHZqPWW3DpVUY8z+gy8njYt5D476qwHh2Lat9BcWgalO6OjtwMLnkCG7WI9bA31OL3lT3C2tIQcrzIaMXHLJogqVa/NgYiIqLcVmnNh0hrDLkfV3UAIEREREVFXGNggIhrEQgU48rKMWDp3FB595uM+n0OZztX027fxuARAFhX4p34CvthuARLmugbXteDu35Z4X2uM1WDrg7OgUiraszY8+9SYkGqthQiEbGjeGUdTExLeeBtfvPG2d1tvBhYkux2H77kP9vowP6XKsllERBQlRFHE7RNuxhMfbe5yrEmbgEJzbj/MioiIiIiGEvbYICIaAjwBjlULxyEr2YBl8wsxoSC5T3pxBAjSeFwEEHP7D2DLzoMQIiIhCECSUQulwvVfVXFBEnIz471P7kks8v4n1t2gRqgD9mZgQVAqoTGbw3+BLGPY0iUBPUYGKmuNBU2nSkN+WS21kZ4iERH1oSmZxVh71Uooxc7/37x9wk0QRV52EhEREVHv4sdCiYiGEN9+HACwbH6hXyZHulmPSktgT47L5Wk8vqziLaRba1EXm4zrvnMNlF9bvFkYHckycOvcQu+NfkEQcNu80QFZG+nWWtgEBdSy8/Im2cuBBUEQMGzpEnz52M/DGQxDzkgYi4t65dh9LZxsFJbVIiIa/KZkFmNi+jh8XPEZ1Ao1bE6b9zmTNgG3T7gJUzKLIzhDIiIiIhqsGNggIhrCfEtVbd52FHcuGIPn3z6GE+X10KgUsNqdSDfrUFPfBrtDuryD+TQer58yC6/uPAFZlpFk1KKmvrXjUORmGlFckOS33ZO1cbKiwW9/R+JGYlzDKahlO+Kc/vsKlyY5GbbGRlSX7A5oNN7T3hvG4iIYcnPQdOpU593aOwmqDMSG455sFHtDoysCFTCAZbWIiIaKS7YmAMDKibfApEvAxdYGJGjjUWjOZaYGEREREfUZ3nHoRTfccAN27dqFGTNm4K9//Wukp0NEFDbfTA5BELB521HMmJSFnfvLsfKGsZAkBGRWCOj8Xn0w3sbjpwGcPhZynCwD35uVH3CjXxAELL9uNDa89BlqG61+jcz3JYxFdvM53Hh+FxRwdrvWorW6Gid/+7ugz/U0+yCsrI1OsjUGamZEl+fVg+yXzgI4DocDYnPvZxIREdHla7S6AhvGmDhckZwf4dkQERER0VDBwEYv+vGPf4w77rgDf/7znyM9FSKiHvMNciya7rpBIcsy8rKMOFFe7x0nA0g361FV2wxJDh3oMMXFoLaxrVtz0KgUmFiYEnJ+f3p4DlY9vjOgbNYZfQZeT5uGxed3dut4nbrM7ANjcRFEtRqSzRZ8QCdBgIGcGeHNRiktAySfbB5RhGHkiG6V1QongGPUxkBasABgaSsiogGlse0SACA+JjbCMyEiIiKioYS5wb1o2rRpiI3lG3oiGnwEQcCy+YXITNIjI0kPAMjLMrqyOdz32z2BDsAVmPCMWX3z+G4f7+YZ+Z2WrxAEASsXjA36nKf3Rq+RZSRNn4bm0jI0nSpF3aefoe7AZ2E3zbY3NIYOasCVcREqCODJjAga1Ogwt/5u1u2dm9ShRJkkdTtbw9tovZNO8k69nqWtiIgGGEmW0OguRRWn4XUQEREREfWfiN8hWL9+PV5//XUcO3YMWq0W3/zmN/HLX/4SBQUFvXaM3bt349e//jUOHDiA8+fPY9u2bViwYEHAuKeffhq//vWvUVVVhfHjx+P3v/89Jk+e3GvzICKKZh37cSybX4jxeUneTI68LCNum1eIZ/7eXsbKMyYjSY9zNeGVEtKoFLhxRm6X4yaMSg7e7NzTe6N6HwRBhsl+CRalAUZnK5SQQgcJOlG2+dmwxyrj4lD44DqI7pvwFw8cdE1LpYJst0NQqyHbbFDGx8HR0AhlXByaS8uC7ksVHw9jcRH0OSPRfKq007lFoiSVN2vj5CnvNkNuTreboIdT2qplQlGvNXYnIqLe0WRrgez+fzVWY4jwbIiIiIhoKIl4YKOkpAR33XUXJk2aBIfDgZ/85CeYPXs2vvzyS+j1+oDxH330ESZPngxVhxs3X375JUwmE1JSAkuXNDc3Y/z48bjjjjuwcOHCoPN45ZVXsGbNGmzatAlTpkzBhg0bMGfOHBw/fhzJyckAgKKiIjgcjoDXvvvuu0hPT+/J6QMA7HY77HZ7j1/fk+P5/kkDG9cregyVtbpiRAKeWnM1AFfvg1tm5+PZf36BW2bnY8zI9ue++60R3jF3fGc0frZ1f1j7v3F6DpxOJ5xOZ5dj/+O7o/Hff/4UDqd/sOKMLh1bhi9AdkslZtXsx46kSRBl2a9E1WFDDsY3neq4y8vmaGrC0fvWBWyX3f8uBFGEJiMd5mu+hYoXX0Hr2bM4vObeoPtSGeMxfuP/IP17N+PELx4PfVBBgNqUCIcsQ+jnf3/p37sZX/98vd/jYP9XdkU/5gpXAKe0zD/4JIrQDs+GJSN90P9sDRZD5XfhYBDpteK/kejXaHWVodKrdVCKigjPhoiIiIiGkogHNrZv3+73+LnnnkNycjIOHDiAq6++2u85SZJw1113IS8vDy+//DIUCteb5+PHj2P69OlYs2YN7rvvvoBjzJs3D/Pmzet0Hk8++STuvPNOrFixAgCwadMmvPnmm9i6dSseeOABAMChQ4d6epp+nn76aTz99NPem3bvvvsudDpdr+y7O3bs2NHvx6Se43pFj6G4VnNHAedO7MO5E8Gfl2XAbAAsTaH3IQAwGYCYlq/x1ltfh33smYXA9s+DP+fbXByyjEqNCenWWlRqTHg7eSqSbReRaqtDr+YBdCzN5EMGYDXoUT17Bs61tMDk3hbs+DKAFgA7XnwJgt2G+BDjXINlVOaMwJm33w76tNjUDKGtvc+J0NoK0dpeHkvWqCFpte2PtTGQgny4INSxTYIAQZYhKRT417kKoPJceK/tQJUzAvEdM1MkCVW5IwFBGJI/W9GM6xU9IrVWLS0tETku9Z7GNk8ZKmZrEBEREVH/inhgo6OGBlfj0MTExIDnRFHEW2+9hauvvhrLli3D888/j7KyMkyfPh0LFiwIGtQIh81mw4EDB7BuXfsnbEVRxMyZM7F3796enUgn7rrrLtx1111obGxEfHw8Zs+ejbi4uF4/Tih2ux07duzArFmzAjJfaODhekUPrlXn0vNqOs3akAH84OZJKM5P6tZ+ZVnGif/5CKfONXY+0FOiqmY/SkzFgChit6m4243GVUlmAALsNTXdeh3gCkxcsWoljEXjIcsyDvz9DUhWa8ixqvoGJPzzrc53KorQjxiOSXf+R9BSTZLdjkOrVsPRELoxd0eeTJFwylpJdjs+/dPzAAC1Tof5110X9nE6kmUZhw8cgq3W3S9EEKAfOQJFty/He++9x5+tKMHfhdEj0mvV2NjF720a8DwZG/Hsr0FERERE/WxABTYkScJ//ud/4qqrrsKYMWOCjklPT8f777+Pb33rW7jllluwd+9ezJw5Exs3buzxcS0WC5xOZ0AZq5SUFBw7dizs/cycOROHDx9Gc3MzMjMz8dprr2Hq1Kldvk6lUkXkYjJSx6We4XpFD65VcJNGp3n7cWhUCljtTuRmxgOCgJPuHh2TRqf1qI/C7d++Ak+9fBCWhrZOx/llcMDdaFydiHRbnTdzIlQGhYe9xtLt+Xnoc0bCPPFK2Cy1sDc2Qp2chLbyClfT7A69P0SNxtV0vKueIJKE7FtvgVqtDvq0rFQiJsmMpsbG8PqLCAI0ZjPUWm1Ya9FWV+f9u7O1FUqFAkInjd+7YsjNQZ0nsCHLfufGn63owvWKHpF8L0rRzRPYYONwIiIiIupvPb/z0AfuuusufP7553j55Zc7HTds2DA8//zzeOWVV6BUKvHss88OiIai7733HmpqatDS0oKKioqwghpEREOFIAhYNr8QWckGLJmdj6xkA5ZfNxrL3duWzS/s8e/yovxkbH1oNvKyjN2dFErME9Cg0HmDGX35v8mwW2+B7HDg8D334fCae11BDSBowCFj4YKuAxGC0GmzbmuNBc2lZUiafm34TdNlGcOWLgl7LWx1F9tf6nDA0RRek/jQh2+fp9ps6nYjciIi6j8NbZ7ABktREREREVH/GjAZG6tXr8Ybb7yB3bt3IzMzs9OxFy5cwMqVK/Gd73wH+/fvx913343f//73PT622WyGQqHAhQsXAo6Tmpra4/0SEZG/ovxk/OH+GQCARdPzvds92y6HJ3Dyx9ePQJJlVFrCq91+RpeOjcMXYVnFW67+G+pEQBCQaq2DiDCDAWGISU9DgvsmvcZshr0hdAaFoFIhfkIxLB9+hFZP8MP7pE92RydBCMlux+F77oO9PvwSVBBFGEaO6FYwwVs2ys1efxGquJ5/ctdmac+I0Q3PHhAfXKCBz1pjgb2Tskaq+HhozKaoOQ5RtGi0untsxDBjg4iIiIj6V8QDG7Is40c/+hG2bduGXbt2YcSIEZ2Ot1gsmDFjBgoLC/Haa6/h66+/xrRp06DRaPCb3/ymR3NQq9W48sorsXPnTixYsACAqyzWzp07sXr16h7tk4iI+l9RfjI2PjATh76uDqs0lZdv/w3zBIiyHNB7o6sSVV0Zcee/e2/SD1u6BF8+9vOQY2W7HZ/f+0CIJ2WojPGw1zdA1Mb4BSF8b7rKsgxlbGynAZQAktStbA0AsNbW+T22XayHbtiwsF8fsL/q9t4lUktrj/dDQ0c4QTyV0YiJWzaF1Tcm0schiibewAYzNoiIiIion0U8sHHXXXfhxRdfxD/+8Q/ExsaiqqoKABAfHw+tVus3VpIkzJs3D9nZ2d4yVKNHj8aOHTswffp0ZGRk4O677w44RlNTE06ePOl9XFZWhkOHDiExMRHD3Ddf1qxZg+XLl2PixImYPHkyNmzYgObmZqxYsaIPz56IiPqCpzTVmg0lOFkReBNSAKBUiLA7Je82v/4bsoxKjQnp1lpYVLFQSU7EOzvJAAnSI8OXb7YGABiLi2DIzUHTqdLwgw5u+twcpMyagdKNmyHbHaj79ACcLS2QHA6c3vInOFvCy1QBAEGphOxweB93VtYqFFudf2CjWxkiHThaWuFoavI+bj13rsf7oqHBWmOBraGh8yCeIEBjNkFQXt7bXkGp7DzbqpeOQxRNvM3DmbFBRERERP0s4ldenqbf06ZN89v+pz/9CbfffrvfNlEU8d///d/41re+5dckdfz48XjvvfeQlJQU9Biffvoprr32Wu/jNWvWAACWL1+O5557DgCwePFi1NTU4OGHH0ZVVRWKioqwffv2gIbiREQUHQRBwPLrRgfN3JAB3DQjBy+/ewJS8Bd7Mzh2JE3CGW0allW8hTRrrX/WhiBANCdDqrkQbC+uISoVRn7/Tr8sCEEQuszaCCX92/Ohcf/fJDscOPbz9d3eh0fClRNQ98k+7+PuZmsAgYENW/3FECO7Zq1xZWuIMTGQ2tpgb2iEvfESoI3p8T5p8Aq73Fo3+8aE0uXPrSwjafo0NJeWeTexNBUNdo1tbB5ORERERJER8cCG3M1Pqs6aNSvo9uLi4pCvmTZtWljHWb16NUtPERENIp7MjbVP7caJ8npoVApY7U7kZRmx6Npc1FWewPbPg7/WL4MDwJ7EooDyVJBlvKS4At/SOEJmd/xz2AxMGjMmYP89ydpQZGXj5LN/hnwpdI3/sIkiRJ3O73F80fhu78bmLkWlSkiA/eJF2C/W97gPgbW6GgCgNiXC2dwCe3096j7ZB82wLCjLK2DZ/SE0xniojcaw90mDV5cZFG76HmQihdLVz23Z5mf9HrM0FQ1mkiShttUVzK5proUkSRBFMcKzIiIiIqKhIuKBDSIior7kaSq+edtRzJiUhZ37y7FsfiEEQUBGApCTEYdT57oOFJTp0r3lqWyCAmrZiUqNCWX6DEiiGJDdkW6txXmNCdasPCgVrhs9NRdb0dBs9e5TOee7wNO/Des8GhQ6vOXIxTW2Q0gFcNm3jiQJdXs/9nvcfKoUsXm53dqNJ2PDkDMSFz89AGttXY/7ELSdd5WjbDtX6d128n/+AAAwAijd8X6390k91/Hfa0dGgwZmozbk830t3Myn7F7I1ujuMd2DWZqKBq1PKg7iT5+9iha7KyNy0/7/xWufv4HbJ9yMKZmhP3BGRERERNRbeKVFRESDXlF+Mv5w/wwAwKLp+QAAu90OQQBunTsKT//1SNeNxn3KUx2JG4lxjaUoMRUDghCQ3eEZt8tUjCvzkvDPPaWQJBkv7TiOlrb2nhaQZSxzB0s6U6eKxeZhCwBBwB4gMHOkh6Q2/3P+4pGfYvKfn/ULDnSWfSHLMqwW19z1I0fg4qcHYG9o6HEfgjaLpWcnwhvIvc7ucGLNhhLUN3US2IjVYOuDs6BSKvpxZh3m4MmgKC0DpMDCcr2ZreF7TLUp0ZutFFIvlcAiGmg+qTiIJz7aHLC9trUeT3y0GWuvWsngBhERERH1Od4BICKiIW18njlouapgfAMY+xLGhtyn77gzH5wMfXBPsKR6HwRBRoK9CSICgwE7zJNdDcrRnjmSaq29/KyNDhQxMX7BgbB7GMCVsQEA9oYGDF9+W6d9CELd7LX1NLDBG8i9TqkQkZSgRUOzNVR8CklGrTcbKVK6yqDozWwN32PGXTEalt0f+m70D+SJIgwjR/R6UIUo0iRJwnOfvdrpmOc+ew2T0sezLBURERER9Sm+2yQioiHPU64qK9mAJbPzkZmkhyle0y/HPqNLx5bhC/CeeXLQoEZMehoU+YW+k8WexKI++Q9c1GpRs3sPqkt2o7pkNy4ePgJlbKw3qBL6dTEQNa7vl/1ivfdT9Oh4U0sUYejwCXprjQVNp0rRdKoULWfLAQBqkyngmDIAUaMOa590+QRBwK1zC0O2rpBl4Na5hQMimGQsLoImOTlgu254dp/9u1DGxXv/rjIlBmYnSRKDbTQofWU5idrW+k7H1LZexFeWToL6RERERES9gBkbRERECCxXdfD4Bfxs6z44nFK4vb0vS3smRp03wCErlbh07fWYkpCOkz59QIKN7Q1tFRU48eRT3X6d1NqGr3/zJABXxobnpm7Ap+g73OwNlRFiqw0szSUASFt4A8699Eqn+6TeU1yQhLwsI05V1EPyTUYQgJxMI4oLkiI3OR+CIMA4oRgXtr/jtz3tuvl99u9CtrWX6DJ985u4uG8/rBcuuDaIAgwjRzLYRoPSxdauM/i6M46IiIiIqKeYsUFERBREcUEKHlwxpV+CGgB8MjHaD/hq0jV44pMWvLD9WJdjAUB298YQk1L6fLodOZqavX+3WmpdfQjMpvYBghCQWSEoldCYzV1mhACA3RiPuPHjEJOW6re9Lz+VP9R5sjakjskIAyhbw0Pj82/NU05NNyyrz47n9OlPo1CrEJuX2/6kxNJoNHglaOO7HtSNcUREREREPcXABhERUQieT6wDQG5mPHLdf+8rnkwMAKjUmFCmSw9rrEUVC4sqHh/EjYFFFY8XlGNQqTEF5nKIIvQ5I6EPViaqF9mbmiAIAlRGY/tGWUbS9GloLi3zlp6y1dZh2NIlwZuMd6Cqb8BXD/wX2s5X+W231lggOxwhXkWXq7ggCRlJBu9jUQDysgZOtoaHZHVlUCgMelewDICzpaXvjtfWnrHRVlUFh0+gQ5uVxWAbDVqF5lyYtMZOx5i0CSg053Y6hoiIiIjocjGwQUREFIJv743l143G8vmFyEzSIyNJDwDQqBR+f6abdVApL+O/VnczcYsqHiWm4s4zGXzG7kiagi3Z12Nfwlhsyb4eZ/QZ2JNYhIBXSxLE2d+Bas53AUny21dvunTsGBqOHUfzyVN+28s2P4vDa+5t/1p7H+LGXOHqx9FxDoIAKBRdHkuVmODX8Jx6j7XGgubSMszMAlLaapHSVouk1lrcMlaP5tIyWC2BJcMixekONKTOme3NFHI0911gwzdjo62qGq3l5d7HqbNnMFtjkHn66acxfPhwxMTEYMqUKdi3b1/IsV988QUWLVqE4cOHQxAEbNiwof8m2g9EUcTtE27udMztE25i43AiIiIi6nO8E0BERNQJ394bALDxgZk49HU1Nm87ihmTsrBzf7n3z5U3jIUkAY88szdgP4IQVmKCq5l49vVhza2zse19OGohApAgoEqTiL+8WwcAWKYxId1ai1pVLEz2S2EdL1xlm5/tepAgQGM2QVSpgvfjcGd41OzY2eluEiYU8yZyH/Dtf5IGYIXPc9bfvYnDAFRGIyZu2QTRXQItkiSrK9CgiImBUqcDADhbmjt7yWXxDWy0njsHyTdjIyOjz45L/e+VV17BmjVrsGnTJkyZMgUbNmzAnDlzcPz4cSQHaVrf0tKCkSNH4qabbsLdd98dgRn3vSmZxVh71Ups3PcXtNjb/+2btAm4fcJNmJJZHMHZEREREdFQwcAGERFRN3VsNO77pyzLyMsy4kR5PTQqBax2J9LNelRa/G+yppt1qL7YCoez+008lKIAR8fGBx25+3AsPu8KDIiQsSexyJsZUWIqxqya/XgvaSJmXzqKxGaLfxZHX5Pb+xAYi4sgqtWQbDbv3AVR7DKoAQBtF6rRdKrUb5sqPt6v5wJ1n6f/ib2hMXhEzh2YGijZMp5AgyImBgqdFkDfZmx4Sl8B8AtqAICztbXPjkv978knn8Sdd96JFStc4b1NmzbhzTffxNatW/HAAw8EjJ80aRImTZoEAEGfHyymZBbjTH0l/vrFGxiTXIBFV8xHoTmXmRpERERE1G8GxtUoERHRIOEpX+Wb0XHngjF4/u1jOFFej4wkPQRBwPc7ye4IvW8gN9OIKVek4n87NhQPwpO1kW6tDejZ4ZvtofrmCOCvW7p/su0zAwI7eoQmitBlZUEZF4emU6WwVte0BzUAQJahNpthra7uMs3l4sef4OLHn/htG0iZBN1lrbHA3tgY8vn+CtoIghA8k8ZDHlgNsj09L8QYDRSejI0+DDA4mkJngzSfOYvYUaMYXBsEbDYbDhw4gHXr1nm3iaKImTNnYu/e8H93d8VqtcLqEyxrdP8OsNvtsNvtvXacrniOFe4xbXbXnDNjU5GfMAJOpxNOp7PP5kfturtWFFlcr+jBtYouXK/owbWKLpFer+4cl4ENIiKiXhYso0MQBGzedhQrbxiLonxX+RJZlpGbGY+TFQ1h7VeWgVvnFqK4IAnvf1oekAUSwN2HY1bN/k57djx90OotTaUbORLO1lZYz58PuduY9DS0Vfo+L6NWFYsE+6XwmndJEtqqq3Fk7X0hh9gvXQqvdlcQSoMBzWfOBtx0H+iZHL7ln0Lpz6CNsbgIhtwcXDpVCsF3LUQRhpEjBlSDbG/GhsanFFUfZWxIdjtsdXUhn6949a+48O57URtco3YWiwVOpxMpKSl+21NSUnDsWNfB5XCtX78ejz32WMD2d999Fzr3v+f+tGPHjrDGfW3/GgBw9vRZvHXurb6cEoUQ7lrRwMD1ih5cq+jC9YoeXKvoEqn1amkJ/zqOgQ0iIqJ+0LFXB+AKdiy/bjSeevkgLA1tIV7ZLi/LiOKCJAiCgJULxuLRLR93+ZqwenYIAnabizH/4gGMXn4rIMv46hePQ+74SQn3De1hty1F6eZnAVlGW2Ul6mKTsdMwFjefD146SgYCGplLXXyaXpuWCggCmkvLul0iq7WiImjQZKBncgy08k8hszYkaUBlawDtgQ0xJgYKvR4A4OjGG+LuCOf7P5DKdNHAt27dOqxZs8b7uLGxEVlZWZg9ezbi4uL6bR52ux07duzArFmzoArj9+T5g5dwrOwMCvNHYX7hvH6YIXl0d60osrhe0YNrFV24XtGDaxVdIr1ejZ1UMOiIV1xEREQRVJSfjK0Pzcbap3bjRHk90s061NS3weGUIMuAKABpZr23xJXnZvKEUclBe3cAQEKsGhcv2QK2d+a0Nh1V86/GIWccYnVqxK9cjfqnf+s/yH1DO6FoPK78w+9Qf+gwSp/ZitS5C1H6wUW/ZuW+enL7O/vWWwAgaCkkTVoqlHo9mk+eCn+HlxEU6K/yUAOx/JOxuAgOjRZKqysQJQPQZWZ6y4gBAyMTxtPzQhGj6fvm4ZLUZTbRQAv8UM+YzWYoFApcuHDBb/uFCxeQmpraa8fRaDTQaDQB21UqVUQuJsM9rlN2lZ2KUcXwJkWEROrfCPUM1yt6cK2iC9crenCtoksk34uGi4ENIiKiCPPty7GyQ+8NSQZWLhiHCaOSA16zauFY/GzrPm8QRACgVIr4z+9NwB+3He26VFUHr39wsv2BLGOF1oyUVgugVgM2G5TDhsOSNBy1FfWuMeZsxK17DLIsY8TxQ/iwtQg3V/pnbUgQoE1LgfV8VXiT6FDmyJCbgyZP1oYgQFAqkbNqJSSbDcd+8Xj4J9fDoEB/l4fylH9q6pip0svln8IN1sgOB0RbezaRgMCMmIGQCeNs9W0e7gps9FXzcKfVJ2goCAFBDmVc3IAq00U9p1arceWVV2Lnzp1YsGABAECSJOzcuROrV6+O7OQGAJvTldWnVvAGBRERERH1PwY2iIiIBgDfUlWyLCMvy4gT5fXe8lPBFBek4MEVU7xBEBnAgyumYMKoZKxaCPxs6z7YHd0r4+QlCHg/oQizHPtxJHYkxjWWYocjF2c27A46PEajQJu2vVm5hwgZI+/8d5Rt+RPaKiu7Pq47K8RS34aGZiuUc74LeDJHZBnxK1ej1pyNOJ0KokYNyRpeZoo+N6dHN5v7uzxUf5R/6k6wBoLg318jcMIDouySZG0vRaXUezI2+qjHhtWnbFyQ740+exizNQaRNWvWYPny5Zg4cSImT56MDRs2oLm5GStWrAAALFu2DBkZGVi/fj0AV8PxL7/80vv3c+fO4dChQzAYDMjNzY3YefQFm9P1+5eBDSIiIiKKBAY2iIiIBhjfDA7f8lPBFBckBQ2CdAx69IRvf47PzOPgcIa+wd1mdbY3K6/eB0GQYbJfgj43BwkTiiHcKYQuseQhitBkZ6MqYRh+9uQHuNRiB2TZ29i8UmPC49stwDslMMZq8LOFC3HupZfDOhdtVibKX/sbHM3NgAAodXoodFqoYmOhNBigNhoBBJZVikR5KG/Whk+pLUMPAzPBdCdY03K2vPNSYhEojxWMs629FJVC17eBDU8/D0GjgT4r01WSS5a92RtiTEyfHJciY/HixaipqcHDDz+MqqoqFBUVYfv27d6G4mfPnoUothfgq6ysRHFxsffxb37zG/zmN7/BNddcg127dvX39PuU3ekAAKgY2CAiIiKiCGBgg4iIaAAK1mw8mM6CIL5BD1+3zhmF/33nWLfm01lQw9cZXTq2DF+A7JZK3Gw9AtW8BTh1rgFy0nBoRoyA9fTp0P0JJAmvIR9f/s+HvifoCpbU7EeJqdiVQSAASUYtsm6ahfOvb/P2V+iM5YOSsOYfrKySN9DguYHt0cvloTwEQUDmTTfi2Ppferdl3fK9XgsehBOsSZo+Dc2lZajbvx8AYBMUUMpO//4pfXT+3SVLkk+PDZ9SVC2dN6jvKckdRFFqtf7fR/e/DamtLdRLKUqtXr06ZOmpjsGK4cOHQ+6iB8tgwYwNIiIiIookBjaIiIiiXKggiCfo8cfXj0AGcK6mGXlZRtw0Mw/vHyjvdg+O7jijS8evdenA2zXA266gwhixAN+WyzpOEqJaDclqRaXGhC/F5KD78mSOAK77x7fOLYRCoUDWzYtw5vkXe2fSIcoqdVYeyhMAAHq3iba6w360GRm9sl+PkL08BAGCKKJs87P+83E3CfbTi+WxLodvYEuMiYFS56r772xpgSzLvT4/T8aGpFTDkjQcymHD4Th7GoqkZDhrqtHc0ARLfSvMRm2vHpdooGnvsaGO8EyIiIiIaCgSux5CRERE0aooPxkbH5iJVQvHISvZgGXzCyGKIlYtHAuVsv/eBggCYM3Kgz43x/8JWUbmzYvQqEvAbrMrI6MrKYlaNDS34YMD5Tg/+ioohw0P63Vd8slUaDpV6veliIsP+pKyzc/i8Jp7XV9r74Nkt1/+PAC0navs8Phcr+zXwxOs8QtqAIAsQ5OSHPL76f0cuiD0anmsy+EJNHiCZAp3jw3Z4YBkC68HS3fY3E3JzzfasWbDbjzvyIVFFY93pSwAwIXzdbh7QwnsjiDBIKJBhM3DiYiIiCiSmLFBREQ0BHTM6uiNHhzdIcvA2Lwk1GfOhqrhdSgEwFl9AYbcHGQuWoiaMd/C6TDncqGuFU++eND7eIQ9B4vl070yz46ZCh6iu7xRSL3cRLuloiLgccKVE7q9H2uNBfbGxqDPKePioBuejZbTZ7zbDLk5yFq6BF+FKFPlDXcMkN4aQHt/DVGjgSAIUMTEePtdOFtaoNBoeveAdlewxCa61tqTUZTSVgsAUEt2JBm1UCr4+SEa3OwMbBARERFRBDGwQURENET59uDQqBSw2p1IN+svq0SVWinC5pCCPvf6Byddf4mfg+yWSszRWFFwi+vmuGcupyrqIXWzPH2ZLh2V7gbjNkEBteyEJi0N1vPne3weHYmiiOBn5dbNG/2dBRwAuPp5AFDo9XA2N6Pxi68QP2aM3xjbxXo4mpv8mp/7Uuh0OPrAT2Cvbwh5HEWHgM2wpUtC9hSRAEgQoYQEUaMZENkaACBZXRkbCnfTbkEUodBp4WxugaO5BeqEhN49njtDxC74v422ia6bu2rJgVvnFg6IoA9RX2LGBhERERFFEgMbREREQ5Rv4/EZk7Kwc3857lwwBn956yucrAh9M7wzN8/ID6sx+RldOv6RuRhycyyEPaUw6FSYfEVqQKPzsPg0GD8SNxJXtpzGsIXfg/Of2+A4e7r7+wvC0dTU6fG1GRmQnBKqS3aHDDR4enBIdjsO33NfpwEHiK5P+ydcWQzL7g9R98k+1H2yr1tzVrqPZ29oDN6wXRCgMpngbHGVVhLVahiLi0L2FBEBfBpfgMkNX0GWJNc+B8DNe2erf2ADAJQ6HZzNLd5z69XjuTNE1HotRAHeQJw3sCHbUZRv7vXjEg00bB5ORERERJHEwAYREdEQ5luiatH0fACugMdTLx+EpaEt5Ovi9Go0Nvv3L+huY/ILda145h9fXMbs2/k2GN+XMBZ4p9ZVogqne2X/nZJltFZU4NjP/7vTYUqDAYUP/xcEhQLK2NjQAQfA2/tCGRfXszkJAmKSzJ2WlYIsI2X6NJz58/MBTxmLi6BKMMJ+sd41HQhoiEvGB6YJmNR0ArDb0XahGtq01J7Nrxd5moeLMe0lpzyZKH0R2PBkbAzLMkO61L7dU5pKACBbrYCWzcNpcLNJDgCAioENIiIiIooAFv8lIiIiP0X5ydj60GzkZRmDPp+XZcTzj87xPp+RpEemT2PylQvG9up8EmN71iPBU6IKAGyCAoCrDwMAaCJwQ97R1ISj963DkbX3obW8InRQw0fVG2/17GDu0lgJ7rJSngwQL1GEITcHalOid5Nks8FxyZWZIggCNEnJ7cMho6roWsiiAg5TCgD49eaIJE/zcIWmPWPDE9hw9EXGhjuQYk6OR5qpvZSXU1RCdnch8WSREA1WsiyzxwYRERERRRQDG0RERBTAU6YqM0mPjCQ9gMAAxrL5hchKNmDVwnHYeP8MFOW7boRPGJWMdLO+V+ZhNsZg9U3jYDb4NK4O/yRQYiqGRRWPDxPHQUhORdbim6DNzETO9++EJi2tR3NSJSZ2PaifiBpNyKCFb1kpTwaIlyQhafo0NJ0s9dvcduGC9+/2hvZSWVUxJqjT0pHSVos2jWttLx48iKZTpd4vq6W2d08uTN7Ahta/FBXQNxkbztZW9/G0mHxFe4BMggDBHTjzjCEarDxBDQBQK9QRnAkRERERDVUsRUVERERBFeUnY+MDM3Ho62ps3nYUK28Y6w1eeJ73lLHyJQgCVi0ci59t3Qd7iEbi4UhP0mPT/TPgcDgwcTiw/fPu78NToio3Mx5T//MaCIKAzEU3AAByVv57QB+JcOTctQpf/+oJbwmkSMq8cSHOvvCS/0ZJ8mtkHjfmClcvjA4ZImWbnw3YX1vVBcTm5cJptcJaXQ0AqFXF4tP0KzHvn5uR09Lea+TCOztw4Z0d3scqoxETt2zqrVMLm+TueeHJxgEAhd6dsdHcB6Wo3Ouu0GiQGNceTMlMNkB9UQebtY2BDRr0bD6BDZaiIiIiIqJIYMYGERERdcoTwPANanSluCAFD66YclnH/f6Ccd6b8xkJQG5mPABAo3KVlfItA9SV6ZOG4dS5BpysqIel3nXT2VhcBH3OyG7NSZ+bg8QrJyDr5kXdel1f0OfmIOPGhdBlD/Pb7snW8BBVKr/+E52xujM2Ws+dA2QZgt6AZ4YtQGV8Nhz6eHQWplIaDGg+cxa22svL3LDWWPwyQTp+dcwM8WRstEgiTlbU42RFPZol12d3aqrq/Na8N3jKTIkxMWhuc3i3f3NcOhTuvhoMbNBgZ5NcgQ1REKEUFRGeDRERERENRczYICIioj5RXJCEvCwjTpTXQ60UYetG9kZulhHFBUnex4IALJ1TgK3//BIzJmVh5/5y3LlgDDa9fjSsRuWbtx31/t2gU+GR//gGzPFaZN96S7eyNrLdmRAZixaidu8naDp5KuzX9rbspUsgiiKMxUVoOXPWu903WwNwZdAoDQbYOun74GkU7ilF1XK23PVEciogCKi7ZMXflaOwGOdC7qO1ogJH1t4HlTEeuP7bPTonyW7H4Xvug72+IeQYT2aIqHJ9Stze4goi7D1eh3d+WwIAuMZSg6kAdn10Aju/LoExVoOtD86CSnn5N2Alq7v0VUwMmlps3u0GrYqBDRoybOyvQUREREQRxowNIiIi6hOePh1ZyQbcMqcA5viYrl/kdtvcQr+b8wAwPs+MP9w/A4um5+MP989AcUEKVi0cC6Wie903mlrsuPd3e/CjJz5AVeIwqIcP7zjxoL0r9D6ZEN7eFb1JFKEb4TMXUYA+ZyT0uTmuyI4PZWysdy6OFv+b6Lrh2X6PJYcDtrqLnR46ftw4AK5SVEB7YENOau8hUaZLR6U6EZ22PBcEqE2mwL4fYRKUSmjM5oDz9d2/xmyCoGz/bI5sc5WGsovt26yiq+a/WrJDEIAkoxZKRe+87fVkbChiYtDc2p6xYWlo9QlssHk4DW42hyuox8AGEREREUUKAxtERETUZzxlrBZNz8fWh2YjL8sIoL2clEalgNjhHnbHbI3OFBek4KE7vtGjuTW12HHf7z/ES1IB7Ib49idkGcI1s/0abqvNZgy/balfsMVYXARDbk6Pjh2UJCF+7BifxzKyb70F2UuXBPTHEDVq71wav/zS77maD3b5lW5q+PxLwOmEqA7d4FdjNgMAmk+fRnXJblz87CAAwOmUkNJWi5S2WsQ6W7DHVNx5E3dZRsaSxaEDE13wBozkEOETWQ7ISPH02LAJ7YENm+i62aqRbJBl4NYggbKecrp7bIgxGjS1tmds1Na3eRuYM2ODBju75Arqsb8GEREREUUKS1ERERFRv/BkcGzedtRbTuraiVn4y1tfeceYjVosn9+9m9DFBUnIzYzHyYrQ5Ys6c0KdgidSvotl9reQbq1FpcaEv5yMxzKNCenWWuhzcjD+iV8GzEkQBGTfthSnNj8LyDLaKisBtRqw2QClEnA4QhwxkEKrhbO1FbUff+Ldps3KhDYrCxqzCYbcHDSdPIWY9DS0VZ6HzVKLqnd2QJYktFX4l4c685cXcOYvL3gfizGum+2a1FQIooCW02cCjn/ub68DAByNl3Diyafa53XgX1jh/nuTIgYbsxeiUp2INFtdYIBDFGEYOQLx48cBlaFLVnXFEzBqKi3zCy559u/bPwRoLw0VnxALUQAkGbAqXEGcGMmOvG4EysLhCaQoYmLQ1HrJu90/Y4OBDRrcbE5mbBARERFRZDFjg4iIiPqNbwbHH+6fgRun53mzOPKyjNj64KxuNSkHXAGG5deN7lapqyA7QYmpGBZVPEpMxYAoosRUjPoYI+qnzsKBY9VBm1Abi8bjyj/8Dtn/cQfqNEa8H3sFLKp4fBA3NuhhVKZExKSnuw7pk0HhuRFuq67xbmstr8CRe+6H7HAga8liQBTRVnne+/ypP2xC6abNXZ6a5G6u3Xr2LKw1ljC/If5kAI1KPZyCInTWhiQFZFP0hDdrQ+rQkyXE/j1lnyaMy4Le1oyUtlpona5tekcLbhmrR3NpWdDG4z3hbHOtlavHht27vbaegQ0aOtp7bITOBCMiIiIi6kvM2CAiIqKI8c3iWNbNTA1fRfnJ2PrQbKx9ajdOlNcjNzMeEAScKq/vvCeEjzO6dGzJvt7v8Sbdd4GPW4CPPwbQ3njct1+D0aCBaUIRPvjmMpysqMe+hLGALKOg+SxSrXUQIUOCgPrYJFy35Wk0HjmK0me2Iunaa1D+8quQHXYEnaRPP4mEKyfAMHLEZTcrVxmNEFUq2OvrXX0wOgYPQhAAlBb8G9AieHttpNvq/MbEZGZCGReH5tIyKCy1sNXWQpWaGnyHXTAWFyEmLQ1t592BHEGAIWdkQLYG0F4aalh6Au544zloHe1BhSR7A6y/W4/D7scdG4/3hLPNU4oqBs2t7YGNuktWCFksRUVDgzewIfJykoiIiIgig+9EiYiIKKI8WRyXyzdIsvy60ZAk4JFn9vbCDNt5Go/78gQ7vvOtkXjyxc88k8GexCIsPr8TACBCRupNiyGKIoxF45H188fR0GxFfFwy6p/+bfCDyTKUc76LU+dcJbaUc74LnAwxNkxt53xKRLmDGqJGA8luDxnkkCDAak7D5O9Ow4cvH3Sdm6kIN1d9AMGnF0ZbRQWOrL0PAJAA4IvdH2Lilj/2KIggCAKMReNQ5QlsBOmt4Z2fOyNFoddBijNCqmsNnpIsCBATEvwaj/eE53iixr/HhiTJsLvL8rB5OA12dk9gQ8mMDSIiIiKKDAY2iIiIaNDwDZLIsoy8LCNOlNf36TE9wQ69VonMZAPO1TRBluHKbHD36aiLTcZ137kaAGB3OLFmQwnqm6yALGOZxuTN7PCQIKBGa8Lj2y3AOyVwn5B7bO3l1RIVBL/m3Ir0DEhlpSGHi5BRP2Um/vFGe5PyMl0GzqsTkWatDVqWSgagNpkuK4jgW6pLlZAQNFsDAJzuQAM0GrxrGIsb6s4HHQdZxg57KnJPnIQ2MREas6nbc5Jl2Zsh4lAo4XC6vo8GrQpNrXa0ygrXnJixQYNceykq9tggIiIioshgjw0iIiIalDwZHJlJemQk6fv8eM2tDlRUN7XHDHz6diTddDNE0fW2S6kQkZSghSDAm9khdqhFJULGLuN4VxCi/YTcYzsRTikvWUazUut9ePSCHTWqeHjyNWS0V8aSBQGVGhOEnELXnDvMJdTRBAAZSxZfVr8N334j2oz0kPvylIZSa2NQlZCFSnViyPJjV1fsxRf3PoDDa+9zZal0k2SzeTNb2uAKYoiigMxkAwCgWWJgg4YGT/NwlcjABhERERFFBgMbRERENGgV5Sdj4wMzsWrhOL8AR7q57wMdgKtPx59zboCpeDxOVtTjZEU9ahvacOvcQm8AxJPZ4QksSHAFE8p06QH76zjWSxQRk5bml4nRGb1PH4pRLeVIsjd43xQK7i8AEGQZexKLoNOqXHMOOpcOAQdRhN1sQvz4cWHNJZQ2n8CGZLWFHCdZ3aWodFpkpcR1GnAB4Ne7pLskd7YGALQ4XUEMg1YFs9EVKGp0uL6LDGzQYGdzOgAwY4OIiIiIIoeBDSIiIhr0fAMcWckGrFo4FnlZRgCARuW6Qa1W9s3bIrtDwpqn9uDu35bg7t+W4Ie/fh+1ja1ISdR1yNpwEeEKJgTNvhAEfBgsa0OSMOLOO2DIzQEAV5CjmzxBi0p1IoTMbABAfXwKynTpiNEoUVyQhLwsI0Rv1CN4tgkkCS0TivwyLKw1FjSdKg35ZbXUBszHWl3t/XtbVVXIeXtKUSk0MRAEoEyfgVpVbCcnGrpfR1c8vTNEtRrNVicAQK0Svc3kzzW4skBaGptwsqIelnoGOGhw8mRsMLBBRERERJHCHhtEREQ0ZPj24BAEAZu3HcWMSVnYub8cMyZl4Y0Py2Bp6NvGz61tDvzulUN+23z7cdToknBaH5it4VHqM9YmKKCWndDn5CBhQjFEhQKlz2zFiP9YgTPPv4DmUz69M0QRMSkpaDsfvAeFAKBBocNXeVdh9LV5uPTXl3AkeQrQIiBGrYQgCLh1bqFfQ3bfeXvEpKehXpJg2f0hFEoFJIcDp599Ds7m5pDnpDIaMXHLJm+jcUdLKxyXLnmfd1y6BEdzM5R6/0wbWZYhuUtRiTEaNDbbAEHAe6ZJWFz1fuCBRBGGkSNC9uvoiic7RNRoUH/J9XdLfRt2fVYBAPi0tAGFAGou1OPnvy2BMVaDrQ/Ogkqp6NHxiAaq9h4bbB5ORERERJHBwAYRERENSb5BjkXT8wEAC6/Nw9qnduNEeT3UShE2R3vRJwEI2bvhsrn7ccyq2Y/3jOMhd1ZMyWfskbiRmNBcBvvUWe6b64nAHffgkATop30bsDwPNFx0vU6ScGnad6AoeRvC+QoIsn+z8ipNIv6SOR+wCti/3QIYZkFsc511jNp1Y764IAnD0+Jw+nyjdy7HRkxG+rG3vftqqzwPY+V5lL73Qdjn3rE0lLXGVYZKGWuAICpgb2hA24ULMIwc6fdS2eGA7HRlTihiYtDQ5PoUuXPkKNTW7ofJfslvPCSpx9kaQHvGhkIbgyabw7s91t4MnbMNsQ5X8CbGaUWqtRZZxli0nT4NyWjsUbNyooHKE9hQKXg5SURERESRwXeiRERERG6ehuOeTA7fDA4Zrt4clZbQmQeX44wuHVuyr+/22H0JY4GPW4CPPwscaP42lrW9hXRrLSo1JvxlXytGyPlYLJf7DQtW/koQAFEAJABajesto8MpoaZDeaV9NhP+zZ050iNBSkN5ylBpkpMBGbA3NKD+4JGAyJLDNwtErUFjsyt74+ZZBXitbDJuPL8LSji9YSJDbk6PszUAwOnusSFqNGhudQU2FLITyyvehMHZnumjlWy4vfxNoBw48unLARkpRNHOzowNIiIiIoowBjaIiIiIfPhmcvhmcORlGXHbvEJs3nYEkiyj0tIS4ZmGwSe7o8RUDAiCt3xUqrUOImRvtkbHZuWyDGhUSjicdsS4AxtKhYg0sx4ny+vbB4oiPkoYh2vrDvZofoackQHBBm9gw2zCxc8OAQDO/OV5nPlLiP0oFGhqc0JyBz6uGpeG57Py8LazDd+t/sg7zDjpSjSXlgEAbBfrAQFQG41Bd6mKjw/IsvBmbMRo0dTqurFr0MfgklIPnbMtePO6y2hWTjRQtZeiYrCOiIiIiCKDV1hEREREIfhmcCybX+htQn7o62o89fLBkP04cjLjIQgCSivqvTfbL8e1EzLxgbuPQ3cFZIK4m34vPr8TQPBsDVEAcjKNOFPlKjnlKUUlCAJu69BnAwA+SRiDgqYzSLPVdVZEK5Asw3zN1d5ggyeY0FbtKkUlaDRQaGPgsNuDv14QAFmGQhuDhiZXNkWsTg2lUoHF00ZCeuI5v+EVL72KipdeDWtqvlkW1hoL7I2NaDl71j1vCY7yM0hpq0XRsCTsvzAK373wUfAdXUazcqKBytM8XMXABhERERFFCAMbRERERJ3wzeDw3bb1odnebA5fZqMWt183GpKEgABAT2Qk6fHj7xXhX0fPw2rvYbmnDnybfldqTAHZGpIMXHtlFjb//SgAoKq2GUqFCLNRi+KCJORkxuNURUP7CwQBe0zF3mBJd5x+9k/evysNBhQ+/F9oOnEKAFC7+8POX+zuE6KI0aLeHdgwxmoAANd+YwT+odJD72zrXrAF8MuykOx2HL7nPtjr28+36eQp5Jw8hRwAqAAKVVqc1yQixVrnn7UhCNBmZEAZF4emU6VBs0CIopHd6SrFxowNIiIiIoqUoBnzRERERNQ5TzZHZpIeGUl6AEBelhFbH5yFovxkFBckIS/LCMDVm6MznT2/csE4KBQK3Dwjv9fm7ilRZVHFe0tUdeQJagDAQ3/ci7s3lMDucHqzNjoq06XjvDrhshqsO5qacPS+dWj84ouwxsdkuAIyrsbh7sCGQYOai604fb4RX+V8s/tBDQCQZSRNn4bm0jI0nzkLZWxs0O8RAMgQoE1JxocJ4wPfWMsyWisqcGTtfTi85l4cXnsfpFDZJ2Gw1ljQdKo05JfVUtvjfRN1hydjg4ENIiIiIooUZmwQERER9ZBvaSpPuSpPySHfMlZ3LhiD598+FpDdAbiCIUvnjsKjz3zst91TDqq4IAkAcOOMXLy68+tey9roTrNyQQCSjFooFa5b9xNGJQc2UhcE7DZN6FHWRk/phg1D27lKSDYbmo8cRkpbLdJsAh761Zs4Z1MBshEFGhNSrbXd/jRP2eZnwxonQMaof78N1ncssF3YDZXsDB5MucxeG8EyRzpik3LqL+yxQURERESRxowNIiIiosvkKVdVlJ8cdHtxQUpAdkdGkh6ZyQYsm1+ICQXJ3uwOD0kGbp3bHigRRRGLZ/Vi1kYHiXGakM/JMjB9YhZOnWuApb4VgiBg5YKxAePKdOmoVCe6XuN5bV9M1q1urysYZK2uRtzrW7Gi4k1M+ODPuOnkP6CUnd5+In31hleCADEzG47hBZj/byOxN2Fs6AyRy+y1ISiV0JjNITNH2KSc+hMDG0REREQUaQxsEBEREfUDT3bHqoXjkJVswKqF47DRHQwJVdbKk63hceP0PORlGUPePNeoXE2+1crw3+KJgutYP15cDKUi9E33P247irt/W+ItSeXJ2vAjCCgxT0CDQuedowDAKYjtN+T7uIm2DAHa5CQ43G9zPf1EpHB3oFCEfSwRMvTXLcDap3Zj898/x17jGNiEwNdLEKDPyYGxuCjsfXckCAKGLV3i7SsSwKd8FktUUV+zewMb6gjPhIiIiIiGKgY2iIiIiPpRZ9kdvoEP37JWHoIg4Na5hUGzIMxGLZbMzkdWsgHfm10Q8vgzJw+DOT7G+9iTGTJhVAoeXDGl07n7lqQSBAGrFo6FqkMQ5YwuHRuHL0KlxtUku1JjQsyKH7bfkJdlxKSndS/A0Y2xntJQecMSIAroftaGM7xSXzKA85pEmCcVIylB65qiKOKjhHEBY0XIGHarK1vjcvpkGIuLYMjNAcTgZ1O2+VlXL4+OX5fZ24OoI2ZsEBEREVGkMVediIiIaADxBD5C8TQlP1FeD41KAavdibwsI5748dUQBAGLpudDlmX860glTla092Pw9Oz4fzcXAQDWPrUbJ8rr/TJDJoxKRppZh/OWlqDHljuUxyoucAVDHnlmr/9Ad3PyWTX78VXuN1FUPB51w4bDcfY0DLk5yFq6BF899vOuvxmCgJjUVLSdP9/1WLhLQ2VkIaG4CLfqarzz8mRtpFt7L3NBALA7sRhz9RrcOrfQe6xPEsagsKkMybZ6iHAFQISkVKji4tB4/Gt89dNfwNHUFHK/yrg4FD64DqJPSSnbxXo4ml2vSZg8CU0nT3VjoixRRb3PE9hQMbBBRERERBHCKxwiIiKiKOLblHzGpCzs3F8ekN0hCAKWXzcaT718EJaGNgCBPTs8++jY8Pz7C8bh0S0fBxy3YzNzD99Aiy9vc3IrsP+pPch25GK25iKsk2fBFpMGpTvQAbUasNkRtBuHLGPEnXeg/MWX0XTyFGLS0joNcoiQYfj2DRAEAWNyEqEQBTgluT3QUr0PgiDDZL8Uxne6c7WqWJTp0nHe0oxYvQpZKbGoqL4EUZYQ72jxZogIAFBThSNr7wtrv87mZhy9b133JiOKgBSi2NZl9vYgCsYmMWODiIiIiCKLgQ0iIiKiKOOb1bFoevCG4kX5ydj60OygmRkd9+HL0zuj0tLst71jYMTDE2jZ9LfDqL7YBrsz+A32M7p0PKO7HtjXAuz7BNmOXMxSXcRRw0hcW3cw6GuUw4ajNnkElPMWQPHai9AsWgLH/70OR/mZgF4TEgRUaRKRmZWDkxX1kGUZZqMWF+pavMffMnwBslsqvQGOBHsTxG62N5fg6hnyrnkKIAhY89Ruv+edEHFRFYsYa23oRuKdUCUmwGapDd1LIwhNcjKUBj2aS8v8AxyiCMPIEZfV24OGNkmS8JXlJC62NiBBG49Ccy5EUWQpKiIiIiKKOAY2iIiIiAYp3+yOYD07Qr1m1cKx+NnWfXA4Jchy6GwNj6L8ZGxaNwuv7vgaz2//Kqy5eTM6ZBljbRUwN9VAUKsh22yISUtDZV0r3nHk4swGd+DAMAvYbsEIew4Wy6cD9idCxp7EIpQ996l3my4m8K2uJ8AxovkcFp/fGdZc/Y8DvJZ6Lc7o0wOe85QG25NY1KN9A4CtxtLt16R9Zz4EQURZxxJVksRsDeqxTyoO4rnPXkVta713m0lrxPLim2Bz2gCwFBURERERRQ6bhxMRERENYqGalXfG0zvDkzQQKlujoxtn5EKjUnRvgoKAHXHjYVHF41+mIsRkZmDkqjvxwTeX4WyQ4EGZLh3n3Y3J6wxJ3r9Xakwo06X77hbpZj3SzLqgh/X03QCACzEmiOYwvj+CEHAcXzfPyA/Yd384/cxWlG3eEviEQoG4MVf02zxo8Pik4iCe+GizX1ADAGpb6/Hkv56B7P7lwIwNIiIiIooUBjaIiIiIKICndwaAgDJWoYiiiBun53T7WJ7sjWNZxWi84x4cciZi8hWpwasxCQJ2mYrhNCVDNW8BdpmKYVHFo8RU7IpmuMkycNu80fj+gnHBD+ruu2FRxeP9xGK8pBwTcpzvTksL/g2C6B/gEQXX9+iaKzOQmWQABAF7Eou69T1Qmc3dGh8OTXIyRBVvPFP3SLKE5z57NayxaoW6j2dDRERERBQcS1ERERERUYCelLECgIXTcvDOR1+jtiloO/BOXahrxZMvBu+34euMLh2/1qUDB62Ap6SVj46ls4L1DPHsx/taWUatKjawsbgsIyY9DW2V52HIzcHMW+bgww7N1SUZ+N6sAtzz1B7UN1kBtGdtpFprIcL1vejsO2i3dL8EVVcybrieZaio245ZTgVkaoSiEnk5SURERESRwYwNIiIiIgqqJ2WsBEHAxOHdD2r0Jt/SWYIgYOWCsV2/SBDwrnky7FDA235bFGHIzcHI798JbWYmsm9bigmjkqFRt5fb8mRrTCxMRlKCtj3Bw5214XmzfbnhheAt2Ttnq69H06nSoF9WS+1lzogGq/q2xrDGKQQFA2dEREREFDH8iA0RERER9aqMBCA3Mx4nKxoicnyFKGBMTqL38YRRySGzNnyd0WdgW/o03Fzpbvztbr6dUDQeCU8/BQBoszpgtzu9r/EEUURRxK1zC/HIM3u9z3myNtKttbAJCqghIXh9rc4FyyQRNRpINlun+6t48WVUvPhy0OdURiPGb/x9t+dCg58xJi6scSoFLyWJiIiIKHKYsUFEREREvUoQgKVzCpCZpEdGkr7fj5+SqINK2Z5VIQgCVi0cC5Wy67e+pdp0OFIzAQDKYcPhGFHg9/zX5RchyYBC4fqkum//EU9fEu9n2H36eBzJuLJHQY0GhQ7vmie3NyM3J0ObmYmsmxeF3J/SaOx8p4IAjdkEQckb0xRolDkHJq2xy3ExSk3fT4aIiIiIKAQGNoiIiIio143PM2PjAzOxauE4vwBHRpIe5viYPj32ygVjA0rkFBek4MEVU7p+sSDgNXEULKp4PO/IxV2/+QDbdp3EP/eU4oMD5XjzwzIAQFaSASmJOsyYNAy1DW3ulwr43qwCvzJcnj4e72kKvMEJiyoWFmUcalWxnZaYqlXFYuPwRTijz8AeczEadQkY/aNVmPD0U8hYtBCG3BxADHw776iv7/wcZRlx48agds9HUJ8shWX3h6g78BlLVBEAQBRE3D7h5i7Hadg4nIiIiIgiiB/TIiIiIqI+U5SfjI0PzMShr6uxedtRrLxhLMbnJWHtU7txorweGpUCVp/STpcrI0mPCaOC9wTxZFR0dVy/puJtDmz95xcBY05XuUpDbXr9CF7ecRxbH5wFlVKBiYXJwfftzt6YVbMfO5Im4YwuHSOaz2Hx+Z1B52AXRLxrngJP044ybTpS/t8iJLjPTRAEDFu6BF8+9nO/14VTogoAKl//BwAgDkDp7g+921VGIyZu2QRRper09TS4TcksxtqrVuKP+19Ak629hJtGocaUrAnYffpjqBX8N0JEREREkcOMDSIiIiLqc76NyAVBwLL5hchKNmDxrPwuXysA0KgUEMPoU7xywbiQDY27e9xwCAKQZNRCqXC9rRZFETfPCL5vT8DkjC4dQHsPjmBZGx+P/TbO6NO9jzNTDHBKTnxwoNz7dUgyQUrPch03OQXqtPROS1SFczIsUUUeUzKL8e2CmX7brE4bdp/+GABgczoiMS0iIiIiIgDM2CAiIiKiCPAEOmRZxt6j5zvNopAB3DwjH89v/8pvu0algM3hhCwDogDkZLb3u+jOcVVKEXZHZ0WhQpPdzcN9gyk3zsjFqzu/7joTRRCwJ7EoIGtDn5OD0bOuwkf/aM8UqbjQhJ8+uy9gF9kowCxVI3Yox6LWnI2HJ06B5sO9sJaV9ehkhi1dEjIwREPPF9XHQz53obkGf/3iTSwsnAcxSEk0IiIiIqK+xHegRERERBQxvlkUS2bn+/Xj0KhcDcDzsoy4cUYu8rKMAFzlpjLdWRee5AQpSIAh/OMWdP2CIETBv3m4d7sohp0R4snaAFy9Ny5qjCgbczUOHq8O6/W+WSBNLXbc9/sP8TexB+cjijDk5sBYXNT919KgJEkSjtWc7HTMq5+/gR++8V/4pOJgP82KiIiIiMiFGRtEREREFFGeLAoAWDQ939uPY8akLOzcX45l8wshiiKWzS/09ukoyk/2y7oIFmAI97ie/Zwsr0d3ijh1Fky5cXoe9h49j1MV9ZA622mQ3hv4wgmgplvn4rM7WDPzoBdOoLm0DJDCzESRJGZrkJ+vLCdhl7ouN1XXWo8nPtqMtVetxJTM4n6YGRERERERMzaIiIiIaIDxBBwWTc/39uXw3e557Jt1sWx++NkaHQmCgFvnFnYrqBEqW6PjPjsNarh17L1xOWQZuHXeaGQvXRJ+UIPZGhREbcvFbo1/7rPXIIX7b46IiIiI6DIxsEFEREREUatjsKOniguSvKWuwhFO6SvffeZmxiMnM/6y5tgVAUBWigFxehUsScOhGTECAKDPGQl9bo4rnSMYZmtQEN3911DbehFfWTovXUVERERE1FsY2CAiIiKiIc+T/eHb46Oj3Mx45LoDFeGUvvLNKFl+3Wjcft1omONjenvqXjKA8gtNuHvDbqzZsBuvoABiShoSFt3syuCQ/dNHRI0agCvwwWwN8iVJEmpb67v9uoutDb0/GSIiIiKiINhjg4iIiIgIruyPjQ/MxKGvq/HH149ABnCuphkZSXoIgoDl140GAGzedjTs0le+/UMAYOtDs7H2qd04UV7fR2fR7pgiGf8dOwvat6qx8vox0KRnQawsh5icAqVCgeQZ03D6n28ik9ka5GP/ucN4/sjfehTYSND2bVYSEREREZEHAxtERERERD58Axy+zco9fAMV3eXJ4vjj60cgyTIqLS0hx4oCMDLDdaP41LkGv4QLjUoBq90Z1jFb2xx46pVDyEYBZqkasUM5FrXmbPzXhIk4JyvxzXFje3w+NLicdVbhhU+29+i1Jm0CCs25vTwjIiIiIqLgGNggIiIiIgqiY7ZFb+7XEzh56uWDsDS0BR0nycBt81xZIo88s9e73WzU4ttXDceOT86gur4Ndkd4DZs9TcoBAC12rPvDXqgUgGlYOUzxehhjNTAaNDAbtZd3ghSVJFnCp/avevz62yfcBFFkpWMiIiIi6h8MbBARERERRUBRfrJfaSpPFobnT98+HnlZRpwor0delhFP/PhqCIKARdPz8drOr/GXt3p+M9ruBP7ntaPex8ZYDbY+OAsqpeKyz4+iy9+PvYtWWLscF6cxoNHa5H1s0ibg9gk3YUpmcV9Oj4iIiIjIDz9SQ0REREQUIb4NxpfMzvf709PHw3dMx94eN07PQ16WEb3RIUMQgCSjFkoFLxF8Pf300xg+fDhiYmIwZcoU7Nu3r9Pxr732GkaNGoWYmBiMHTsWb731Vj/NtOc+qTiIv30V3jyXFd2IR669G//vG3fgkWvvxtPf/jmDGkRERETU75ixQUREREQUQb4lrxZNz/f7M9gYX4Ig4Na5hX6lqnpKloFb54bXFH2oeOWVV7BmzRps2rQJU6ZMwYYNGzBnzhwcP34cycnJAeP/9a9/YcmSJVi/fj2+/e1v48UXX8SCBQvw2WefYcyYMRE4g65JkoTnPns17PEmXQKuSM7veiARERERUR9iYIOIiIiIKIoVFyR5S1X1lCgAOZntpa/I5cknn8Sdd96JFStWAAA2bdqEN998E1u3bsUDDzwQMP6pp57C3Llzce+99wIAfvazn2HHjh34n//5H2zatCnoMaxWK6zW9hJQjY2NAAC73Q673d7bpxTgy5oTqG2tD2tsotaIXGN2v8yLQvN8/7kO0YHrFT24VtGF6xU9uFbRJdLr1Z3jMrBBRERERBTFPKWq/vj6EcgAztU0I92sR6WlOex9SMzWCGCz2XDgwAGsW7fOu00URcycORN79wbPkNm7dy/WrFnjt23OnDn4+9//HvI469evx2OPPRaw/d1334VOp+vZ5LvhtLMy7LFXOIZj+9vb+3A21B07duyI9BSoG7he0YNrFV24XtGDaxVdIrVeLS0tYY9lYIOIiIiIKMoV5Sdj4wMzcejramzedhR3LhiD598+5teUPBRmawRnsVjgdDqRkpLitz0lJQXHjh0L+pqqqqqg46uqqkIeZ926dX7BkMbGRmRlZWH27NmIi4u7jDMIz5c1J/DRniNdjltUOA8LC+f1+Xyoa3a7HTt27MCsWbOgUqkiPR3qAtcrenCtogvXK3pwraJLpNfLk70cDgY2iIiIiIgGCd9eHIIgYPO2o5gxKQvv7TvrzeboiNkakaXRaKDRaAK2q1SqfrmYHJs6CiatsdNyVIkxRtw05tsQRTaWH0j6698I9Q6uV/TgWkUXrlf04FpFl0itV3eOyXemRERERESDkCfIsWh6PjY+MBOrFo5DZpIeGUl6AIBGpQAA5GbGM1sjCLPZDIVCgQsXLvhtv3DhAlJTU4O+JjU1tVvjBwJRFHH7hJs7HbPiypsZ1CAiIiKiAYXvTomIiIiIhgBPuapVC8chK9mAm2fkwqgDls4pYLZGEGq1GldeeSV27tzp3SZJEnbu3ImpU6cGfc3UqVP9xgOu+sShxg8UUzKL8Z9T/h06+GeOmLQJWHvVSkzJLI7QzIiIiIiIgmMpKiIiIiKiIcSTyWG326FpOY7xeeZIT2nAWrNmDZYvX46JEydi8uTJ2LBhA5qbm7FixQoAwLJly5CRkYH169cDAH784x/jmmuuwRNPPIHrrrsOL7/8Mj799FNs3rw5kqcRlkkZ43FBU4GRk/Nxyd6MBG08Cs25zNQgIiIiogGJgQ0iIiIiIqIgFi9ejJqaGjz88MOoqqpCUVERtm/f7m0QfvbsWb8b/9/85jfx4osv4sEHH8RPfvIT5OXl4e9//zvGjBkTqVPoFlEQMDopj/WviYiIiGjAY2CDiIiIiIgohNWrV2P16tVBn9u1a1fAtptuugk33XRTH8+KiIiIiGhoY14xERERERERERERERFFDQY2iIiIiIiIiIiIiIgoajCwQUREREREREREREREUYOBDSIiIiIiIiIiIiIiihoMbBARERERERERERERUdRgYIOIiIiIiIiIiIiIiKIGAxtERERERERERERERBQ1GNggIiIiIiIiIiIiIqKowcAGERERERERERERERFFDQY2iIiIiIiIiIiIiIgoajCwQUREREREREREREREUYOBDSIiIiIiIiIiIiIiihoMbBARERERERERERERUdRQRnoCQ5ksywCAxsbGfj2u3W5HS0sLGhsboVKp+vXY1H1cr+jBtYouXK/owbWKLlyv6BHptfK8B/a8JyYXXiNQV7hW0YXrFT24VtGF6xU9uFbRJdLr1Z1rBAY2IujSpUsAgKysrAjPhIiIiIgoMi5duoT4+PhIT2PA4DUCEREREQ114VwjCDI/IhUxkiShsrISsbGxEASh347b2NiIrKwslJeXIy4urt+OSz3D9YoeXKvowvWKHlyr6ML1ih6RXitZlnHp0iWkp6dDFFkh14PXCNQVrlV04XpFD65VdOF6RQ+uVXSJ9Hp15xqBGRsRJIoiMjMzI3b8uLg4/kKJIlyv6MG1ii5cr+jBtYouXK/oEcm1YqZGIF4jULi4VtGF6xU9uFbRhesVPbhW0SUarhH40SgiIiIiIiIiIiIiIooaDGwQEREREREREREREVHUYGBjCNJoNHjkkUeg0WgiPRUKA9crenCtogvXK3pwraIL1yt6cK3IF/89RA+uVXThekUPrlV04XpFD65VdImm9WLzcCIiIiIiIiIiIiIiihrM2CAiIiIiIiIiIiIioqjBwAYREREREREREREREUUNBjaIiIiIiIiIiIiIiChqMLBBRERERERERERERERRg4GNIejpp5/G8OHDERMTgylTpmDfvn2RntKQ9+ijj0IQBL+vUaNGeZ9va2vDXXfdBZPJBIPBgEWLFuHChQsRnPHQsXv3bnznO99Beno6BEHA3//+d7/nZVnGww8/jLS0NGi1WsycORMnTpzwG1NXV4elS5ciLi4ORqMR//7v/46mpqZ+PIuho6v1uv322wN+1ubOnes3huvVP9avX49JkyYhNjYWycnJWLBgAY4fP+43JpzffWfPnsV1110HnU6H5ORk3HvvvXA4HP15KoNeOGs1bdq0gJ+tVatW+Y3hWvWPjRs3Yty4cYiLi0NcXBymTp2Kt99+2/s8f64oGF4fDEy8Rhi4eI0QXXiNED14jRA9eI0QXQbrNQIDG0PMK6+8gjVr1uCRRx7BZ599hvHjx2POnDmorq6O9NSGvCuuuALnz5/3fn344Yfe5+6++27885//xGuvvYaSkhJUVlZi4cKFEZzt0NHc3Izx48fj6aefDvr8r371K/zud7/Dpk2b8Mknn0Cv12POnDloa2vzjlm6dCm++OIL7NixA2+88QZ2796NlStX9tcpDCldrRcAzJ071+9n7aWXXvJ7nuvVP0pKSnDXXXfh448/xo4dO2C32zF79mw0Nzd7x3T1u8/pdOK6666DzWbDv/71L/z5z3/Gc889h4cffjgSpzRohbNWAHDnnXf6/Wz96le/8j7Hteo/mZmZePzxx3HgwAF8+umnmD59Oq6//np88cUXAPhzRYF4fTCw8RphYOI1QnThNUL04DVC9OA1QnQZtNcIMg0pkydPlu+66y7vY6fTKaenp8vr16+P4KzokUcekcePHx/0ufr6elmlUsmvvfaad9tXX30lA5D37t3bTzMkWZZlAPK2bdu8jyVJklNTU+Vf//rX3m319fWyRqORX3rpJVmWZfnLL7+UAcj79+/3jnn77bdlQRDkc+fO9dvch6KO6yXLsrx8+XL5+uuvD/karlfkVFdXywDkkpISWZbD+9331ltvyaIoylVVVd4xGzdulOPi4mSr1dq/JzCEdFwrWZbla665Rv7xj38c8jVcq8hKSEiQt2zZwp8rCorXBwMXrxGiA68RoguvEaILrxGiB68Ros9guEZgxsYQYrPZcODAAcycOdO7TRRFzJw5E3v37o3gzAgATpw4gfT0dIwcORJLly7F2bNnAQAHDhyA3W73W7dRo0Zh2LBhXLcIKysrQ1VVld/axMfHY8qUKd612bt3L4xGIyZOnOgdM3PmTIiiiE8++aTf50zArl27kJycjIKCAvzgBz9AbW2t9zmuV+Q0NDQAABITEwGE97tv7969GDt2LFJSUrxj5syZg8bGRu8nT6j3dVwrjxdeeAFmsxljxozBunXr0NLS4n2OaxUZTqcTL7/8MpqbmzF16lT+XFEAXh8MfLxGiD68RohOvEYYmHiNED14jRA9BtM1gjJiR6Z+Z7FY4HQ6/f4RAkBKSgqOHTsWoVkRAEyZMgXPPfccCgoKcP78eTz22GP41re+hc8//xxVVVVQq9UwGo1+r0lJSUFVVVVkJkwA4P3+B/uZ8jxXVVWF5ORkv+eVSiUSExO5fhEwd+5cLFy4ECNGjMCpU6fwk5/8BPPmzcPevXuhUCi4XhEiSRL+8z//E1dddRXGjBkDAGH97quqqgr68+d5jnpfsLUCgFtuuQXZ2dlIT0/HkSNHcP/99+P48eN4/fXXAXCt+tvRo0cxdepUtLW1wWAwYNu2bRg9ejQOHTrEnyvyw+uDgY3XCNGJ1wjRh9cIAxOvEaIHrxGiw2C8RmBgg2gAmDdvnvfv48aNw5QpU5CdnY1XX30VWq02gjMjGly+973vef8+duxYjBs3Djk5Odi1axdmzJgRwZkNbXfddRc+//xzv7rhNDCFWivfGtNjx45FWloaZsyYgVOnTiEnJ6e/pznkFRQU4NChQ2hoaMBf//pXLF++HCUlJZGeFhF1E68RiPoHrxEGJl4jRA9eI0SHwXiNwFJUQ4jZbIZCoQjoan/hwgWkpqZGaFYUjNFoRH5+Pk6ePInU1FTYbDbU19f7jeG6RZ7n+9/Zz1RqampA802Hw4G6ujqu3wAwcuRImM1mnDx5EgDXKxJWr16NN954Ax988AEyMzO928P53Zeamhr058/zHPWuUGsVzJQpUwDA72eLa9V/1Go1cnNzceWVV2L9+vUYP348nnrqKf5cUQBeH0QXXiNEB14jRD9eI0QerxGiB68RosdgvEZgYGMIUavVuPLKK7Fz507vNkmSsHPnTkydOjWCM6OOmpqacOrUKaSlpeHKK6+ESqXyW7fjx4/j7NmzXLcIGzFiBFJTU/3WprGxEZ988ol3baZOnYr6+nocOHDAO+b999+HJEne/9QpcioqKlBbW4u0tDQAXK/+JMsyVq9ejW3btuH999/HiBEj/J4P53ff1KlTcfToUb8LzR07diAuLg6jR4/unxMZArpaq2AOHToEAH4/W1yryJEkCVarlT9XFIDXB9GF1wjRgdcI0Y/XCJHDa4TowWuE6DcorhEi1racIuLll1+WNRqN/Nxzz8lffvmlvHLlStloNPp1taf+t3btWnnXrl1yWVmZ/NFHH8kzZ86UzWazXF1dLcuyLK9atUoeNmyY/P7778uffvqpPHXqVHnq1KkRnvXQcOnSJfngwYPywYMHZQDyk08+KR88eFA+c+aMLMuy/Pjjj8tGo1H+xz/+IR85ckS+/vrr5REjRsitra3efcydO1cuLi6WP/nkE/nDDz+U8/Ly5CVLlkTqlAa1ztbr0qVL8j333CPv3btXLisrk9977z15woQJcl5entzW1ubdB9erf/zgBz+Q4+Pj5V27dsnnz5/3frW0tHjHdPW7z+FwyGPGjJFnz54tHzp0SN6+fbuclJQkr1u3LhKnNGh1tVYnT56Uf/rTn8qffvqpXFZWJv/jH/+QR44cKV999dXefXCt+s8DDzwgl5SUyGVlZfKRI0fkBx54QBYEQX733XdlWebPFQXi9cHAxWuEgYvXCNGF1wjRg9cI0YPXCNFlsF4jMLAxBP3+97+Xhw0bJqvVanny5Mnyxx9/HOkpDXmLFy+W09LSZLVaLWdkZMiLFy+WT5486X2+tbVV/uEPfygnJCTIOp1OvuGGG+Tz589HcMZDxwcffCADCPhavny5LMuyLEmS/NBDD8kpKSmyRqORZ8yYIR8/ftxvH7W1tfKSJUtkg8Egx8XFyStWrJAvXboUgbMZ/Dpbr5aWFnn27NlyUlKSrFKp5OzsbPnOO+8MuHHD9eofwdYJgPynP/3JOyac332nT5+W582bJ2u1WtlsNstr166V7XZ7P5/N4NbVWp09e1a++uqr5cTERFmj0ci5ubnyvffeKzc0NPjth2vVP+644w45OztbVqvVclJSkjxjxgzvBYss8+eKguP1wcDEa4SBi9cI0YXXCNGD1wjRg9cI0WWwXiMIsizLvZ8HQkRERERERERERERE1PvYY4OIiIiIiIiIiIiIiKIGAxtERERERERERERERBQ1GNggIiIiIiIiIiIiIqKowcAGERERERERERERERFFDQY2iIiIiIiIiIiIiIgoajCwQUREREREREREREREUYOBDSIiIiIiIiIiIiIiihoMbBARERERERERERERUdRgYIOIiKibBEHA3//+90hPg4iIiIiIBgheIxAR9S8GNoiIKKrcfvvtEAQh4Gvu3LmRnhoREREREUUArxGIiIYeZaQnQERE1F1z587Fn/70J79tGo0mQrMhIiIiIqJI4zUCEdHQwowNIiKKOhqNBqmpqX5fCQkJAFwp4Bs3bsS8efOg1WoxcuRI/PWvf/V7/dGjRzF9+nRotVqYTCasXLkSTU1NfmO2bt2KK664AhqNBmlpaVi9erXf8xaLBTfccAN0Oh3y8vLwf//3f3170kREREREFBKvEYiIhhYGNoiIaNB56KGHsGjRIhw+fBhLly7F9773PXz11VcAgObmZsyZMwcJCQnYv38/XnvtNbz33nt+FyUbN27EXXfdhZUrV+Lo0aP4v//7P+Tm5vod47HHHsPNN9+MI0eOYP78+Vi6dCnq6ur69TyJiIiIiCg8vEYgIhpcBFmW5UhPgoiIKFy33347/vd//xcxMTF+23/yk5/gJz/5CQRBwKpVq7Bx40bvc9/4xjcwYcIE/OEPf8AzzzyD+++/H+Xl5dDr9QCAt956C9/5zndQWVmJlJQUZGRkYMWKFfj5z38edA6CIODBBx/Ez372MwCuCyGDwYC3336bdXyJiIiIiPoZrxGIiIYe9tggIqKoc+211/pdlABAYmKi9+9Tp071e27q1Kk4dOgQAOCrr77C+PHjvRcsAHDVVVdBkiQcP34cgiCgsrISM2bM6HQO48aN8/5dr9cjLi4O1dXVPT0lIiIiIiK6DLxGICIaWhjYICKiqKPX6wPSvnuLVqsNa5xKpfJ7LAgCJEnqiykREREREVEXeI1ARDS0sMcGERENOh9//HHA48LCQgBAYWEhDh8+jObmZu/zH330EURRREFBAWJjYzF8+HDs3LmzX+dMRERERER9h9cIRESDCzM2iIgo6litVlRVVfltUyqVMJvNAIDXXnsNEydOxL/927/hhRdewL59+/Dss88CAJYuXYpHHnkEy5cvx6OPPoqamhr86Ec/wm233YaUlBQAwKOPPopVq1YhOTkZ8+bNw6VLl/DRRx/hRz/6Uf+eKBERERERhYXXCEREQwsDG0REFHW2b9+OtLQ0v20FBQU4duwYAOCxxx7Dyy+/jB/+8IdIS0vDSy+9hNGjRwMAdDod3nnnHfz4xz/GpEmToNPpsGjRIjz55JPefS1fvhxtbW347W9/i3vuuQdmsxk33nhj/50gERERERF1C68RiIiGFkGWZTnSkyAiIuotgiBg27ZtWLBgQaSnQkREREREAwCvEYiIBh/22CAiIiIiIiIiIiIioqjBwAYREREREREREREREUUNlqIiIiIiIiIiIiIiIqKowYwNIiIiIiIiIiIiIiKKGgxsEBERERERERERERFR1GBgg4iIiIiIiIiIiIiIogYDG0REREREREREREREFDUY2CAiIiIiIiIiIiIioqjBwAYREREREREREREREUUNBjaIiIiIiIiIiIiIiChqMLBBRERERERERERERERR4/8D8GY8A45aJDUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1600x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved as /kaggle/working/training_validation_metrics_log_scale.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tạo một range cho trục x (số epochs)\n",
    "epochs_plot = range(1, num_epochs + 1)\n",
    "\n",
    "# Tạo figure và các subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16, 12)) # Tăng kích thước một chút\n",
    "fig.suptitle('Training and Validation Metrics', fontsize=16)\n",
    "\n",
    "# 1. Plot Average Losses\n",
    "axs[0, 0].plot(epochs_plot, train_avg_losses, 'bo-', label='Train Avg Loss')\n",
    "axs[0, 0].plot(epochs_plot, val_avg_losses, 'ro-', label='Val Avg Loss')\n",
    "axs[0, 0].set_title('Average Losses')\n",
    "axs[0, 0].set_xlabel('Epoch')\n",
    "axs[0, 0].set_ylabel('Loss (log scale)')\n",
    "axs[0, 0].set_yscale('log') # <<< ÁP DỤNG THANG ĐO LOGARIT\n",
    "axs[0, 0].legend()\n",
    "axs[0, 0].grid(True, which=\"both\", ls=\"-\") # Grid cho cả major và minor ticks\n",
    "\n",
    "# 2. Plot Main Losses\n",
    "axs[0, 1].plot(epochs_plot, train_main_losses, 'bs-', label='Train Main Loss')\n",
    "axs[0, 1].plot(epochs_plot, val_main_losses, 'rs-', label='Val Main Loss')\n",
    "axs[0, 1].set_title('Main Losses (Student Task Loss)')\n",
    "axs[0, 1].set_xlabel('Epoch')\n",
    "axs[0, 1].set_ylabel('Loss (log scale)')\n",
    "axs[0, 1].set_yscale('log') # <<< ÁP DỤNG THANG ĐO LOGARIT\n",
    "axs[0, 1].legend()\n",
    "axs[0, 1].grid(True, which=\"both\", ls=\"-\")\n",
    "\n",
    "# 3. Plot KD Losses\n",
    "axs[1, 0].plot(epochs_plot, train_kd_losses, 'bv-', label='Train KD Loss')\n",
    "axs[1, 0].plot(epochs_plot, val_kd_losses, 'rv-', label='Val KD Loss')\n",
    "axs[1, 0].set_title('Knowledge Distillation Losses')\n",
    "axs[1, 0].set_xlabel('Epoch')\n",
    "axs[1, 0].set_ylabel('Loss (log scale)')\n",
    "axs[1, 0].set_yscale('log') # <<< ÁP DỤNG THANG ĐO LOGARIT\n",
    "axs[1, 0].legend()\n",
    "axs[1, 0].grid(True, which=\"both\", ls=\"-\")\n",
    "\n",
    "# 4. Plot mAP\n",
    "axs[1, 1].plot(epochs_plot, maps, 'go-', label='Validation mAP')\n",
    "axs[1, 1].set_title('Validation mAP')\n",
    "axs[1, 1].set_xlabel('Epoch')\n",
    "axs[1, 1].set_ylabel('mAP')\n",
    "# Đánh dấu epoch có mAP tốt nhất\n",
    "if maps:\n",
    "    best_map_value_plot = max(maps)\n",
    "    # Kiểm tra xem có giá trị nào không phải là số không (ví dụ như từ epoch đầu nếu mAP chưa tính)\n",
    "    valid_maps = [m for m in maps if isinstance(m, (int, float))]\n",
    "    if valid_maps:\n",
    "        best_map_value_plot = max(valid_maps)\n",
    "        try:\n",
    "            # Tìm index của best_map_value_plot trong list maps gốc\n",
    "            best_epoch_idx = maps.index(best_map_value_plot)\n",
    "            axs[1, 1].plot(epochs_plot[best_epoch_idx], best_map_value_plot, 'y*', markersize=15, label=f'Best mAP: {best_map_value_plot:.4f}')\n",
    "        except ValueError:\n",
    "            print(\"Warning: Best mAP value not found in the original 'maps' list for plotting marker.\")\n",
    "\n",
    "axs[1, 1].legend()\n",
    "axs[1, 1].grid(True)\n",
    "\n",
    "# Điều chỉnh layout để không bị chồng chéo\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96]) # rect để chừa chỗ cho suptitle\n",
    "\n",
    "# Hiển thị plot\n",
    "plt.show()\n",
    "\n",
    "# Lưu biểu đồ (tùy chọn)\n",
    "try:\n",
    "    save_path = os.path.join(working_dir, 'training_validation_metrics_log_scale.png')\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Plots saved as {save_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving plot: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53162a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T10:48:01.720526Z",
     "iopub.status.busy": "2025-05-18T10:48:01.720252Z",
     "iopub.status.idle": "2025-05-18T10:48:28.147989Z",
     "shell.execute_reply": "2025-05-18T10:48:28.146828Z"
    },
    "papermill": {
     "duration": 26.833108,
     "end_time": "2025-05-18T10:48:28.149404",
     "exception": false,
     "start_time": "2025-05-18T10:48:01.316296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ no model scale passed. Assuming scale='n'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       788  lsmyolo.nn.modules.RFAConv.RFAConv           [3, 16, 3, 2]                 \n",
      "  1                  -1  1      6400  lsmyolo.nn.modules.RFAConv.RFAConv           [16, 32, 3, 2]                \n",
      "  2                  -1  1      8736  lsmyolo.nn.modules.block.MSFM                [32, 32, 1, True]             \n",
      "  3                  -1  1     19776  lsmyolo.nn.modules.block.LAE                 [32]                          \n",
      "  4                  -1  2     58240  lsmyolo.nn.modules.block.MSFM                [32, 64, 2, True]             \n",
      "  5                  -1  1     41600  lsmyolo.nn.modules.block.LAE                 [64]                          \n",
      "  6                  -1  2    231168  lsmyolo.nn.modules.block.MSFM                [64, 128, 2, True]            \n",
      "  7                  -1  1     91392  lsmyolo.nn.modules.block.LAE                 [128]                         \n",
      "  8                  -1  1    510208  lsmyolo.nn.modules.block.MSFM                [128, 256, 1, True]           \n",
      "  9                  -1  1    164608  lsmyolo.nn.modules.block.SPPF                [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  lsmyolo.nn.modules.conv.Concat               [1]                           \n",
      " 12                  -1  1    169088  lsmyolo.nn.modules.block.MSFM                [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  lsmyolo.nn.modules.conv.Concat               [1]                           \n",
      " 15                  -1  1     42560  lsmyolo.nn.modules.block.MSFM                [192, 64, 1]                  \n",
      " 16                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 17             [-1, 2]  1         0  lsmyolo.nn.modules.conv.Concat               [1]                           \n",
      " 18                  -1  1     10784  lsmyolo.nn.modules.block.MSFM                [96, 32, 1]                   \n",
      " 19                  -1  1     19776  lsmyolo.nn.modules.block.LAE                 [32]                          \n",
      " 20            [-1, 15]  1         0  lsmyolo.nn.modules.conv.Concat               [1]                           \n",
      " 21                  -1  1     36416  lsmyolo.nn.modules.block.MSFM                [96, 64, 1]                   \n",
      " 22                  -1  1     41600  lsmyolo.nn.modules.block.LAE                 [64]                          \n",
      " 23            [-1, 12]  1         0  lsmyolo.nn.modules.conv.Concat               [1]                           \n",
      " 24                  -1  1    144512  lsmyolo.nn.modules.block.MSFM                [192, 128, 1]                 \n",
      " 25                  -1  1     91392  lsmyolo.nn.modules.block.LAE                 [128]                         \n",
      " 26             [-1, 9]  1         0  lsmyolo.nn.modules.conv.Concat               [1]                           \n",
      " 27                  -1  1    575744  lsmyolo.nn.modules.block.MSFM                [384, 256, 1]                 \n",
      " 28    [18, 21, 24, 27]  1    617364  lsmyolo.nn.modules.head.Detect               [1, [32, 64, 128, 256]]       \n",
      "LSM-YOLO summary: 503 layers, 2882152 parameters, 2882136 gradients, 12.6 GFLOPs\n",
      "\n",
      "Ultralytics YOLOv8.0.202 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "LSM-YOLO summary (fused): 391 layers, 2873048 parameters, 18824 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/val/labels.cache... 151 images, 225 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.43it/s]\n",
      "                   all        376        181      0.891      0.785      0.888      0.649\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/val\u001b[0m\n",
      "Ultralytics YOLOv8.0.202 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Br35H-Mask-Prepared/test/labels... 150 images, 226 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<00:00, 967.44it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/Br35H-Mask-Prepared/test/labels.cache\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "                   all        376        186      0.939       0.72      0.845       0.62\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/test\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_model = YOLO_lsm('LSM-YOLO/LSM-YOLO.yaml')\n",
    "best_model.model.load_state_dict(torch.load('lsm_best.pt'))\n",
    "best_model.val(data=data_yaml_path, split='val', project='runs', name='val')\n",
    "best_model.val(data=data_yaml_path, split='test', project='runs', name='test')\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc23f81f",
   "metadata": {
    "papermill": {
     "duration": 0.414771,
     "end_time": "2025-05-18T10:48:28.988034",
     "exception": false,
     "start_time": "2025-05-18T10:48:28.573263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7432452,
     "sourceId": 11830903,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33296.983525,
   "end_time": "2025-05-18T10:48:33.075204",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-18T01:33:36.091679",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
